commit_sha: 40f07fe2cc37a11d0f7945633a51aa793d0b532f  # The commit at which this recipe failed to build.
skiplist: true # Set to true to skiplist this recipe so that it will be ignored as long as its latest commit is the one given above.
log: |-
  /opt/mambaforge/envs/bioconda/lib/python3.8/site-packages/conda_build/cli/main_build.py:390: UserWarning: RECIPE_PATH received is a file (recipes/rmats2sashimiplot/meta.yaml).
  It should be a path to a folder.
  Forcing conda-build to use the recipe file.
    warnings.warn(
  Updating build index: /opt/mambaforge/envs/bioconda/conda-bld

  No numpy version specified in conda_build_config.yaml.  Falling back to default numpy value of 1.21
  WARNING:conda_build.metadata:No numpy version specified in conda_build_config.yaml.  Falling back to default numpy value of 1.21
  Adding in variants from internal_defaults
  INFO:conda_build.variants:Adding in variants from internal_defaults
  INFO:conda_build.variants:Adding in variants from /opt/mambaforge/envs/bioconda/conda_build_config.yaml
  INFO:conda_build.variants:Adding in variants from /opt/mambaforge/envs/bioconda/lib/python3.8/site-packages/bioconda_utils/bioconda_utils-conda_build_config.yaml
  Adding in variants from /opt/mambaforge/envs/bioconda/conda_build_config.yaml
  Adding in variants from /opt/mambaforge/envs/bioconda/lib/python3.8/site-packages/bioconda_utils/bioconda_utils-conda_build_config.yaml
  INFO:conda_build.metadata:Attempting to finalize metadata for rmats2sashimiplot
  Attempting to finalize metadata for rmats2sashimiplot
  conda-forge/osx-64                                          Using cache
  conda-forge/noarch                                          Using cache
  bioconda/osx-64                                             Using cache
  bioconda/noarch                                             Using cache
  Reloading output folder: /opt/mambaforge/envs/bioconda/conda-bld
  Reloading output folder: /opt/mambaforge/envs/bioconda/conda-bld
  Reloading output folder: /opt/mambaforge/envs/bioconda/conda-bld
  BUILD START: ['rmats2sashimiplot-2.0.4-py38ha5e64a6_3.tar.bz2']
  Reloading output folder: /opt/mambaforge/envs/bioconda/conda-bld

  ## Package Plan ##

    environment location: /opt/mambaforge/envs/bioconda/conda-bld/rmats2sashimiplot_1685182621597/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placeh


  The following NEW packages will be INSTALLED:

      bzip2:           1.0.8-h0d85af4_4          conda-forge
      ca-certificates: 2023.5.7-h8857fd0_0       conda-forge
      libffi:          3.4.2-h0d85af4_5          conda-forge
      libsqlite:       3.42.0-h58db7d2_0         conda-forge
      libzlib:         1.2.13-hfd90126_4         conda-forge
      ncurses:         6.3-h96cf925_1            conda-forge
      openssl:         3.1.0-h8a1eda9_3          conda-forge
      pip:             23.1.2-pyhd8ed1ab_0       conda-forge
      python:          3.8.16-hf9b03c3_1_cpython conda-forge
      readline:        8.2-h9e318b2_1            conda-forge
      setuptools:      67.7.2-pyhd8ed1ab_0       conda-forge
      tk:              8.6.12-h5dbffcc_0         conda-forge
      wheel:           0.40.0-pyhd8ed1ab_0       conda-forge
      xz:              5.2.6-h775f41a_0          conda-forge

  Preparing transaction: ...working... done
  Verifying transaction: ...working... done
  Executing transaction: ...working... done
  Reloading output folder: /opt/mambaforge/envs/bioconda/conda-bld
  Reloading output folder: /opt/mambaforge/envs/bioconda/conda-bld

  ## Package Plan ##

    environment location: /opt/mambaforge/envs/bioconda/conda-bld/rmats2sashimiplot_1685182621597/_build_env


  Source cache directory is: /opt/mambaforge/envs/bioconda/conda-bld/src_cache
  INFO:conda_build.source:Source cache directory is: /opt/mambaforge/envs/bioconda/conda-bld/src_cache
  Downloading source to cache: rmats2sashimiplot-2.0.4_2bd76cc2e9.tar.gz
  Downloading https://pypi.io/packages/source/r/rmats2sashimiplot/rmats2sashimiplot-2.0.4.tar.gz
  INFO:conda_build.source:Downloading source to cache: rmats2sashimiplot-2.0.4_2bd76cc2e9.tar.gz
  INFO:conda_build.source:Downloading https://pypi.io/packages/source/r/rmats2sashimiplot/rmats2sashimiplot-2.0.4.tar.gz
  Success
  INFO:conda_build.source:Success
  Extracting download
  source tree in: /opt/mambaforge/envs/bioconda/conda-bld/rmats2sashimiplot_1685182621597/work
  export PREFIX=/opt/mambaforge/envs/bioconda/conda-bld/rmats2sashimiplot_1685182621597/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placeh
  export BUILD_PREFIX=/opt/mambaforge/envs/bioconda/conda-bld/rmats2sashimiplot_1685182621597/_build_env
  export SRC_DIR=/opt/mambaforge/envs/bioconda/conda-bld/rmats2sashimiplot_1685182621597/work
  RefactoringTool: Skipping optional fixer: buffer
  RefactoringTool: Skipping optional fixer: idioms
  RefactoringTool: Skipping optional fixer: set_literal
  RefactoringTool: Skipping optional fixer: ws_comma
  RefactoringTool: Refactored src/MISO/__init__.py
  --- src/MISO/__init__.py	(original)
  +++ src/MISO/__init__.py	(refactored)
  @@ -1 +1 @@
  -import misopy
  +from . import misopy
  RefactoringTool: No changes to src/MISO/test.py
  RefactoringTool: Refactored src/MISO/misopy/Gene.py
  --- src/MISO/misopy/Gene.py	(original)
  +++ src/MISO/misopy/Gene.py	(refactored)
  @@ -202,8 +202,8 @@
           parts_before = []
           for p in self.parts:
               if p == None:
  -                raise Exception, "Attempting to reference a None part in %s, (part = %s)" \
  -                      %(str(self), str(part))
  +                raise Exception("Attempting to reference a None part in %s, (part = %s)" \
  +                      %(str(self), str(part)))
               if p.end < part.start:
                   parts_before.append(p)
               else:
  @@ -237,7 +237,7 @@
           start_part_num = self.parts.index(start_part)
           end_part_num = self.parts.index(end_part)
           # find parts crossed in between start and end
  -        parts_crossed = range(start_part_num + 1, end_part_num)
  +        parts_crossed = list(range(start_part_num + 1, end_part_num))
           if read_len != None:
               if (end - start) <= read_len:
                   return parts_crossed
  @@ -311,8 +311,8 @@
                   # retrieve part
                   part = self.get_part_by_label(part_label)
                   if not part:
  -                    raise Exception, "Invalid description of isoforms: refers to undefined part %s, %s, gene: %s" \
  -                          %(part, part_label, self.label)
  +                    raise Exception("Invalid description of isoforms: refers to undefined part %s, %s, gene: %s" \
  +                          %(part, part_label, self.label))
                   isoform_parts.append(part)
                   isoform_seq += part.seq
               # make isoform with the given parts
  @@ -328,7 +328,7 @@
           """
           if self.transcript_ids != None:
               if len(self.transcript_ids) != len(self.isoforms):
  -                raise Exception, "Transcript IDs do not match number of isoforms."
  +                raise Exception("Transcript IDs do not match number of isoforms.")
               for iso_num, iso in enumerate(self.isoforms):
                   curr_iso = self.isoforms[iso_num]
                   curr_iso.label = self.transcript_ids[iso_num]
  @@ -759,7 +759,7 @@
           start_part_num = self.parts.index(start_part)
           end_part_num = self.parts.index(end_part)
           # find parts crossed in between start and end
  -        return range(start_part_num + 1, end_part_num)
  +        return list(range(start_part_num + 1, end_part_num))

       def cigar_overhang_met(self, cigar, overhang_len):
           """
  @@ -843,20 +843,20 @@


   def pretty(d, indent=0):
  -    for key, value in d.iteritems():
  -        print '  ' * indent + str(key)
  +    for key, value in d.items():
  +        print('  ' * indent + str(key))
           if isinstance(value, dict):
               pretty(value, indent+1)
           else:
  -            print '  ' * (indent+1) + str(value)
  +            print('  ' * (indent+1) + str(value))


   def printTree(tree, depth = 0):
       if tree == None or not type(tree) == dict:
  -        print "\t" * depth, tree
  +        print("\t" * depth, tree)
       else:
  -        for key, val in tree.items():
  -            print "\t" * depth, key
  +        for key, val in list(tree.items()):
  +            print("\t" * depth, key)
               printTree(val, depth+1)


  @@ -889,7 +889,7 @@

           if gene_label not in gene_hierarchy:
               if not suppress_warnings:
  -                print "Skipping gene %s..." %(gene_label)
  +                print("Skipping gene %s..." %(gene_label))
               continue

           gene_hierarchy[gene_label]['gene'] = gene
  @@ -900,19 +900,19 @@
                                                 gene_records)
           if gene_obj == None:
               if not suppress_warnings:
  -                print "Cannot make gene out of %s" %(gene_label)
  +                print("Cannot make gene out of %s" %(gene_label))
               continue
           gff_genes[gene.get_id()] = {'gene_object': gene_obj,
                                       'hierarchy': gene_hierarchy}

           if (num_genes % 5000) == 0:
               if not suppress_warnings:
  -                print "Through %d genes..." %(num_genes)
  +                print("Through %d genes..." %(num_genes))
           num_genes += 1

       num_genes = len(gff_genes)
       if not suppress_warnings:
  -        print "Loaded %d genes" %(num_genes)
  +        print("Loaded %d genes" %(num_genes))

       return gff_genes

  @@ -938,8 +938,8 @@
                         if (rec.type == "mRNA" or rec.type == "transcript")]

       if len(transcript_ids) == 0:
  -        raise Exception, "Error: %s has no transcripts..." \
  -              %(gene_label)
  +        raise Exception("Error: %s has no transcripts..." \
  +              %(gene_label))

       num_transcripts_with_exons = 0

  @@ -955,14 +955,14 @@
           exons = []

           if len(transcript_exons) == 0:
  -            print "%s has no exons" %(transcript_id)
  +            print("%s has no exons" %(transcript_id))
               continue

           # Record how many transcripts we have with exons children
           # (i.e., usable transcripts)
           num_transcripts_with_exons += 1

  -        for exon_id, exon_info in transcript_exons.iteritems():
  +        for exon_id, exon_info in transcript_exons.items():
               exon_rec = exon_info['record']

               exon = Exon(exon_rec.start, exon_rec.end, from_gff_record={'record':
  @@ -1119,7 +1119,7 @@
       if event_type == 'AFE':
           parts = [distal_exon, proximal_exon]
       else:
  -        raise Exception, "Parsing wrong event type, %s" %(event_type)
  +        raise Exception("Parsing wrong event type, %s" %(event_type))

       # Make it so proximal isoform is always first
       gene = Gene(['%sProximal' %(event_type), '%sDistal' %(event_type)],
  RefactoringTool: No changes to src/MISO/misopy/__init__.py
  RefactoringTool: Refactored src/MISO/misopy/as_events.py
  --- src/MISO/misopy/as_events.py	(original)
  +++ src/MISO/misopy/as_events.py	(refactored)
  @@ -139,15 +139,15 @@
           elif (self.event_type == 'AFE' or self.event_type == 'ALE'):
               self.filter_afe_ale_events(settings)
           else:
  -            raise Exception, "Unsupported event type for filtering: %s" %(self.event_type)
  +            raise Exception("Unsupported event type for filtering: %s" %(self.event_type))

       def filter_afe_ale_events(self, settings,
                                 atleast_proximal=0,
                                 atleast_distal=0,
                                 proximal_distal_sum=20):
  -        print "Filtering AFE/ALE events..."
  +        print("Filtering AFE/ALE events...")
           filtered_events = {}
  -        for event_name, event in self.events.iteritems():
  +        for event_name, event in self.events.items():
               num_proximal = event.num_proximal_body + event.num_proximal_jxns
               num_distal = event.num_distal_body + event.num_distal_jxns
               if (num_proximal >= atleast_proximal and num_distal >= atleast_distal) \
  @@ -159,7 +159,7 @@
                                    atleast_core=1,
                                    atleast_ext=1,
                                    core_ext_sum=20):
  -        print "Filtering tandem UTR events..."
  +        print("Filtering tandem UTR events...")
           if settings != None:
               if 'utr_filter' in settings:
                   core_ext_sum = settings['utr_filter'][0]
  @@ -167,7 +167,7 @@
                   atleast_core = settings['utr_filter'][2]

           filtered_events = {}
  -        for event_name, event in self.events.iteritems():
  +        for event_name, event in self.events.items():
               if (event.num_core >= atleast_core and event.num_ext >= atleast_ext) and \
                  (event.num_core + event.num_ext) >= core_ext_sum:
                   filtered_events[event_name] = event
  @@ -177,14 +177,14 @@
                            atleast_ri_plus_ne=10,
                            atleast_ne=0,
                            atleast_num_common=1):
  -        print "Filtering RI events..."
  -        print "Filter: "
  -        print "  - ri_plus_ne >= %d" %(atleast_ri_plus_ne)
  -        print "  - ne >= %d" %(atleast_ne)
  -        print "  - num_common >= %d" %(atleast_num_common)
  +        print("Filtering RI events...")
  +        print("Filter: ")
  +        print("  - ri_plus_ne >= %d" %(atleast_ri_plus_ne))
  +        print("  - ne >= %d" %(atleast_ne))
  +        print("  - num_common >= %d" %(atleast_num_common))

           filtered_events = {}
  -        for event_name, event in self.events.iteritems():
  +        for event_name, event in self.events.items():
               if ((event.num_inc + event.num_exc) >= atleast_ri_plus_ne \
                   and (event.num_exc >= atleast_ne) and \
                   (event.num_common >= atleast_num_common)):
  @@ -195,7 +195,7 @@
                            atleast_ni_plus_ne=10,
                            atleast_ne=0,
                            atleast_num_common=1):
  -        print "Filtering SE events..."
  +        print("Filtering SE events...")
           if settings != None:
               if 'se_filter' in settings:
                   atleast_ni_plus_ne = settings['se_filter'][0]
  @@ -203,7 +203,7 @@
                   atleast_num_common = settings['se_filter'][2]

           filtered_events = {}
  -        for event_name, event in self.events.iteritems():
  +        for event_name, event in self.events.items():
               if ((event.num_inc + event.num_exc) >= atleast_ni_plus_ne) and (event.num_exc >= atleast_ne) and \
                      (event.num_common >= atleast_num_common):
                   filtered_events[event_name] = event
  @@ -216,18 +216,18 @@
           t1 = time.time()
           self.events = json_utils.json_load_file(json_filename)
           t2 = time.time()
  -        print "Loading from JSON file took %.2f seconds." %(float(t2 - t1))
  +        print("Loading from JSON file took %.2f seconds." %(float(t2 - t1)))
           self.num_events = len(self.events)

       def load_from_pickle_file(self, pickle_filename):
  -        print "Called on: ", pickle_filename
  +        print("Called on: ", pickle_filename)
           # clear currently loaded events, if any
           self.clear_events()
           # Modify events directly
           t1 = time.time()
           self.events = pickle_utils.load_pickled_file(pickle_filename)
           t2 = time.time()
  -        print "Loading from Pickle file took %.2f seconds." %(float(t2 - t1))
  +        print("Loading from Pickle file took %.2f seconds." %(float(t2 - t1)))
           self.num_events = len(self.events)

       def loaded_events_to_genes(self, single_event_name=None,
  @@ -236,7 +236,7 @@
           Parse the loaded set of events into gene structures.  Map events to genes.
           """
           if len(self.events) == 0:
  -            raise Exception, "Must load events first before they can be converted to genes."
  +            raise Exception("Must load events first before they can be converted to genes.")
           events_to_genes = {}

           t1 = time.time()
  @@ -244,7 +244,7 @@
               # If given an event name, only parse that event
               event_names = [single_event_name]
           else:
  -            event_names = self.events.keys()
  +            event_names = list(self.events.keys())
           for event_name in event_names:
               event = self.events[event_name]

  @@ -262,10 +262,10 @@
                                                     label=event.label, read_len=read_len,
                                                     overhang_len=overhang_len)
               else:
  -                raise Exception, "Unsupported event type: %s" %(self.event_type)
  +                raise Exception("Unsupported event type: %s" %(self.event_type))
               events_to_genes[event_name] = gene
           t2 = time.time()
  -        print "Parsing of events to genes took %.2f seconds." %(t2 - t1)
  +        print("Parsing of events to genes took %.2f seconds." %(t2 - t1))
           return events_to_genes

       def output_file(self, results_output_dir, sample_label, method="pickle"):
  @@ -280,7 +280,7 @@
           """
           Output as json.
           """
  -        print "Serializing a total of %d events by JSON." %(len(self.events))
  +        print("Serializing a total of %d events by JSON." %(len(self.events)))
           json_output_dir = os.path.join(results_output_dir, 'json')
           if not os.path.isdir(json_output_dir):
               os.mkdir(json_output_dir)
  @@ -289,7 +289,7 @@
           return json_events_filename

       def output_pickle_file(self, results_output_dir, sample_label):
  -        print "Serializing a total of %d events by Pickle." %(len(self.events))
  +        print("Serializing a total of %d events by Pickle." %(len(self.events)))
           pickle_output_dir = os.path.join(results_output_dir, 'pickle')
           if not os.path.isdir(pickle_output_dir):
               os.mkdir(pickle_output_dir)
  @@ -335,8 +335,8 @@
                   'chrom': core_part_info['chrom']}
       elif (event_type == 'AFE' or event_type == 'ALE'):
           if event_name not in events_to_info:
  -            raise Exception, "Error: Given unknown event %s of type %s." \
  -                  %(event_name, event_type)
  +            raise Exception("Error: Given unknown event %s of type %s." \
  +                  %(event_name, event_type))
           # Return information about the events
           return events_to_info[event_name]

  @@ -372,8 +372,8 @@
       assert((event_type == 'AFE') or (event_type == 'ALE')), \
                          "Error: Event type must be AFE/ALE"

  -    print "Loading events from %s (event type: %s)" %(events_info_filename,
  -                                                      event_type)
  +    print("Loading events from %s (event type: %s)" %(events_info_filename,
  +                                                      event_type))
       events_info_file = open(events_info_filename, 'r')
       events_info = csv.reader(events_info_file,
                                delimiter=delimiter)
  @@ -492,7 +492,7 @@
           ## MXEs
           ##
           elif event_type == 'MXE':
  -            raise Exception, "MXEs not supported."
  +            raise Exception("MXEs not supported.")

           assert(event != None), "Event type %s is unknown." %(event_type)

  RefactoringTool: Refactored src/MISO/misopy/cluster_utils.py
  --- src/MISO/misopy/cluster_utils.py	(original)
  +++ src/MISO/misopy/cluster_utils.py	(refactored)
  @@ -9,7 +9,7 @@
   import misopy
   import misopy.settings as settings
   import misopy.misc_utils as misc_utils
  -from settings import Settings, load_settings
  +from .settings import Settings, load_settings

   def write_cluster_preface(file_handle):
       module_preface = \
  @@ -108,13 +108,13 @@
       elif queue_type == "short":
           queue_name = Settings.get_short_queue_name()
       else:
  -        raise Exception, "Unknown queue type: %s" %(queue_type)
  +        raise Exception("Unknown queue type: %s" %(queue_type))

       if queue_type == None:
  -        print "  - queue: unspecified"
  -    else:
  -        print "  - queue: %s, using queue name %s" %(queue_type,
  -                                                     queue_name)
  +        print("  - queue: unspecified")
  +    else:
  +        print("  - queue: %s, using queue name %s" %(queue_type,
  +                                                     queue_name))
       cs = open(cluster_script, 'w')
       cs.write("#!/bin/sh" + "\n")
       cs.write("#$ -N %s\n" %(job_name))
  @@ -162,7 +162,7 @@
                      queue_type=None,
                      cmd_name="qsub",
                      settings_fname=None):
  -    print "Submitting job: %s" %(job_name)
  +    print("Submitting job: %s" %(job_name))
       queue_name = None

       # Load command name from settings file
  @@ -175,17 +175,17 @@
       elif queue_type == "short":
           queue_name = Settings.get_short_queue_name()
       else:
  -        print "Warning: Unknown queue type: %s" %(queue_type)
  +        print("Warning: Unknown queue type: %s" %(queue_type))
           queue_name = queue_type

       if queue_type is None:
  -        print "  - queue type: unspecified"
  -    else:
  -        print "  - queue type: %s" %(queue_type)
  +        print("  - queue type: unspecified")
  +    else:
  +        print("  - queue type: %s" %(queue_type))
       if queue_name is None:
  -        print " - queue name unspecified"
  -    else:
  -        print " - queue name: %s" %(queue_name)
  +        print(" - queue name unspecified")
  +    else:
  +        print(" - queue name: %s" %(queue_name))

       misc_utils.make_dir(cluster_output_dir)
       if cluster_scripts_dir == None:
  @@ -219,7 +219,7 @@
       Execute cluster_cmd and return its job ID if
       it can be fetched.
       """
  -    print "Executing: %s" %(cluster_cmd)
  +    print("Executing: %s" %(cluster_cmd))
       proc = subprocess.Popen(cluster_cmd, shell=True,
                               stdout=subprocess.PIPE,
                               stderr=subprocess.PIPE,
  @@ -284,19 +284,19 @@
       if cluster_cmd not in supported_cmds:
           return
       num_jobs = len(job_ids)
  -    print "Waiting on a set of %d jobs..." %(num_jobs)
  +    print("Waiting on a set of %d jobs..." %(num_jobs))
       curr_time = time.strftime("%x, %X")
       t_start = time.time()
  -    print "  - Starting to wait at %s" %(curr_time)
  +    print("  - Starting to wait at %s" %(curr_time))
       completed_jobs = {}
       for job_id in job_ids:
           if job_id in completed_jobs:
               continue
           wait_on_job(job_id, cluster_cmd)
  -        print "  - Job ", job_id, " completed."
  +        print("  - Job ", job_id, " completed.")
           completed_jobs[job_id] = True
       curr_time = time.strftime("%x, %X")
       t_end = time.time()
  -    print "Jobs completed at %s" %(curr_time)
  +    print("Jobs completed at %s" %(curr_time))
       duration = ((t_end - t_start) / 60.) / 60.
  -    print "  - Took %.2f hours." %(duration)
  +    print("  - Took %.2f hours." %(duration))
  RefactoringTool: Refactored src/MISO/misopy/compare_miso.py
  --- src/MISO/misopy/compare_miso.py	(original)
  +++ src/MISO/misopy/compare_miso.py	(refactored)
  @@ -28,11 +28,11 @@
   miso_path = os.path.dirname(os.path.abspath(__file__))

   def greeting(parser=None):
  -    print "MISO (Mixture of Isoforms model)"
  -    print "Compare MISO samples to get differential isoform statistics."
  -    print "Use --help argument to view options.\n"
  -    print "Example usage:\n"
  -    print "compare_miso --compare-samples sample1/ sample2/ results/"
  +    print("MISO (Mixture of Isoforms model)")
  +    print("Compare MISO samples to get differential isoform statistics.")
  +    print("Use --help argument to view options.\n")
  +    print("Example usage:\n")
  +    print("compare_miso --compare-samples sample1/ sample2/ results/")
       if parser is not None:
           parser.print_help()

  @@ -74,18 +74,18 @@
           use_compressed = \
               os.path.abspath(os.path.expanduser(options.use_compressed))
           if not os.path.exists(use_compressed):
  -            print "Error: mapping filename from event IDs to compressed IDs %s " \
  -                  "is not found." %(use_compressed)
  +            print("Error: mapping filename from event IDs to compressed IDs %s " \
  +                  "is not found." %(use_compressed))
               sys.exit(1)
           else:
  -            print "Compression being used."
  +            print("Compression being used.")

       if options.samples_to_compare is not None:
           sample1_dirname = os.path.abspath(options.samples_to_compare[0])
           sample2_dirname = os.path.abspath(options.samples_to_compare[1])
           output_dirname = os.path.abspath(options.samples_to_compare[2])
           if not os.path.isdir(output_dirname):
  -            print "Making comparisons directory: %s" %(output_dirname)
  +            print("Making comparisons directory: %s" %(output_dirname))
               misc_utils.make_dir(output_dirname)
           ht.output_samples_comparison(sample1_dirname,
                                        sample2_dirname,
  RefactoringTool: No changes to src/MISO/misopy/credible_intervals.py
  RefactoringTool: Refactored src/MISO/misopy/exon_utils.py
  --- src/MISO/misopy/exon_utils.py	(original)
  +++ src/MISO/misopy/exon_utils.py	(refactored)
  @@ -93,7 +93,7 @@
       - records in gff format
       - filename to output results to
       """
  -    print "Outputting exons to file: %s" %(output_filename)
  +    print("Outputting exons to file: %s" %(output_filename))

       if output_format == "gff":
           # Write file in GFF format
  @@ -104,7 +104,7 @@
           output_file.close()
       elif output_format == "bed":
           # Write file in BED format
  -        raise Exception, "BED format unsupported."
  +        raise Exception("BED format unsupported.")


   def get_tagBam_cmd(bam_filename,
  @@ -154,44 +154,44 @@

       output_filename = os.path.join(output_dir, bam_basename)

  -    print "Mapping BAM to GFF..."
  -    print "  - BAM: %s" %(bam_filename)
  -    print "  - GFF: %s" %(gff_filename)
  -    print "  - Output file: %s" %(output_filename)
  +    print("Mapping BAM to GFF...")
  +    print("  - BAM: %s" %(bam_filename))
  +    print("  - GFF: %s" %(gff_filename))
  +    print("  - Output file: %s" %(output_filename))

       if os.path.isfile(output_filename):
  -        print "WARNING: %s exists. Skipping.." \
  -              %(output_filename)
  +        print("WARNING: %s exists. Skipping.." \
  +              %(output_filename))
           return output_filename

       # "-intervals" option embeds the original GFF coordinates
       # in the output BAM file. Thanks to Aaron Quinlan for implementing
       # this helpful feature.
  -    print "Preparing to call bedtools \'tagBam\'"
  +    print("Preparing to call bedtools \'tagBam\'")
       if misc_utils.which("tagBam") is None:
  -        print "Aborting operation.."
  +        print("Aborting operation..")
           sys.exit(1)
       tagBam_cmd = get_tagBam_cmd(bam_filename, interval_label,
                                   gff_filename)
       # Write intervals as BAM
       tagBam_cmd += " | samtools view -Shb -o %s - " \
                     %(output_filename)
  -    print tagBam_cmd
  +    print(tagBam_cmd)
       t1 = time.time()
       cmd_status = None
       try:
           cmd_status = subprocess.call(tagBam_cmd,
                                        stdout=subprocess.PIPE,
                                        shell=True)
  -    except OSError, e:
  +    except OSError as e:
           if e.errno == errno.ENOENT:
  -            raise Exception, "Error: tagBam or one of the input filenames " \
  -                  "does not exist. Are you sure tagBam is on your PATH?"
  +            raise Exception("Error: tagBam or one of the input filenames " \
  +                  "does not exist. Are you sure tagBam is on your PATH?")
       if cmd_status != 0:
  -        raise Exception, "Error: tagBam call failed."
  +        raise Exception("Error: tagBam call failed.")
       t2 = time.time()
  -    print "tagBam call took %.2f seconds." \
  -          %(t2 - t1)
  +    print("tagBam call took %.2f seconds." \
  +          %(t2 - t1))
       return output_filename


  @@ -220,10 +220,10 @@
       interval of a GFF)
       """
       if not os.path.isfile(bam_filename):
  -        print "Error: BAM file %s does not exist." %(bam_filename)
  +        print("Error: BAM file %s does not exist." %(bam_filename))
           sys.exit(1)
       if not os.path.isfile(gff_filename):
  -        print "Error: GFF file %s does not exist." %(gff_filename)
  +        print("Error: GFF file %s does not exist." %(gff_filename))
           sys.exit(1)
       if not os.path.isdir(output_dir):
           os.makedirs(output_dir)
  @@ -232,20 +232,20 @@
       bam_ext = re.compile("\.bam", re.IGNORECASE)
       output_basename = bam_ext.sub("", os.path.basename(bam_filename))
       output_filename = "%s.bed" %(os.path.join(output_dir, output_basename))
  -    print "Generating coverage file..."
  -    print "  - BAM file: %s" %(bam_filename)
  -    print "  - GFF file: %s" %(gff_filename)
  -    print "  - Output file: %s" %(output_filename)
  +    print("Generating coverage file...")
  +    print("  - BAM file: %s" %(bam_filename))
  +    print("  - GFF file: %s" %(gff_filename))
  +    print("  - Output file: %s" %(output_filename))
       if os.path.isfile(output_filename):
  -        print "  - File exists. Skipping..."
  +        print("  - File exists. Skipping...")
           return output_filename
       coverage_cmd = get_bedtools_coverage_cmd(bam_filename,
                                                gff_filename,
                                                output_filename)
  -    print "Executing: %s" %(coverage_cmd)
  +    print("Executing: %s" %(coverage_cmd))
       status = os.system(coverage_cmd)
       if status != 0:
  -        print "Error computing coverage using bedtools."
  +        print("Error computing coverage using bedtools.")
           sys.exit(1)
       return output_filename

  @@ -268,18 +268,18 @@
       - output_format: gff or BED
       - all_constitutive: treat all exons as constitutive
       """
  -    print "Getting constitutive exons..."
  -    print "  - Input GFF: %s" %(gff_filename)
  -    print "  - Output dir: %s" %(output_dir)
  -    print "  - Output format: %s" %(output_format)
  +    print("Getting constitutive exons...")
  +    print("  - Input GFF: %s" %(gff_filename))
  +    print("  - Output dir: %s" %(output_dir))
  +    print("  - Output format: %s" %(output_format))

       if not os.path.isdir(output_dir):
           os.makedirs(output_dir)

       if min_size > 0:
  -        print "  - Including only exons greater than or " \
  +        print("  - Including only exons greater than or " \
                 "equal to %d-bp" \
  -              %(min_size)
  +              %(min_size))

       t1 = time.time()
       gff_in = gff_utils.GFFDatabase(from_filename=gff_filename)
  @@ -288,7 +288,7 @@

       num_exons = 0

  -    for gene, mRNAs in gff_in.mRNAs_by_gene.iteritems():
  +    for gene, mRNAs in gff_in.mRNAs_by_gene.items():
           # For each gene, look at all mRNAs and return constitutive exon
           curr_const_exons = \
               get_const_exons_from_mRNA(gff_in, mRNAs,
  @@ -308,24 +308,24 @@
                                          %(basename,
                                            min_size))
       if not all_constitutive:
  -        print "Constitutive exon retrieval took %.2f seconds (%d exons)." \
  -              %((t2 - t1), num_exons)
  +        print("Constitutive exon retrieval took %.2f seconds (%d exons)." \
  +              %((t2 - t1), num_exons))
           output_exons_to_file(const_exons_by_gene, output_filename,
                                output_format=output_format)
       else:
  -        print "Constitutive exons GFF was given, so not outputting " \
  -              "another one."
  +        print("Constitutive exons GFF was given, so not outputting " \
  +              "another one.")
       return const_exons_by_gene, output_filename


   def greeting():
  -    print "Utility for fetching constitutive exons from GFF files."
  -    print "Optionally fetch constitutive exons by size."
  -    print "Part of MISO (Mixture of Isoforms model)\n"
  -    print "Usage:\n"
  -    print "To fetch constitutive exons from GFF:\n"
  -    print "exon_utils.py --get-const-exons input.gff --output-dir outdir\n"
  -    print "See --help for more options.\n"
  +    print("Utility for fetching constitutive exons from GFF files.")
  +    print("Optionally fetch constitutive exons by size.")
  +    print("Part of MISO (Mixture of Isoforms model)\n")
  +    print("Usage:\n")
  +    print("To fetch constitutive exons from GFF:\n")
  +    print("exon_utils.py --get-const-exons input.gff --output-dir outdir\n")
  +    print("See --help for more options.\n")


   def main():
  @@ -350,7 +350,7 @@

       if options.output_dir == None:
           greeting()
  -        print "Error: need --output-dir."
  +        print("Error: need --output-dir.")
           return

       output_dir = os.path.abspath(os.path.expanduser(options.output_dir))
  RefactoringTool: Refactored src/MISO/misopy/filter_events.py
  --- src/MISO/misopy/filter_events.py	(original)
  +++ src/MISO/misopy/filter_events.py	(refactored)
  @@ -111,8 +111,8 @@
           num_pass = len(comp[0])
           output_filename = os.path.join(output_dir,
                                          os.path.basename(fname) + ".filtered")
  -        print "Filtering %s into %s" %(",".join(filter_filename),
  -                                       output_filename)
  +        print("Filtering %s into %s" %(",".join(filter_filename),
  +                                       output_filename))
           filter_output(comp[0], output_filename, h, num_pass, total_events[0])

       else:
  @@ -129,7 +129,7 @@
                   rep_list[c][event['event_name']].append(event)
               c = c + 1

  -        for event_name in event_dict.keys():
  +        for event_name in list(event_dict.keys()):
               # not enough replicates of the event passed the previous filters
               if len(event_dict[event_name]) < diff_thresh:
                   del(event_dict[event_name])
  @@ -171,7 +171,7 @@
           for events in comp:
               event_list = []
               for event in events:
  -                if event_dict.has_key(event['event_name']):
  +                if event['event_name'] in event_dict:
                       event_list.append(event)
               comp_new.append(event_list)

  @@ -180,8 +180,8 @@
               fname = filter_filename[i]
               output_filename = os.path.join(output_dir,
                                              os.path.basename(fname) + ".filtered")
  -            print "Filtering %s into %s" %(fname,
  -                                           output_filename)
  +            print("Filtering %s into %s" %(fname,
  +                                           output_filename))
               filter_output(comp_new[i], output_filename, h, num_pass, total_events[i])


  @@ -249,7 +249,7 @@

       if abs(delta_psi_filter) > 1 or \
          abs(delta_psi_filter) < 0:
  -        raise Exception, "Error: delta psi value outside [0, 1]."
  +        raise Exception("Error: delta psi value outside [0, 1].")

       for event in data:
           # Sometimes the bayes factor is not formatted correctly, this fixes that
  @@ -257,9 +257,9 @@

           num_isoforms = len(event['isoforms'])
           if num_isoforms != 2:
  -            print "Error: filter_events.py is only defined for MISO output " \
  +            print("Error: filter_events.py is only defined for MISO output " \
                     "on two-isoform alternative events. " \
  -                  "Found a non-two isoform event: %s" %(event['event_name'])
  +                  "Found a non-two isoform event: %s" %(event['event_name']))
               sys.exit(1)

           # Get sample 1 counts
  @@ -299,7 +299,7 @@
               sample2_counts = get_counts(event['sample2_counts'])

               if sample2_counts == None:
  -                raise Exception, "Incompatible samples."
  +                raise Exception("Incompatible samples.")

               sample2_inc, sample2_exc, sample2_both = sample2_counts

  @@ -333,16 +333,16 @@
       """
       dictlist2file(filtered_events, output_filename, h)

  -    print "%d/%d events pass the filter (%.2f percent)." \
  +    print("%d/%d events pass the filter (%.2f percent)." \
             %(num_pass,
               total_events,
  -            (num_pass/float(total_events)) * 100)
  +            (num_pass/float(total_events)) * 100))


   def greeting():
  -    print "filter_events: filtering MISO pairwise comparison output.\n"
  -    print "Note: This utility is only works on MISO output for two-isoform "
  -    print "event annotations.\n"
  +    print("filter_events: filtering MISO pairwise comparison output.\n")
  +    print("Note: This utility is only works on MISO output for two-isoform ")
  +    print("event annotations.\n")


   def main():
  @@ -389,11 +389,11 @@
       (options, args) = parser.parse_args()

       if options.filter_filename == None:
  -        print "Need at least one filename to filter (use --filter.)"
  +        print("Need at least one filename to filter (use --filter.)")
           return
       if options.output_dir == None:
  -        print "Need an output directory to output filtered file to " \
  -              "(use --output-dir)"
  +        print("Need an output directory to output filtered file to " \
  +              "(use --output-dir)")
           return

       filter_filename = []
  RefactoringTool: Refactored src/MISO/misopy/gff_utils.py
  --- src/MISO/misopy/gff_utils.py	(original)
  +++ src/MISO/misopy/gff_utils.py	(refactored)
  @@ -33,7 +33,7 @@
   import shelve
   import misopy
   import misopy.pickle_utils as pickle_utils
  -from urllib import quote as url_quote, unquote as url_unquote
  +from urllib.parse import quote as url_quote, unquote as url_unquote

   from collections import defaultdict

  @@ -76,13 +76,13 @@
       if it exists. Return None if it does not exist.
       """
       shelve_fname = os.path.join(indexed_gff_dir, shelve_basename)
  -    print "Searching for %s.." %(shelve_fname)
  +    print("Searching for %s.." %(shelve_fname))
       gene_ids_to_gff_index = None
       if os.path.isfile(shelve_fname):
  -        print "  - Found shelved file."
  +        print("  - Found shelved file.")
           gene_ids_to_gff_index = shelve.open(shelve_fname)
       else:
  -        print "  - File not found."
  +        print("  - File not found.")
       return gene_ids_to_gff_index


  @@ -90,8 +90,8 @@
       """
       Return mapping from gene IDs to their indexed GFF filename.
       """
  -    print "Mapping genes to their indexed GFF representation, using %s" \
  -          %(indexed_gff_dir)
  +    print("Mapping genes to their indexed GFF representation, using %s" \
  +          %(indexed_gff_dir))
       gff_chrom_dirs = os.listdir(indexed_gff_dir)

       # Load gene IDs to mapping from .shelve file
  @@ -111,7 +111,7 @@

           # Skip subentries that are not directories
           if not os.path.isdir(chrom_dir_path):
  -            print "Skipping: %s" %(chrom_dir_path)
  +            print("Skipping: %s" %(chrom_dir_path))
               continue

           # Get the chromosome filename
  @@ -123,9 +123,9 @@
           num_genes = len(chrom_indexed_filenames)
           if num_genes > 1:
               # Handle genes case
  -            print "Loading indexed gene filenames from: %s" \
  -                  %(chrom_dir_path)
  -            print "  - Loading %d genes" %(num_genes)
  +            print("Loading indexed gene filenames from: %s" \
  +                  %(chrom_dir_path))
  +            print("  - Loading %d genes" %(num_genes))

               for gene_index_filename in chrom_indexed_filenames:
                   # Skip non-Pickle files
  @@ -136,10 +136,10 @@
                                                                      gene_index_filename))
                   indexed_gene = load_indexed_gff_chrom(gene_index_filename)

  -                for gene_id, gene_info in indexed_gene.iteritems():
  +                for gene_id, gene_info in indexed_gene.items():
                       gene_ids_to_gff_index[gene_id] = gene_index_filename
           elif num_genes == 0:
  -            raise Exception, "No genes in directory: %s" %(chrom_dir_path)
  +            raise Exception("No genes in directory: %s" %(chrom_dir_path))
           else:
               chrom_indexed_filename = os.path.join(chrom_dir_path,
                                                     chrom_indexed_filenames[0])
  @@ -147,7 +147,7 @@
               # Load the indexed chromosome GFF file
               indexed_gff_chrom = load_indexed_gff_chrom(chrom_indexed_filename)

  -            for gene_id, gene_info in indexed_gff_chrom.iteritems():
  +            for gene_id, gene_info in indexed_gff_chrom.items():
                   gene_ids_to_gff_index[gene_id] = chrom_indexed_filename

       return gene_ids_to_gff_index
  @@ -276,8 +276,8 @@

               if len(mRNAs) == len(exons) == len(cdss) == 0:
                   if not self.suppress_warnings:
  -                    print "WARNING: No entries found for gene %s in GFF %s" \
  -                          %(gene, self.from_filename)
  +                    print("WARNING: No entries found for gene %s in GFF %s" \
  +                          %(gene, self.from_filename))
                   # Remove from gene hierarchy
                   del gene_hierarchy[gene]
   #               raise Exception, "No entries found for gene %s in GFF: %s" %(gene,
  @@ -298,14 +298,14 @@
           recs, hierarchy = self.get_genes_records(genes)
           # retrieve the records corresponding to the genes
           if len(recs) == 0:
  -            raise Exception, "No entries found for " + str(genes) + " in GFF: %s" %(filename)
  +            raise Exception("No entries found for " + str(genes) + " in GFF: %s" %(filename))
           # serialize them as GFF
           output_file = open(filename, 'w')
  -        print >> sys.stderr, "Outputting sliced GFF records to: %s" %(filename)
  +        print("Outputting sliced GFF records to: %s" %(filename), file=sys.stderr)
           gff_writer = Writer(output_file)
           gff_writer.write_recs(recs)

  -    def next(self):
  +    def __next__(self):
           if self.__entries == []:
               raise StopIteration
           return self.__entries.pop()
  @@ -348,8 +348,8 @@
           if self.start > self.end:
               self.start, self.end = self.end, self.start
               if strand != '-':
  -                print >>sys.stderr, "WARNING: Swapping start and end fields, which must satisfy start <= end:"
  -                print >>sys.stderr, self.__repr__()
  +                print("WARNING: Swapping start and end fields, which must satisfy start <= end:", file=sys.stderr)
  +                print(self.__repr__(), file=sys.stderr)

           # set default exon IDs if they are not already set
           self._set_default_exon_id()
  @@ -394,7 +394,7 @@
           """Returns a copy of this GFF record"""

           # Make new attributes dict with copied value lists
  -        attributes_copy = dict([(k, v[:]) for k, v in self.attributes.items()])
  +        attributes_copy = dict([(k, v[:]) for k, v in list(self.attributes.items())])

           return GFF(self.seqid,
                         self.source,
  @@ -533,7 +533,7 @@

           #  Set default record parser
           if version not in self._record_parsers:
  -            raise Exception, "Unrecognized GFF default version: " + version
  +            raise Exception("Unrecognized GFF default version: " + version)
           self._record_parser = self._record_parsers[version]

           # Stage next record so that we read all metadata at top of file
  @@ -572,7 +572,7 @@
       def read(self):
           """Returns the next record or None if there are none left."""
           try:
  -            return self.next()
  +            return next(self)
           except StopIteration:
               return None

  @@ -586,7 +586,7 @@
       def __iter__(self):
           return self

  -    def next(self):
  +    def __next__(self):
           self._stage_rec()
           if self._next_rec is None:
               raise StopIteration
  @@ -622,8 +622,8 @@
               self._record_parser = self._record_parsers[self._version]
           except KeyError:
               self._record_parser = self._record_parsers[self._default_version]
  -            print >>sys.stderr, "Warning: Unrecognized GFF version (%s). " + \
  -                "Using default version %s %s." % (self._version, self._default_version)
  +            print("Warning: Unrecognized GFF version (%s). " + \
  +                "Using default version %s %s." % (self._version, self._default_version), file=sys.stderr)

       def _parse_directive(self, line):
           tokens = line[2:-1].split(None, 1)
  @@ -669,7 +669,7 @@
           elif len(fields) == 9:
               attributes = {"group": [fields[8]]}
           else:
  -            raise FormatError, "Invalid number of fields (should be 8 or 9):\n" + line
  +            raise FormatError("Invalid number of fields (should be 8 or 9):\n" + line)

           try:
               return GFF(seqid=fields[0],
  @@ -681,8 +681,8 @@
                             strand=parse_maybe_empty(fields[6]),
                             phase=parse_maybe_empty(fields[7], int),
                             attributes=attributes)
  -        except ValueError, e:
  -            raise FormatError, "GFF field format error: " + e.message
  +        except ValueError as e:
  +            raise FormatError("GFF field format error: " + e.message)

       def _parse_record_v2(self, line):
           fields = line[:-1].split('\t', 8)
  @@ -692,7 +692,7 @@
           elif len(fields) == 9:
               attributes_string = fields[8]
           else:
  -            raise FormatError, "Invalid number of fields (should be 8 or 9):\n" + line
  +            raise FormatError("Invalid number of fields (should be 8 or 9):\n" + line)

           try:
               return GFF(seqid=fields[0],
  @@ -704,8 +704,8 @@
                             strand=parse_maybe_empty(fields[6]),
                             phase=parse_maybe_empty(fields[7], int),
                             attributes=self._parse_attributes_v2(attributes_string))
  -        except ValueError, e:
  -            raise FormatError, "GFF field format error: " + e.message
  +        except ValueError as e:
  +            raise FormatError("GFF field format error: " + e.message)

       def _parse_record_v3(self, line):
           self._references_resolved = False
  @@ -716,7 +716,7 @@
           fields = line.split('\t')

           if len(fields) != 9:
  -            raise FormatError, "Invalid number of fields (should be 9):\n" + line
  +            raise FormatError("Invalid number of fields (should be 9):\n" + line)

           try:
               return GFF(seqid=url_unquote(fields[0]),
  @@ -728,8 +728,8 @@
                             strand=parse_maybe_empty(fields[6]),
                             phase=parse_maybe_empty(fields[7], int),
                             attributes=self._parse_attributes_v3(fields[8]))
  -        except ValueError, e:
  -            raise FormatError, "GFF field format error: " + e.message
  +        except ValueError as e:
  +            raise FormatError("GFF field format error: " + e.message)

       def _parse_attributes_v3(self, s):
           attributes = {}
  @@ -739,10 +739,10 @@
                   continue
               try:
                   tag, value = pair_string.split("=")
  -                attributes[url_unquote(tag)] = map(url_unquote,
  -                                                   value.split(","))
  +                attributes[url_unquote(tag)] = list(map(url_unquote,
  +                                                   value.split(",")))
               except ValueError:
  -                print >>sys.stderr, "WARNING: Invalid attributes string: ", s
  +                print("WARNING: Invalid attributes string: ", s, file=sys.stderr)
   #                raise FormatError("Invalid attributes string: " + s)
           return attributes

  @@ -755,7 +755,7 @@
                       currentTag = token.value
                       attributes[currentTag] = []
                   else:
  -                    raise FormatError, "Invalid attributes string: " + s
  +                    raise FormatError("Invalid attributes string: " + s)
               elif isinstance(token, SeparatorToken):
                   currentTag = None
               elif isinstance(token, CommentToken):
  @@ -765,7 +765,7 @@
               elif isinstance(token, ValueToken):
                   attributes[currentTag].append(token.value)
               else:
  -                raise FormatError, "Invalid attributes string: " + s
  +                raise FormatError("Invalid attributes string: " + s)
           return attributes

   class IdentifierToken:
  @@ -797,7 +797,7 @@
       def __iter__(self):
           return self

  -    def next(self):
  +    def __next__(self):
           if self.pos >= len(self.s):
               raise StopIteration

  @@ -814,7 +814,7 @@

   def is_integer(x):
       """Returns true if x is of integer type (int or long)."""
  -    return type(x) in (int, long)
  +    return type(x) in (int, int)

   def parse_maybe_empty(s, parse_type=str):
       if s == '.':
  @@ -862,7 +862,7 @@
               self.version = version
               self.write_metadatum(Metadatum("gff-version", version))
           except KeyError:
  -            raise Exception, "Unrecognized GFF version: " + version
  +            raise Exception("Unrecognized GFF version: " + version)

           for metadatum in metadata:
               self.write_metadatum(metadatum)
  @@ -870,13 +870,13 @@
       def write_metadatum(self, metadatum):
           """Writes a metadatum line."""
           if metadatum.value is not None:
  -            print >>self.stream, "##%s %s" % (metadatum.name, metadatum.value)
  +            print("##%s %s" % (metadatum.name, metadatum.value), file=self.stream)
           else:
  -            print >>self.stream, "##%s" % metadatum.name
  +            print("##%s" % metadatum.name, file=self.stream)

       def write_comment(self, comment):
           """Writes a comment line."""
  -        print >>self.stream, "#%s" % comment
  +        print("#%s" % comment, file=self.stream)

       def write(self, rec):
           """Writes a single record."""
  @@ -898,7 +898,7 @@
                     format_maybe_empty(rec.phase)]
           if rec.attributes.get('group') is not None:
               fields.append(rec.attributes['group'][0])
  -        print >>self.stream, '\t'.join(fields)
  +        print('\t'.join(fields), file=self.stream)

       def _write_rec_v2(self, rec):
           fields = [rec.seqid,
  @@ -911,7 +911,7 @@
                     format_maybe_empty(rec.phase)]
           if rec.attributes:
               fields.append(self._format_attributes_v2(rec.attributes))
  -        print >>self.stream, '\t'.join(fields)
  +        print('\t'.join(fields), file=self.stream)

       def _write_rec_v3(self, rec):
           _type_pat.sub(url_quote, rec.type)
  @@ -924,7 +924,7 @@
                     format_maybe_empty(rec.strand),
                     format_maybe_empty(rec.phase),
                     format_maybe_empty(self._format_attributes_v3(rec.attributes))]
  -        print >>self.stream, '\t'.join(fields)
  +        print('\t'.join(fields), file=self.stream)

       def _write_rec_gtf(self, rec):
           # The required GTF attributes
  @@ -945,11 +945,11 @@
           return ';'.join(["%s=%s" % (_tag_pat.sub(url_quote_sub, tag),
                                       ','.join([_value_pat.sub(url_quote_sub, value)
                                                 for value in values]))
  -                         for tag, values in attributes.items()])
  +                         for tag, values in list(attributes.items())])

       def _format_attributes_v2(self, attributes):
  -        return ' '.join([' '.join([tag] + map(quote, values)) + ";"
  -                          for tag, values in attributes.items()])
  +        return ' '.join([' '.join([tag] + list(map(quote, values))) + ";"
  +                          for tag, values in list(attributes.items())])


   def get_inclusive_txn_bounds(gene_hierarchy):
  @@ -962,7 +962,7 @@

       strand = None

  -    for mRNA_id, mRNA_info in gene_hierarchy['mRNAs'].iteritems():
  +    for mRNA_id, mRNA_info in gene_hierarchy['mRNAs'].items():
           mRNA_rec = mRNA_info["record"]
           strand = mRNA_rec.strand

  RefactoringTool: Refactored src/MISO/misopy/hypothesis_test.py
  --- src/MISO/misopy/hypothesis_test.py	(original)
  +++ src/MISO/misopy/hypothesis_test.py	(refactored)
  @@ -56,8 +56,7 @@
           elif self.covfact:
               return float(self.covfact)
           else:
  -            raise ValueError, \
  -                'covariance factor has to be scotts, silverman or a number'
  +            raise ValueError('covariance factor has to be scotts, silverman or a number')

       def reset_covfact(self, covfact):
           self.covfact = covfact
  @@ -103,7 +102,7 @@
       densities = {}
       # Compute analytic prior density
       prior_density_fn = lambda x: 1 + x if x <= 0 else 1 - x
  -    analytic_prior_density = map(prior_density_fn, diff_range)
  +    analytic_prior_density = list(map(prior_density_fn, diff_range))
       posterior_samples1 = samples1_results[0]
       posterior_samples2 = samples2_results[0]

  @@ -155,10 +154,10 @@
           all_same_diff = all(posterior_diff - posterior_diff[0] == 0)

           if all_same_diff and not warning_outputted:
  -            print "Warning: Event %s was not sampled properly in %s or %s" \
  +            print("Warning: Event %s was not sampled properly in %s or %s" \
                     %(event_name,
                       sample1_label,
  -                    sample2_label)
  +                    sample2_label))
               warning_outputted = True

           if mean_abs_posterior_diff <= .009 or all_same_diff:
  @@ -190,16 +189,16 @@
       Expects two directories with samples from a MISO run, where corresponding
       events in the two samples' directories begin with the same event name.
       """
  -    print "Given output dir: %s" %(output_dir)
  -    print "Retrieving MISO files in sample directories..."
  +    print("Given output dir: %s" %(output_dir))
  +    print("Retrieving MISO files in sample directories...")
       sample1_obj = MISOSamples(sample1_dir,
                                 use_compressed=use_compressed)
       sample2_obj = MISOSamples(sample2_dir,
                                 use_compressed=use_compressed)
  -    print "Computing sample comparison between %s and %s..." %(sample1_dir,
  -                                                               sample2_dir)
  -    print "  - No. of events in %s: %d" %(sample1_dir, sample1_obj.num_events)
  -    print "  - No. of events in %s: %d" %(sample2_dir, sample2_obj.num_events)
  +    print("Computing sample comparison between %s and %s..." %(sample1_dir,
  +                                                               sample2_dir))
  +    print("  - No. of events in %s: %d" %(sample1_dir, sample1_obj.num_events))
  +    print("  - No. of events in %s: %d" %(sample2_dir, sample2_obj.num_events))
       # Output header for Bayes factor file
       if sample_labels is None:
           # Use directory names as sample labels
  @@ -208,11 +207,11 @@
       else:
           # If we're given sample labels, use them
           sample1_label, sample2_label = sample_labels
  -        print "Using user-given sample labels (sample1 = %s, sample2 = %s)" \
  -              %(sample1_label, sample2_label)
  +        print("Using user-given sample labels (sample1 = %s, sample2 = %s)" \
  +              %(sample1_label, sample2_label))
       output_dir = os.path.join(output_dir, "%s_vs_%s" %(sample1_label,
                                                          sample2_label))
  -    print "Creating comparisons parent directory: %s" %(output_dir)
  +    print("Creating comparisons parent directory: %s" %(output_dir))
       # Create parent directory for comparison
       misc_utils.make_dir(output_dir)

  @@ -341,7 +340,7 @@
                            gene_info["mRNA_ends"]]
           output_line = "%s\n" %("\t".join(output_fields))
           output_file.write(output_line)
  -    print "Compared a total of %d events." %(num_events_compared)
  +    print("Compared a total of %d events." %(num_events_compared))
       output_file.close()


  @@ -370,8 +369,8 @@
           bayes_factor = bayes_factor[0]

       if print_bayes:
  -        print "diff_posterior: %.4f" %(diff_posterior)
  -        print "bayes_factor: %.2f" %(bayes_factor)
  +        print("diff_posterior: %.4f" %(diff_posterior))
  +        print("bayes_factor: %.2f" %(bayes_factor))

       # Upper bound on Bayes factor
       if bayes_factor > max_bf:
  RefactoringTool: Refactored src/MISO/misopy/index_gff.py
  --- src/MISO/misopy/index_gff.py	(original)
  +++ src/MISO/misopy/index_gff.py	(refactored)
  @@ -44,7 +44,7 @@
       genes_by_chrom = defaultdict(dict)

       # Split up genes by chromosome
  -    for gene_id, gene_info in gff_genes.iteritems():
  +    for gene_id, gene_info in gff_genes.items():
           gene_obj = gene_info["gene_object"]
           gene_hierarchy = gene_info["hierarchy"]
           genes_by_chrom[gene_obj.chrom][gene_id] = \
  @@ -63,7 +63,7 @@

       # Serialize all the genes in each chromosome into their
       # own directory
  -    for chrom, chrom_genes in genes_by_chrom.iteritems():
  +    for chrom, chrom_genes in genes_by_chrom.items():
           if chrom.startswith("chr"):
               chrom_dir_name = chrom
           else:
  @@ -74,14 +74,14 @@
           # Make directory for chromosome if it doesn't already exist
           chrom_dir = os.path.join(output_dir, chrom_dir_name)
           if not os.path.isdir(chrom_dir):
  -            print "Making directory: %s" %(chrom_dir)
  +            print("Making directory: %s" %(chrom_dir))
               os.makedirs(chrom_dir)

           t1 = time.time()
           # Serialize each gene into a separate file
           num_genes = len(genes_by_chrom[chrom])

  -        for gene_id, gene_info in genes_by_chrom[chrom].iteritems():
  +        for gene_id, gene_info in genes_by_chrom[chrom].items():
               gene_compressed_id = None
               if compress_id:
                   gene_compressed_id = \
  @@ -105,13 +105,13 @@
                   compressed_id_to_gene_id[gene_compressed_id] = gene_id

           t2 = time.time()
  -        print "  - Chromosome serialization took %.2f seconds" %(t2 - t1)
  +        print("  - Chromosome serialization took %.2f seconds" %(t2 - t1))

       # Shelve the mapping from gene ids to filenames
       shelved_filename = os.path.join(output_dir,
                                       "genes_to_filenames.shelve")
       shelved_data = shelve.open(shelved_filename)
  -    for k, v in gene_id_to_filename.iteritems():
  +    for k, v in gene_id_to_filename.items():
           shelved_data[k] = v
       shelved_data.close()

  @@ -119,14 +119,14 @@
       shelved_filename = os.path.join(output_dir,
                                       "compressed_ids_to_genes.shelve")
       shelved_data = shelve.open(shelved_filename)
  -    for k, v in compressed_id_to_gene_id.iteritems():
  +    for k, v in compressed_id_to_gene_id.items():
           shelved_data[k] = v
       shelved_data.close()

       # Output a list of genes in ordinary GFF format
       genes_filename = os.path.join(output_dir, "genes.gff")
  -    print "Outputting gene records in GFF format..."
  -    print "  - Output file: %s" %(genes_filename)
  +    print("Outputting gene records in GFF format...")
  +    print("  - Output file: %s" %(genes_filename))
       with open(gff_filename) as gff_in:
           with open(genes_filename, "w") as gff_out:
               for line in gff_in:
  @@ -142,23 +142,23 @@
       Index the given GFF and placed the indexed representation
       in the output directory.
       """
  RefactoringTool: Refactored src/MISO/misopy/json_utils.py
  -    print "Indexing GFF..."
  +    print("Indexing GFF...")
       if compress_id:
  -        print "  - Using compressed IDs to create indexed filenames."
  +        print("  - Using compressed IDs to create indexed filenames.")
       # First check that the GFF is not already indexed
       indexed_files = glob.glob(os.path.join(output_dir, "chr*"))
       if len(indexed_files) >= 1:
  -        print "%s appears to already be indexed. Aborting." \
  -            %(gff_filename)
  +        print("%s appears to already be indexed. Aborting." \
  +            %(gff_filename))
           return

  -    print "  - GFF: %s" %(gff_filename)
  -    print "  - Outputting to: %s" %(output_dir)
  +    print("  - GFF: %s" %(gff_filename))
  +    print("  - Outputting to: %s" %(output_dir))
       overall_t1 = time.time()
       t1 = time.time()
       gff_genes = gene_utils.load_genes_from_gff(gff_filename)
       t2 = time.time()
  -    print "  - Loading of genes from GFF took %.2f seconds" %(t2 - t1)
  +    print("  - Loading of genes from GFF took %.2f seconds" %(t2 - t1))

       t1 = time.time()
       serialize_genes(gff_genes,
  @@ -166,9 +166,9 @@
                       output_dir,
                       compress_id=compress_id)
       t2 = time.time()
  -    print "  - Serialization of genes from GFF took %.2f seconds" %(t2 - t1)
  +    print("  - Serialization of genes from GFF took %.2f seconds" %(t2 - t1))
       overall_t2 = time.time()
  -    print "Indexing of GFF took %.2f seconds." %(overall_t2 - overall_t1)
  +    print("Indexing of GFF took %.2f seconds." %(overall_t2 - overall_t1))


   def main():
  @@ -195,9 +195,9 @@
           index_gff(gff_filename, output_dir,
                     compress_id=options.compress_id)
       else:
  -        print "Indexer of GFF files for use with MISO."
  -        print "Need to pass --index, for example:\n"
  -        print "index_gff --index annotation.gff indexed_annotation/"
  +        print("Indexer of GFF files for use with MISO.")
  +        print("Need to pass --index, for example:\n")
  +        print("index_gff --index annotation.gff indexed_annotation/")


   if __name__ == '__main__':
  --- src/MISO/misopy/json_utils.py	(original)
  +++ src/MISO/misopy/json_utils.py	(refactored)
  @@ -9,7 +9,7 @@

   def json_load_file(filename):
       if os.path.isdir(filename):
  -        raise Exception, "%s is a directory -- expected a JSON filename." %(filename)
  +        raise Exception("%s is a directory -- expected a JSON filename." %(filename))
       f = open(filename)
       obj = json.load(f)
       return obj
  RefactoringTool: Refactored src/MISO/misopy/kde_subclass.py
  --- src/MISO/misopy/kde_subclass.py	(original)
  +++ src/MISO/misopy/kde_subclass.py	(refactored)
  @@ -44,8 +44,7 @@
           elif self.covfact:
               return float(self.covfact)
           else:
  -            raise ValueError, \
  -                'covariance factor has to be scotts, silverman or a number'
  +            raise ValueError('covariance factor has to be scotts, silverman or a number')

       def reset_covfact(self, covfact):
           self.covfact = covfact
  @@ -75,7 +74,7 @@
       xn = np.random.randn(n_basesample)
       xnmean = xn.mean()
       xnstd = xn.std(ddof=1)
  -    print xnmean, xnstd
  +    print(xnmean, xnstd)

       # get kde for original sample
       gkde = stats.gaussian_kde(xn)
  @@ -84,16 +83,16 @@
       xs = np.linspace(-7,7,501)
       kdepdf = gkde.evaluate(xs)
       normpdf = stats.norm.pdf(xs, loc=xnmean, scale=xnstd)
  -    print 'MSE', np.sum((kdepdf - normpdf)**2)
  -    print 'axabserror', np.max(np.abs(kdepdf - normpdf))
  +    print('MSE', np.sum((kdepdf - normpdf)**2))
  +    print('axabserror', np.max(np.abs(kdepdf - normpdf)))
       intervall = xs[1] - xs[0]
       assert_(np.sum((kdepdf - normpdf)**2)*intervall < 0.01)
       #assert_array_almost_equal(kdepdf, normpdf, decimal=2)
  -    print gkde.integrate_gaussian(0.0, 1.0)
  -    print gkde.integrate_box_1d(-np.inf, 0.0)
  -    print gkde.integrate_box_1d(0.0, np.inf)
  -    print gkde.integrate_box_1d(-np.inf, xnmean)
  -    print gkde.integrate_box_1d(xnmean, np.inf)
  +    print(gkde.integrate_gaussian(0.0, 1.0))
  +    print(gkde.integrate_box_1d(-np.inf, 0.0))
  +    print(gkde.integrate_box_1d(0.0, np.inf))
  +    print(gkde.integrate_box_1d(-np.inf, xnmean))
  +    print(gkde.integrate_box_1d(xnmean, np.inf))

       assert_almost_equal(gkde.integrate_box_1d(xnmean, np.inf), 0.5, decimal=1)
       assert_almost_equal(gkde.integrate_box_1d(-np.inf, xnmean), 0.5, decimal=1)
  RefactoringTool: Refactored src/MISO/misopy/legacy_test_pysplicing.py
  --- src/MISO/misopy/legacy_test_pysplicing.py	(original)
  +++ src/MISO/misopy/legacy_test_pysplicing.py	(refactored)
  @@ -12,13 +12,13 @@
   pysplicing.noIso(gene)
   pysplicing.isoLength(gene)

  -reads = pysplicing.simulateReads(gene, 0L, (0.2,0.3,0.5), 2000L, 33L)
  +reads = pysplicing.simulateReads(gene, 0, (0.2,0.3,0.5), 2000, 33)

   # Load BAM file


  -print reads[1], type(reads[1])
  -results = pysplicing.MISO(gene, 0L, reads[1], reads[2], 33L, 5000L, 500L, 10L,
  +print(reads[1], type(reads[1]))
  +results = pysplicing.MISO(gene, 0, reads[1], reads[2], 33, 5000, 500, 10,
                             (1.0, 1.0, 1.0))


  RefactoringTool: Refactored src/MISO/misopy/misc_utils.py
  --- src/MISO/misopy/misc_utils.py	(original)
  +++ src/MISO/misopy/misc_utils.py	(refactored)
  @@ -35,8 +35,8 @@
       Load mapping from compressed IDs to genes.
       """
       if not os.path.exists(compressed_filename):
  -        print "Error: %s compressed file does not exist." \
  -              %(compressed_filename)
  +        print("Error: %s compressed file does not exist." \
  +              %(compressed_filename))
           sys.exit(1)
       compressed_ids_to_genes = {}
       # Load mapping from gene IDs to their hashes
  @@ -61,7 +61,7 @@

   def make_dir(dirpath):
       if os.path.isfile(dirpath):
  -        print "Error: %s is a file!" %(dirpath)
  +        print("Error: %s is a file!" %(dirpath))
           sys.exit(1)
       # Try to make the directory
       try:
  @@ -84,10 +84,10 @@
           elif not os.access(fpath, os.X_OK):
               # If the file exists but is not executable, warn
               # the user
  -            print "WARNING: Found %s but it is not executable." %(fpath)
  -            print "Please ensure %s is executable." %(fpath)
  -            print "On Unix, use something like: "
  -            print "  chmod +x %s" %(fpath)
  +            print("WARNING: Found %s but it is not executable." %(fpath))
  +            print("Please ensure %s is executable." %(fpath))
  +            print("On Unix, use something like: ")
  +            print("  chmod +x %s" %(fpath))
               time.sleep(10)
               return False
           return True
  RefactoringTool: Refactored src/MISO/misopy/miso.py
  --- src/MISO/misopy/miso.py	(original)
  +++ src/MISO/misopy/miso.py	(refactored)
  @@ -59,10 +59,10 @@


   def greeting(parser=None):
  -    print "MISO (Mixture of Isoforms model)"
  -    print "Probabilistic analysis of RNA-Seq data for detecting " \
  -          "differential isoforms"
  -    print "Use --help argument to view options.\n"
  +    print("MISO (Mixture of Isoforms model)")
  +    print("Probabilistic analysis of RNA-Seq data for detecting " \
  +          "differential isoforms")
  +    print("Use --help argument to view options.\n")
       if parser is not None:
           parser.print_help()

  @@ -142,7 +142,7 @@
           if gene_ids is not None:
               self.gene_ids = gene_ids
           else:
  -            self.gene_ids = self.gene_ids_to_gff_index.keys()
  +            self.gene_ids = list(self.gene_ids_to_gff_index.keys())
           if len(self.gene_ids) == 0:
               self.main_logger.error("No genes to run on. Did you pass me the wrong path " \
                                      "to your index GFF directory? " \
  @@ -178,7 +178,7 @@
                       if gene_id not in self.gene_ids_to_gff_index:
                           # If gene is not found (perhaps because it had only a 'gene'
                           # entry in GFF, with no mRNA children), then skip it
  -                        print "Skipping: %s" %(gene_id)
  +                        print("Skipping: %s" %(gene_id))
                           continue
                       index_fname = self.gene_ids_to_gff_index[gene_id]
                       output_line = "%s\t%s\n" %(gene_id,
  @@ -201,7 +201,7 @@
           ##
           ## Prepare all the files necessary to run each batch
           ##
  -        print "Preparing to run %d batches of jobs..." %(num_batches)
  +        print("Preparing to run %d batches of jobs..." %(num_batches))
           miso_run = os.path.join(miso_path, "run_miso.py")
           for batch_num, batch in enumerate(batch_filenames):
               batch_filename, batch_size = batch
  @@ -233,7 +233,7 @@
           ##
           # First handle special case of SGE cluster submission
           if self.use_cluster and self.SGEarray:
  -            print "Using SGEarray..."
  +            print("Using SGEarray...")
               # Call SGE
               batch_argfile = os.path.join(self.cluster_scripts_dir,
                                            "run_args.txt")
  @@ -249,8 +249,8 @@
           cluster_jobs = []
           for batch_num, cmd_info in enumerate(all_miso_cmds):
               miso_cmd, batch_size = cmd_info
  -            print "Running batch of %d genes.." %(batch_size)
  -            print "  - Executing: %s" %(miso_cmd)
  +            print("Running batch of %d genes.." %(batch_size))
  +            print("  - Executing: %s" %(miso_cmd))
               # Make a log file for the batch, where all the output
               # will be redirected
               time_str = time.strftime("%m-%d-%y_%H:%M:%S")
  @@ -262,7 +262,7 @@
                   # Run locally
                   p = subprocess.Popen(cmd_to_run, shell=True)
                   thread_id = "batch-%d" %(batch_num)
  -                print "  - Submitted thread %s" %(thread_id)
  +                print("  - Submitted thread %s" %(thread_id))
                   self.threads[thread_id] = p
               else:
                   # Run on cluster
  @@ -272,7 +272,7 @@
                       queue_type = "short"
                   # Run on cluster
                   job_name = "gene_psi_batch_%d" %(batch_num)
  -                print "Submitting to cluster: %s" %(cmd_to_run)
  +                print("Submitting to cluster: %s" %(cmd_to_run))
                   job_id = \
                       cluster_utils.run_on_cluster(cmd_to_run,
                                                    job_name,
  @@ -318,7 +318,7 @@
           num_threads = len(self.threads)
           if num_threads == 0:
               return
  -        print "Waiting on %d threads..." %(num_threads)
  +        print("Waiting on %d threads..." %(num_threads))
           t_start = time.time()
           for thread_name in self.threads:
               if thread_name in threads_completed:
  @@ -359,11 +359,11 @@
         Uses bedtools to determine coverage of each event and remove
         events that do not meet the coverage criteria from the run.
       """
  -    print "Computing Psi values..."
  -    print "  - GFF index: %s" %(gff_dir)
  -    print "  - BAM: %s" %(bam_filename)
  -    print "  - Read length: %d" %(read_len)
  -    print "  - Output directory: %s" %(output_dir)
  +    print("Computing Psi values...")
  +    print("  - GFF index: %s" %(gff_dir))
  +    print("  - BAM: %s" %(bam_filename))
  +    print("  - Read length: %d" %(read_len))
  +    print("  - Output directory: %s" %(output_dir))

       misc_utils.make_dir(output_dir)

  @@ -513,15 +513,15 @@
       greeting()

       if options.version:
  -        print "MISO version %s\n" %(misopy.__version__)
  +        print("MISO version %s\n" %(misopy.__version__))

       ##
       ## Load the settings file
       ##
       if not os.path.isdir(miso_settings_path):
  -        print "Error: %s is not a directory containing a default MISO " \
  +        print("Error: %s is not a directory containing a default MISO " \
                 "settings filename. Please specify a settings filename " \
  -              "using --settings-filename."
  +              "using --settings-filename.")
           return

       settings_filename = \
  @@ -529,12 +529,12 @@
       Settings.load(settings_filename)

       if (not options.use_cluster) and options.chunk_jobs:
  -        print "Error: Chunking jobs only applies when using " \
  -              "the --use-cluster option to run MISO on cluster."
  +        print("Error: Chunking jobs only applies when using " \
  +              "the --use-cluster option to run MISO on cluster.")
           sys.exit(1)
       if (not options.use_cluster) and options.SGEarray:
  -        print "Error: SGEarray implies that you are using an SGE cluster," \
  -              "please run again with --use-cluster option enabled."
  +        print("Error: SGEarray implies that you are using an SGE cluster," \
  +              "please run again with --use-cluster option enabled.")
           sys.exit(1)

       ##
  @@ -550,7 +550,7 @@
               os.path.abspath(os.path.expanduser(options.compute_genes_psi[1]))

           if options.output_dir == None:
  -            print "Error: need --output-dir to compute Psi values."
  +            print("Error: need --output-dir to compute Psi values.")
               sys.exit(1)

           # Output directory to use
  @@ -593,29 +593,29 @@
       if options.view_gene != None:
           indexed_gene_filename = \
               os.path.abspath(os.path.expanduser(options.view_gene))
  -        print "Viewing genes in %s" %(indexed_gene_filename)
  +        print("Viewing genes in %s" %(indexed_gene_filename))
           gff_genes = gff_utils.load_indexed_gff_file(indexed_gene_filename)

           if gff_genes == None:
  -            print "No genes."
  +            print("No genes.")
               sys.exit(1)

  -        for gene_id, gene_info in gff_genes.iteritems():
  -            print "Gene %s" %(gene_id)
  +        for gene_id, gene_info in gff_genes.items():
  +            print("Gene %s" %(gene_id))
               gene_obj = gene_info['gene_object']
  -            print " - Gene object: ", gene_obj
  -            print "=="
  -            print "Isoforms: "
  +            print(" - Gene object: ", gene_obj)
  +            print("==")
  +            print("Isoforms: ")
               for isoform in gene_obj.isoforms:
  -                print " - ", isoform
  -            print "=="
  -            print "mRNA IDs: "
  +                print(" - ", isoform)
  +            print("==")
  +            print("mRNA IDs: ")
               for mRNA_id in gene_info['hierarchy'][gene_id]['mRNAs']:
  -                print "%s" %(mRNA_id)
  -            print "=="
  -            print "Exons: "
  +                print("%s" %(mRNA_id))
  +            print("==")
  +            print("Exons: ")
               for exon in gene_obj.parts:
  -                print " - ", exon
  +                print(" - ", exon)

   if __name__ == "__main__":
       main()
  RefactoringTool: Refactored src/MISO/misopy/miso_db.py
  --- src/MISO/misopy/miso_db.py	(original)
  +++ src/MISO/misopy/miso_db.py	(refactored)
  @@ -10,7 +10,7 @@
   import shutil
   import fnmatch
   import glob
  -import StringIO
  +import io

   import misopy
   import misopy.misc_utils as misc_utils
  @@ -33,15 +33,15 @@
               # Make mapping from uncompressed to compressed IDs
               self.uncomp_to_comp = misc_utils.inv_dict(self.comp_to_uncomp)
           if not os.path.isfile(db_fname):
  -            raise Exception, "%s does not exist." %(db_fname)
  +            raise Exception("%s does not exist." %(db_fname))
           self.db_fname = db_fname
           # Create table names that start with 'table_' to properly handle
           # Ensembl headers, which are numeric only and tables cannot
           # be named numerically.
           self.table_name = "table_%s" %(get_table_name_from_file(self.db_fname))
           if self.table_name is None:
  -            print "Error: Cannot retrieve name of MISO db file %s" \
  -                  %(self.db_fname)
  +            print("Error: Cannot retrieve name of MISO db file %s" \
  +                  %(self.db_fname))
               return None
           self.conn = sqlite3.connect(self.db_fname)
           # Determine event name format
  @@ -73,8 +73,8 @@
           # given a mapping, this is a major error
           if self.is_db_events_compressed and \
              ((self.comp_to_uncomp is None) or (self.uncomp_to_comp is None)):
  -            raise Exception, "The database contains compressed IDs but no " \
  -                             "mapping (.shelve) file was given."
  +            raise Exception("The database contains compressed IDs but no " \
  +                             "mapping (.shelve) file was given.")
           # If we have a compressed event representation in database and
           # the event given is uncompressed, then look at the
           # compressed representation
  @@ -90,8 +90,8 @@
               # If there's no compressed mapping, we can't
               # use this event
               if self.comp_to_uncomp is None:
  -                raise Exception, "Cannot get compressed event %s from " \
  -                                 "uncompressed database." %(event_name)
  +                raise Exception("Cannot get compressed event %s from " \
  +                                 "uncompressed database." %(event_name))
               if event_name not in self.comp_to_uncomp:
                   return None
               event_to_query = self.comp_to_uncomp[event_name]
  @@ -105,15 +105,14 @@
               # Event not found
               return None
           if len(rows) > 1:
  -            raise Exception, \
  -              "More than one entry for event %s" %(event_to_query)
  +            raise Exception("More than one entry for event %s" %(event_to_query))
           event_name, psi_vals_and_scores, header = rows[0]
           # If we're given a mapping to compressed events,
           # return the event name as the *uncompressed* event
           # name
           event_data = "%s\n%s\n" %(header,
                                     psi_vals_and_scores)
  -        event_stream = StringIO.StringIO(event_data)
  +        event_stream = io.StringIO(event_data)
           return event_stream


  @@ -145,19 +144,19 @@
       """
       Convert MISO directory into MySQL table using sqlite3.
       """
  -    print "Converting MISO directory into database"
  -    print "  - MISO dir: %s" %(dir_to_compress)
  -    print "  - Output file: %s" %(output_filename)
  +    print("Converting MISO directory into database")
  +    print("  - MISO dir: %s" %(dir_to_compress))
  +    print("  - Output file: %s" %(output_filename))
       if not os.path.isdir(dir_to_compress):
  -        print "Error: %s not a directory, aborting." %(dir_to_compress)
  +        print("Error: %s not a directory, aborting." %(dir_to_compress))
           sys.exit(1)
       miso_filenames = glob.glob(os.path.join(dir_to_compress, "*.miso"))
       num_files = len(miso_filenames)
  -    print "  - %d files to compress" %(num_files)
  +    print("  - %d files to compress" %(num_files))
       # Initialize the SQLite database
       if os.path.isfile(output_filename):
  -        print "Error: Database %s already exists, aborting." \
  -              %(output_filename)
  +        print("Error: Database %s already exists, aborting." \
  +              %(output_filename))
           return None
       conn = sqlite3.connect(output_filename)
       c = conn.cursor()
  @@ -170,7 +169,7 @@
       for miso_fname in miso_filenames:
           miso_file_fields = load_miso_file_as_str(miso_fname)
           if miso_file_fields is None:
  -            print "Error: Cannot compress %s. Aborting." %(miso_fname)
  +            print("Error: Cannot compress %s. Aborting." %(miso_fname))
               return None
           header, psi_vals_and_scores = miso_file_fields
           ######
  @@ -216,7 +215,7 @@
       into an sqlite database.
       """
       if not os.path.isfile(miso_filename):
  -        print "Error: Cannot find %s" %(miso_filename)
  +        print("Error: Cannot find %s" %(miso_filename))
           return None
       header = ""
       psi_vals_and_scores = ""
  RefactoringTool: Refactored src/MISO/misopy/miso_pack.py
  --- src/MISO/misopy/miso_pack.py	(original)
  +++ src/MISO/misopy/miso_pack.py	(refactored)
  @@ -49,9 +49,9 @@
           """
           t1 = time.time()
           for miso_dirname in miso_dirnames:
  -            print "Processing: %s" %(miso_dirname)
  +            print("Processing: %s" %(miso_dirname))
               if not os.path.isdir(miso_dirname):
  -                print "Error: %s not a directory." %(miso_dirname)
  +                print("Error: %s not a directory." %(miso_dirname))
                   sys.exit(1)
               for dir_to_compress, subdirs, curr_fnames in os.walk(miso_dirname):
                   if miso_db.is_miso_unpacked_dir(dir_to_compress):
  @@ -59,10 +59,10 @@
                       # into a MISO database
                       chrom_basename = os.path.basename(dir_to_compress)
                       if len(chrom_basename) == 0:
  -                        print "Error: Failed to pack MISO directory %s" \
  -                              %(miso_dirname)
  -                        raise Exception, "Basename for %s is empty!" \
  -                              %(dir_to_compress)
  +                        print("Error: Failed to pack MISO directory %s" \
  +                              %(miso_dirname))
  +                        raise Exception("Basename for %s is empty!" \
  +                              %(dir_to_compress))
                       db_fname = \
                         os.path.join(os.path.dirname(dir_to_compress),
                                      "%s%s" %(chrom_basename,
  @@ -75,15 +75,15 @@
                       # containing the *.miso file
                       shutil.rmtree(dir_to_compress)
           t2 = time.time()
  -        print "Packing took %.2f minutes" %((t2 - t1)/60.)
  +        print("Packing took %.2f minutes" %((t2 - t1)/60.))


   def greeting(parser=None):
  -    print "MISO (Mixture of Isoforms model)"
  -    print "Pack the MISO output into an SQL database."
  -    print "Use --help argument to view options.\n"
  -    print "Example usage:\n"
  -    print "miso_pack --pack mydir"
  +    print("MISO (Mixture of Isoforms model)")
  +    print("Pack the MISO output into an SQL database.")
  +    print("Use --help argument to view options.\n")
  +    print("Example usage:\n")
  +    print("miso_pack --pack mydir")
       if parser is not None:
           parser.print_help()

  @@ -94,7 +94,7 @@
       """
       dirs_to_pack = dirs_to_pack_as_str.split(",")
       # Make into absolute paths
  -    dirs_to_pack = map(misc_utils.pathify, dirs_to_pack)
  +    dirs_to_pack = list(map(misc_utils.pathify, dirs_to_pack))
       miso_packer = MISOPacker(dirs_to_pack)
       miso_packer.pack_dirs(dirs_to_pack)

  @@ -102,14 +102,14 @@
   def view_miso_db(db_fname):
       db_fname = misc_utils.pathify(db_fname)
       if not os.path.isfile(db_fname):
  -        print "Error: %s does not exist." %(db_fname)
  +        print("Error: %s does not exist." %(db_fname))
           sys.exit(1)
       curr_db = miso_db.MISODatabase(db_fname)
       event_names = curr_db.get_all_event_names()
       num_events = len(event_names)
  -    print "Database contains %d events" %(num_events)
  +    print("Database contains %d events" %(num_events))
       for event in event_names:
  -        print event
  +        print(event)


   def main():
  RefactoringTool: Refactored src/MISO/misopy/miso_sampler.py
  --- src/MISO/misopy/miso_sampler.py	(original)
  +++ src/MISO/misopy/miso_sampler.py	(refactored)
  @@ -22,7 +22,7 @@

   from scipy import *
   from numpy import *
  -import cPickle as pickle
  +import pickle as pickle
   from scipy.stats import mode
   import math
   import time
  @@ -116,8 +116,8 @@
       counts = defaultdict(int)
       for a in assignments:
           counts[a] += 1
  -    for k, v in counts.iteritems():
  -        print "Total of %d in isoform %d" %(v, k)
  +    for k, v in counts.items():
  +        print("Total of %d in isoform %d" %(v, k))


   def float_array_to_str(array_of_floats):
  @@ -179,8 +179,8 @@
           if self.paired_end:
               if ((not 'mean_frag_len' in self.params) or \
                   (not 'frag_variance' in self.params)):
  -                raise Exception, "Must set mean_frag_len and frag_variance when " \
  -                      "running in sampler on paired-end data."
  +                raise Exception("Must set mean_frag_len and frag_variance when " \
  +                      "running in sampler on paired-end data.")
               self.mean_frag_len = self.params['mean_frag_len']
               self.frag_variance = self.params['frag_variance']

  @@ -227,14 +227,14 @@
           self.num_reads = len(read_positions)

           if self.num_reads == 0:
  -            print "No reads for gene: %s" %(gene.label)
  +            print("No reads for gene: %s" %(gene.label))
               return

           output_file = output_file + ".miso"
           # If output filename exists, don't run sampler
           if os.path.isfile(os.path.normpath(output_file)):
  -            print "Output filename %s exists, not running MISO." \
  -                %(output_file)
  +            print("Output filename %s exists, not running MISO." \
  +                %(output_file))
               return None

           self.params['iters'] = num_iters
  @@ -286,37 +286,37 @@
               # Number of standard deviations in insert length
               # distribution to consider when assigning reads
               # to isoforms
  -            num_sds = 4L
  +            num_sds = 4

               # Run paired-end
  -            miso_results = pysplicing.MISOPaired(c_gene, 0L,
  +            miso_results = pysplicing.MISOPaired(c_gene, 0,
                                                    read_positions,
                                                    read_cigars,
  -                                                 long(self.read_len),
  +                                                 int(self.read_len),
                                                    float(self.mean_frag_len),
                                                    float(self.frag_variance),
                                                    float(num_sds),
  -                                                 long(num_iters),
  -                                                 long(burn_in),
  -                                                 long(lag),
  +                                                 int(num_iters),
  +                                                 int(burn_in),
  +                                                 int(lag),
                                                    prior_params,
  -                                                 long(self.overhang_len),
  -                                                 long(num_chains),
  +                                                 int(self.overhang_len),
  +                                                 int(num_chains),
                                                    start_cond,
                                                    stop_cond)
           else:
               # Run single-end
               miso_results = pysplicing.MISO(c_gene,
  -                                           0L,
  +                                           0,
                                              read_positions,
                                              read_cigars,
  -                                           long(self.read_len),
  -                                           long(num_iters),
  -                                           long(burn_in),
  -                                           long(lag),
  +                                           int(self.read_len),
  +                                           int(num_iters),
  +                                           int(burn_in),
  +                                           int(lag),
                                              prior_params,
  -                                           long(self.overhang_len),
  -                                           long(num_chains),
  +                                           int(self.overhang_len),
  +                                           int(num_chains),
                                              start_cond,
                                              stop_cond,
                                              pysplicing.MISO_ALGO_REASSIGN)
  @@ -350,7 +350,7 @@
           # Skip events where all reads are incompatible with the annotation;
           # do not output a file for those.
           if all(assignments == -1):
  -            print "All reads incompatible with annotation, skipping..."
  +            print("All reads incompatible with annotation, skipping...")
               return

           accepted_proposals = run_stats[4]
  @@ -362,7 +362,7 @@
           #self.miso_logger.info("Number of iterations recorded: %d" %(len(psi_vectors)))

           # Write MISO output to file
  -        print "Outputting samples to: %s..." %(output_file)
  +        print("Outputting samples to: %s..." %(output_file))
           self.miso_logger.info("Outputting samples to: %s" %(output_file))
           self.output_miso_results(output_file, gene, reads_data, assignments,
                                    psi_vectors, kept_log_scores, num_iters,
  @@ -370,7 +370,7 @@
                                    proposal_type)
           if verbose:
               t2 = time.time()
  -            print "Event took %.2f seconds" %(t2 - t1)
  +            print("Event took %.2f seconds" %(t2 - t1))


       def output_miso_results(self, output_file, gene, reads_data, assignments,
  @@ -463,7 +463,7 @@
               output_line = "%s\t%.2f\n" %(psi_sample_str, curr_log_score)
               output.write(output_line)
           output.close()
  -        print "Completed outputting."
  +        print("Completed outputting.")
   #        return [percent_acceptance, array(psi_vectors), array(kept_log_scores)]

   def run_sampler_on_event(gene, ni, ne, nb, read_len, overhang_len, num_iters,
  @@ -471,13 +471,13 @@
       """
       Run sampler on a two-isoform gene event.
       """
  -    print "Running sampler on a two-isoform event..."
  -    print "  - Gene label: ", gene.label, gene
  -    print "  - NI, NE, NB: %d, %d, %d" %(ni, ne, nb)
  -    print "Using default sampler parameters."
  +    print("Running sampler on a two-isoform event...")
  +    print("  - Gene label: ", gene.label, gene)
  +    print("  - NI, NE, NB: %d, %d, %d" %(ni, ne, nb))
  +    print("Using default sampler parameters.")
       if gene.chrom != None:
           # Index output by chromosome
  -        print "Indexing by chromosome..."
  +        print("Indexing by chromosome...")
           output_dir = os.path.join(output_dir, gene.chrom)
           if not os.path.exists(output_dir):
               os.makedirs(output_dir)
  @@ -509,19 +509,19 @@
       # Compute credible intervals
       cred_interval = ht.compute_credible_intervals(samples, confidence_level=confidence_level)
       t2 = time.time()
  -    print "  - Sampler run took %s seconds." %(str(t2-t1))
  +    print("  - Sampler run took %s seconds." %(str(t2-t1)))
       # return samples and credible intervals
       return (samples, cred_interval)


   def profile_miso():
  -    from Gene import make_gene
  +    from .Gene import make_gene
       gene = make_gene([150, 100, 150], [[1, 2, 3], [1, 3]])
       read_len = 36
       overhang_len = 4
       output_dir = "profiler-test"
       for x in range(10):
  -        print "x = %d" %(x)
  +        print("x = %d" %(x))
           a, b = run_sampler_on_event(gene, 500, 50, 40, read_len, overhang_len,
                                       10000, output_dir)

  RefactoringTool: Refactored src/MISO/misopy/miso_utils.py
  --- src/MISO/misopy/miso_utils.py	(original)
  +++ src/MISO/misopy/miso_utils.py	(refactored)
  @@ -14,8 +14,8 @@
       """
       miso_basename_files = []
       if not os.path.isdir(dirname):
  -        print "Error: %s not a directory." \
  -              %(dirname)
  +        print("Error: %s not a directory." \
  +              %(dirname))
           return miso_basename_files
       miso_files = glob.glob(os.path.join(dirname, "*.miso"))
       # return basenames
  @@ -58,11 +58,11 @@
       else:
           miso_prefix = ""

  -    print "miso_prefix: %s" %(miso_prefix)
  +    print("miso_prefix: %s" %(miso_prefix))

       if "miso_files" not in settings:
  -        print "Error: need \'miso_files\' to be set in settings file in " \
  -              "order to plot MISO estimates."
  +        print("Error: need \'miso_files\' to be set in settings file in " \
  +              "order to plot MISO estimates.")
           return miso_filenames

       miso_files = settings['miso_files']
  @@ -75,8 +75,8 @@

       for curr_sample_path in miso_sample_paths:
           event_found = False
  -        print "Searching for MISO files in: %s" %(curr_sample_path)
  -        print "  - Looking for chromosome %s directories" %(chrom)
  +        print("Searching for MISO files in: %s" %(curr_sample_path))
  +        print("  - Looking for chromosome %s directories" %(chrom))

           if event_with_miso_ext in get_miso_files_from_dir(curr_sample_path):
               # Allow the event to be in a top-level directory outside of a
  @@ -85,10 +85,10 @@
               event_filename = os.path.join(curr_sample_path,
                                             event_with_miso_ext)
               miso_filenames.append(event_filename)
  -            print "Found %s MISO file in top-level directory." %(event_name)
  -            print "  - Location: %s" %(event_filename)
  -            print "Please try to keep MISO event files in their chromosome "\
  -                  "directory."
  +            print("Found %s MISO file in top-level directory." %(event_name))
  +            print("  - Location: %s" %(event_filename))
  +            print("Please try to keep MISO event files in their chromosome "\
  +                  "directory.")
               break

           for root, dirs, files in os.walk(curr_sample_path):
  @@ -99,7 +99,7 @@
               # see if the MISO file is in there
               if chrom in dirs:
                   chrom_dirname = os.path.abspath(os.path.join(root, chrom))
  -                print "Looking for MISO files in: %s" %(chrom_dirname)
  +                print("Looking for MISO files in: %s" %(chrom_dirname))
                   # Fetch MISO files, if any
                   curr_miso_files = get_miso_files_from_dir(chrom_dirname)

  @@ -110,27 +110,27 @@
                       # Add to list
                       event_filename = os.path.join(root, chrom,
                                                     event_with_miso_ext)
  -                    print "Found %s MISO file." %(event_name)
  -                    print "  - Location: %s" %(event_filename)
  +                    print("Found %s MISO file." %(event_name))
  +                    print("  - Location: %s" %(event_filename))
                       miso_filenames.append(event_filename)
                       break

           if not event_found:
               # If we're here, it means we couldn't find the MISO
               # output files for the current sample
  -            print "Error: Could not find MISO output files for " \
  +            print("Error: Could not find MISO output files for " \
                     "sample %s (after searching in %s and its subdirectories). " \
                     "Are you sure MISO output files are present in that " \
                     "directory?" %(os.path.basename(curr_sample_path),
  -                                 curr_sample_path)
  +                                 curr_sample_path))
               # Include empty path for this sample
               miso_filenames.append('')

       # Number of event filenames retrieved must equal
       # the number of samples to be plotted
       if len(miso_filenames) != len(miso_files):
  -        print "WARNING: Could not find MISO files for all samples."
  -        print "  - miso_filenames: ", miso_filenames
  -        print "  - miso_samples to be plotted: ", miso_files
  +        print("WARNING: Could not find MISO files for all samples.")
  +        print("  - miso_filenames: ", miso_filenames)
  +        print("  - miso_samples to be plotted: ", miso_files)

       return miso_filenames
  RefactoringTool: Refactored src/MISO/misopy/miso_zip.py
  --- src/MISO/misopy/miso_zip.py	(original)
  +++ src/MISO/misopy/miso_zip.py	(refactored)
  @@ -52,25 +52,25 @@
           results as a zip file.
           """
           if os.path.isfile(output_filename):
  -            print "Error: %s already exists. Please delete to overwrite." \
  -                  %(output_filename)
  +            print("Error: %s already exists. Please delete to overwrite." \
  +                  %(output_filename))
           output_dir = "%s%s" %(output_filename, miso_db.MISO_DB_EXT)
           if os.path.isdir(output_dir):
  -            print "Error: Intermediate compressed directory %s " \
  -                  "exists. Please delete to overwrite." %(output_dir)
  +            print("Error: Intermediate compressed directory %s " \
  +                  "exists. Please delete to overwrite." %(output_dir))
               sys.exit(1)
           for miso_dirname in miso_dirnames:
  -            print "Processing: %s" %(miso_dirname)
  +            print("Processing: %s" %(miso_dirname))
               if not os.path.isdir(miso_dirname):
  -                print "Error: %s not a directory." %(miso_dirname)
  +                print("Error: %s not a directory." %(miso_dirname))
                   sys.exit(1)
               if os.path.isfile(output_filename):
  -                print "Output file %s already exists, aborting. " \
  +                print("Output file %s already exists, aborting. " \
                         "Please delete the file if you want " \
  -                      "compression to run."
  +                      "compression to run.")
                   sys.exit(1)
               self.miso_dirs_to_compress = []
  -            print "Copying source directory tree.."
  +            print("Copying source directory tree..")
               shutil.copytree(miso_dirname, output_dir,
                               ignore=self.collect_miso_dirs)
               for dir_to_compress in self.miso_dirs_to_compress:
  @@ -81,18 +81,18 @@
                   comp_path = "%s%s" %(comp_path, miso_db.MISO_DB_EXT)
                   miso_db.miso_dir_to_db(dir_to_compress, comp_path)
           # Zip directory using conventional zip
  -        print "Zipping compressed directory with standard zip..."
  +        print("Zipping compressed directory with standard zip...")
           t1 = time.time()
           zipper(output_dir, output_filename)
  -        print "Deleting intermediate directory: %s" %(output_dir)
  +        print("Deleting intermediate directory: %s" %(output_dir))
           shutil.rmtree(output_dir)
           t2 = time.time()
  -        print "  - Standard zipping took %.2f minutes." \
  -              %((t2 - t1)/60.)
  -        print "To access the SQLite representation of raw MISO output "
  -        print "(*.miso) files, simply unzip with the .miso_zip file "
  -        print "with standard unzip utility:\n"
  -        print "  unzip %s" %(output_filename)
  +        print("  - Standard zipping took %.2f minutes." \
  +              %((t2 - t1)/60.))
  +        print("To access the SQLite representation of raw MISO output ")
  +        print("(*.miso) files, simply unzip with the .miso_zip file ")
  +        print("with standard unzip utility:\n")
  +        print("  unzip %s" %(output_filename))


       def uncompress(self, compressed_filename, output_dir):
  @@ -101,21 +101,21 @@
           uncompresses it into 'output_dir'.
           """
           if not os.path.isfile(compressed_filename):
  -            print "Error: Cannot find %s, aborting." \
  -                  %(compressed_filename)
  +            print("Error: Cannot find %s, aborting." \
  +                  %(compressed_filename))
           if not os.path.basename(compressed_filename).endswith(self.comp_ext):
  -            print "Warning: %s does not end in %s. Are you sure it is " \
  +            print("Warning: %s does not end in %s. Are you sure it is " \
                     "a file compressed by miso_zip.py?" \
  -                  %(compressed_filename, self.comp_ext)
  +                  %(compressed_filename, self.comp_ext))
           if not os.path.isdir(output_dir):
               os.makedirs(output_dir)
  -        print "Uncompressing %s into %s" %(compressed_filename,
  -                                           output_dir)
  +        print("Uncompressing %s into %s" %(compressed_filename,
  +                                           output_dir))
           # First unzip the file using conventional unzip
           unzipped_files = unzipper(compressed_filename, output_dir)
           # Remove the original .zip
           if os.path.isfile(compressed_filename):
  -            print "Removing the compressed file %s" %(compressed_filename)
  +            print("Removing the compressed file %s" %(compressed_filename))
               if os.path.isfile(compressed_filename):
                   os.remove(compressed_filename)

  @@ -142,21 +142,21 @@
       output_filename = utils.pathify(output_filename)
       for input_dir in input_dirs:
           if not os.path.isdir(input_dir):
  -            print "Error: Cannot find directory %s" %(input_dir)
  +            print("Error: Cannot find directory %s" %(input_dir))
               sys.exit(1)
       if not os.path.basename(output_filename).endswith(comp_ext):
  -        print "Error: Compressed output filename must end in %s" \
  -              %(comp_ext)
  +        print("Error: Compressed output filename must end in %s" \
  +              %(comp_ext))
           sys.exit(1)
       if os.path.isfile(output_filename):
  -        print "Error: Output filename exists. Please delete %s to overwrite." \
  -              %(output_filename)
  +        print("Error: Output filename exists. Please delete %s to overwrite." \
  +              %(output_filename))
           sys.exit(1)
       t1 = time.time()
       miso_comp = MISOCompressor()
       miso_comp.compress(output_filename, input_dirs)
       t2 = time.time()
  -    print "Compression took %.2f minutes." %((t2 - t1)/60.)
  +    print("Compression took %.2f minutes." %((t2 - t1)/60.))


   def uncompress_miso(compressed_filename, output_dir):
  @@ -164,14 +164,14 @@
       Uncompress MISO directory.
       """
       if not os.path.isfile(compressed_filename):
  -        print "Error: Zip file %s is not found." \
  -              %(compressed_filename)
  +        print("Error: Zip file %s is not found." \
  +              %(compressed_filename))
           sys.exit(1)
       t1 = time.time()
       miso_comp = MISOCompressor()
       miso_comp.uncompress(compressed_filename, output_dir)
       t2 = time.time()
  -    print "Uncompression took %.2f minutes." %((t2 - t1)/60.)
  +    print("Uncompression took %.2f minutes." %((t2 - t1)/60.))


   def zipper(dir, zip_file):
  @@ -210,12 +210,12 @@


   def greeting():
  -    print "Compress/uncompress MISO output. Usage:\n"
  -    print "To compress a directory containing MISO files \'inputdir\', use: "
  -    print "   miso_zip --compress outputfile.misozip inputdir"
  -    print "To uncompress back into a directory \'outputdir\', use: "
  -    print "   miso_zip --uncompress outputfile.misozip outputdir"
  -    print "\nNote: compressed filename must end in \'.misozip\'"
  +    print("Compress/uncompress MISO output. Usage:\n")
  +    print("To compress a directory containing MISO files \'inputdir\', use: ")
  +    print("   miso_zip --compress outputfile.misozip inputdir")
  +    print("To uncompress back into a directory \'outputdir\', use: ")
  +    print("   miso_zip --uncompress outputfile.misozip outputdir")
  +    print("\nNote: compressed filename must end in \'.misozip\'")


   def main():
  @@ -241,7 +241,7 @@
       elif (options.compress is not None) and (options.uncompress is not None):
           # Can't be given both.
           greeting()
  -        print "Error: Cannot process --compress and --uncompress at same time."
  +        print("Error: Cannot process --compress and --uncompress at same time.")
           sys.exit(1)

       if options.compress is not None:
  RefactoringTool: Refactored src/MISO/misopy/module_availability.py
  --- src/MISO/misopy/module_availability.py	(original)
  +++ src/MISO/misopy/module_availability.py	(refactored)
  @@ -10,10 +10,10 @@

   def check_module_availability(required_modules):
       unavailable_mods = 0
  -    print "Checking availability of Python modules for MISO"
  -    print "Looking for required Python modules.."
  +    print("Checking availability of Python modules for MISO")
  +    print("Looking for required Python modules..")
       for module_name in required_modules:
  -        print "Checking for availability of: %s" %(module_name)
  +        print("Checking for availability of: %s" %(module_name))
           try:
               __import__(module_name)
               # Manually check for correct matplotlib version
  @@ -21,36 +21,36 @@
               if module_name == "matplotlib":
                   import matplotlib.pyplot as plt
                   if not hasattr(plt, "subplot2grid"):
  -                    print "WARNING: subplot2grid function is not available in matplotlib. " \
  +                    print("WARNING: subplot2grid function is not available in matplotlib. " \
                             "to use sashimi_plot, you must upgrade your matplotlib " \
                             "to version 1.1.0 or later. This function is *not* required " \
  -                          "for MISO use."
  +                          "for MISO use.")
           except ImportError:
  -            print "  - Module %s not available!" %(module_name)
  +            print("  - Module %s not available!" %(module_name))
               if module_name == "matplotlib":
  -                print "matplotlib is required for sashimi_plot"
  +                print("matplotlib is required for sashimi_plot")
               unavailable_mods += 1
       if unavailable_mods != 0:
  -        print "Total of %d modules were not available. " \
  -              "Please install these and try again." %(unavailable_mods)
  +        print("Total of %d modules were not available. " \
  +              "Please install these and try again." %(unavailable_mods))
       else:
  -        print "All modules are available!"
  -    print "Looking for required executables.."
  +        print("All modules are available!")
  +    print("Looking for required executables..")
       required_programs = ["samtools", "bedtools"]
       for prog in required_programs:
           p = utils.which(prog)
  -        print "Checking if %s is available" %(prog)
  +        print("Checking if %s is available" %(prog))
           if p is None:
  -            print " - Cannot find %s!" %(prog)
  +            print(" - Cannot find %s!" %(prog))
               if prog == "bedtools":
  -                print "bedtools is only required for prefiltering " \
  -                      "and computation of insert lengths."
  +                print("bedtools is only required for prefiltering " \
  +                      "and computation of insert lengths.")
                   if utils.which("tagBam"):
  -                    print "Your bedtools installation might be available " \
  +                    print("Your bedtools installation might be available " \
                             "but outdated. Please upgrade bedtools and " \
  -                          "ensure that \'bedtools\' is available on path."
  +                          "ensure that \'bedtools\' is available on path.")
           else:
  -            print "  - %s is available" %(prog)
  +            print("  - %s is available" %(prog))
       return unavailable_mods


  RefactoringTool: Refactored src/MISO/misopy/parse_csv.py
  --- src/MISO/misopy/parse_csv.py	(original)
  +++ src/MISO/misopy/parse_csv.py	(refactored)
  @@ -77,7 +77,7 @@
                                   deletechars='',
                                   delimiter=delimiter)
       except IOError as io_error:
  -        raise Exception, "IOError: %s, file: %s" %(io_error, file_in)
  +        raise Exception("IOError: %s, file: %s" %(io_error, file_in))
       cols = data_array[0,:]
       data = {}
       for n in range(data_array.ndim):
  @@ -93,7 +93,7 @@


   def evalDict(d):
  -    for k, v in d.iteritems():
  +    for k, v in d.items():
           d[k] = tryEval(v)
       return d

  @@ -132,7 +132,7 @@
       if fieldnames != None:
           header = delimiter.join(fieldnames) + lineterminator
       else:
  -        header = dictrows[0].keys()
  +        header = list(dictrows[0].keys())
           header.sort()
       out_f.write(header)
       if write_raw:
  @@ -157,8 +157,8 @@
       dictlist = []
       # convert data to list of dictionaries
       for line in f:
  -        values = map(tryEval, line.strip().split(delimiter))
  -        dictline = dict(zip(header_fields, values))
  +        values = list(map(tryEval, line.strip().split(delimiter)))
  +        dictline = dict(list(zip(header_fields, values)))
           dictlist.append(dictline)
       return (dictlist, header_fields)

  RefactoringTool: Refactored src/MISO/misopy/parse_gene.py
  --- src/MISO/misopy/parse_gene.py	(original)
  +++ src/MISO/misopy/parse_gene.py	(refactored)
  @@ -8,18 +8,18 @@
       Parse a pickled gene.
       """
       if not os.path.isfile(pickle_filename):
  -        raise Exception, "Error: no filename %s" %(pickle_filename)
  +        raise Exception("Error: no filename %s" %(pickle_filename))
       gff_genes = gff_utils.load_indexed_gff_file(pickle_filename)

       if gff_genes == None:
  -        raise Exception, "Error: could not load genes from %s" \
  -              %(pickle_filename)
  +        raise Exception("Error: could not load genes from %s" \
  +              %(pickle_filename))

       exon_starts = []
       exon_ends = []
       mRNAs = []
       chrom = None
  -    for gene_id, gene_info in gff_genes.iteritems():
  +    for gene_id, gene_info in gff_genes.items():
           if event == gene_id:
               gene_obj = gene_info['gene_object']
               gene_hierarchy = gene_info['hierarchy']
  @@ -27,11 +27,11 @@
                   gene_hierarchy[gene_id])
               chrom = gene_obj.chrom

  -            for mRNA_id, mRNA_info in gene_hierarchy[gene_id]['mRNAs'].iteritems():
  +            for mRNA_id, mRNA_info in gene_hierarchy[gene_id]['mRNAs'].items():
                   mRNA = []
                   for exon_id, exon_info in gene_hierarchy[gene_id]['mRNAs']\
                       [mRNA_id]['exons'].\
  -                    iteritems():
  +                    items():

                       exon_rec = gene_hierarchy[gene_id]['mRNAs']\
                           [mRNA_id]['exons'][exon_id]['record']
  RefactoringTool: Refactored src/MISO/misopy/pe_utils.py
  --- src/MISO/misopy/pe_utils.py	(original)
  +++ src/MISO/misopy/pe_utils.py	(refactored)
  @@ -26,7 +26,7 @@
       Read insert length distribution as array of numbers.
       """
       insert_dist = []
  -    for interval, paired_dists in interval_to_paired_dists.iteritems():
  +    for interval, paired_dists in interval_to_paired_dists.items():
           insert_dist.extend(paired_dists)
       return array(insert_dist)

  @@ -54,10 +54,10 @@

       min_cutoff = mu - (sd_max * sdev)
       max_cutoff = mu + (sd_max * sdev)
  -    print "Excluding values < %.2f or > %.2f" \
  -          %(min_cutoff, max_cutoff)
  -
  -    for interval, dists in interval_to_dists.iteritems():
  +    print("Excluding values < %.2f or > %.2f" \
  +          %(min_cutoff, max_cutoff))
  +
  +    for interval, dists in interval_to_dists.items():
           dists = array(dists)
           filtered_dists = delete(dists, nonzero(dists < min_cutoff)[0])
           filtered_dists = delete(filtered_dists,
  @@ -69,7 +69,7 @@

   def load_insert_len(insert_dist_filename,
                       delim='\t'):
  -    print "Loading insert length from: %s" %(insert_dist_filename)
  +    print("Loading insert length from: %s" %(insert_dist_filename))
       insert_dist_file = open(insert_dist_filename, "r")
       insert_lens = []
       params_header = insert_dist_file.readline().strip()
  @@ -102,13 +102,13 @@
       bedtools_cmd = "intersectBed -abam %s -b %s -wa -wb -bed -f 1" \
                      %(bam_filename, gff_intervals_filename)

  -    print "Executing: %s" %(bedtools_cmd)
  +    print("Executing: %s" %(bedtools_cmd))

       if (not os.path.isfile(bam_filename)) or \
          (not os.path.isfile(gff_intervals_filename)):
  -        raise Exception, "Error: %s or %s do not exist." \
  +        raise Exception("Error: %s or %s do not exist." \
               %(bam_filename,
  -              gff_intervals_filename)
  +              gff_intervals_filename))
       bed_stream = os.popen(bedtools_cmd)
       return bed_stream

  @@ -157,7 +157,7 @@
       interval_to_paired_dists = defaultdict(list)
       num_skipped = 0
       num_kept = 0
  -    for read_id, read_pair in paired_reads.iteritems():
  +    for read_id, read_pair in paired_reads.items():
           to_skip = False
           # Get the intervals that each read pair lands in
           # Consider here only the mate pairs that map to
  @@ -208,15 +208,15 @@
           insert_len = right_end - left_start + 1

           if insert_len <= 0:
  -            print "WARNING: 0 or negative insert length detected " \
  -                  "in region %s." %(curr_gff_interval)
  +            print("WARNING: 0 or negative insert length detected " \
  +                  "in region %s." %(curr_gff_interval))
               continue

           interval_to_paired_dists[curr_gff_interval].append(insert_len)
           num_kept += 1

  -    print "Used %d paired mates, threw out %d" \
  -          %(num_kept, num_skipped)
  +    print("Used %d paired mates, threw out %d" \
  +          %(num_kept, num_skipped))

       return interval_to_paired_dists

  @@ -238,14 +238,14 @@
  RefactoringTool: Refactored src/MISO/misopy/pickle_utils.py
       """
       bams_str = "\n  ".join(bams_to_process)
       num_bams = len(bams_to_process)
  -    print "Computing insert length distribution of %d files:\n  %s" \
  -          %(num_bams, bams_str)
  -    print "  - Using const. exons from: %s" %(const_exons_gff_filename)
  -    print "  - Outputting to: %s" %(output_dir)
  -    print "  - Minimum exon size used: %d" %(min_exon_size)
  +    print("Computing insert length distribution of %d files:\n  %s" \
  +          %(num_bams, bams_str))
  +    print("  - Using const. exons from: %s" %(const_exons_gff_filename))
  +    print("  - Outputting to: %s" %(output_dir))
  +    print("  - Minimum exon size used: %d" %(min_exon_size))

       if not os.path.isdir(output_dir):
  -        print "Making directory: %s" %(output_dir)
  +        print("Making directory: %s" %(output_dir))
           os.makedirs(output_dir)

       all_constitutive = True
  @@ -259,9 +259,9 @@
       filter_reads = not no_bam_filter

       if filter_reads:
  -        print "Filtering BAM reads"
  +        print("Filtering BAM reads")
       else:
  -        print "Turning off filtering of BAM reads"
  +        print("Turning off filtering of BAM reads")

       for bam_filename in bams_to_process:
           t1 = time.time()
  @@ -269,15 +269,15 @@
                                          "%s.insert_len" \
                                          %(os.path.basename(bam_filename)))
           if not os.path.isfile(bam_filename):
  -            print "Cannot find BAM file %s" %(bam_filename)
  -            print "Quitting..."
  +            print("Cannot find BAM file %s" %(bam_filename))
  +            print("Quitting...")
               sys.exit(1)
  -        print "Fetching reads in constitutive exons"
  +        print("Fetching reads in constitutive exons")
           mapped_bam_filename = exon_utils.map_bam2gff(bam_filename,
                                                        const_exons_gff_filename,
                                                        output_dir)
           if mapped_bam_filename == None:
  -            raise Exception, "Error: Insert length computation failed."
  +            raise Exception("Error: Insert length computation failed.")

           # Load mapped BAM filename
           mapped_bam = pysam.Samfile(mapped_bam_filename, "rb")
  @@ -289,17 +289,17 @@
           num_paired_reads = len(paired_reads)

           if num_paired_reads == 0:
  -            print "WARNING: no paired mates in %s. Skipping...\n"\
  +            print("WARNING: no paired mates in %s. Skipping...\n"\
                     "Are you sure the read IDs match? If your BAM paired flags are "\
                     "unset, try using --no-bam-filter." \
  -                  %(bam_filename)
  +                  %(bam_filename))
               continue
  -        print "Using %d paired mates" %(num_paired_reads)
  +        print("Using %d paired mates" %(num_paired_reads))
           interval_to_paired_dists = compute_inserts_from_paired_mates(paired_reads)
           summarize_insert_len_dist(interval_to_paired_dists, output_filename,
                                     sd_max=sd_max)
           t2 = time.time()
  -        print "Insert length computation took %.2f seconds." %(t2 - t1)
  +        print("Insert length computation took %.2f seconds." %(t2 - t1))


   # def pair_reads_from_bed_intervals(bed_stream):
  @@ -411,7 +411,7 @@
       header = "#%s\t%s\n" %("region", "insert_len")
       output_file.write(header)

  -    for region, insert_lens in interval_to_paired_dists.iteritems():
  +    for region, insert_lens in interval_to_paired_dists.items():
           if len(insert_lens) == 0:
               continue
           str_lens = ",".join([str(l) for l in insert_lens])
  @@ -449,13 +449,13 @@
       """
       Summarize insert len distributions.
       """
  -    print "Summarizing insert length distribution.."
  -    print "  - Output file: %s" %(output_filename)
  +    print("Summarizing insert length distribution..")
  +    print("  - Output file: %s" %(output_filename))

       output_file = open(output_filename, "w")

  -    print "Removing values %d-many deviations outside the mean" \
  -          %(sd_max)
  RefactoringTool: No changes to src/MISO/misopy/py2c_gene.py
  +    print("Removing values %d-many deviations outside the mean" \
  +          %(sd_max))

       # Filter insert length distribution based on sd_max
       filtered_interval_to_dist = filter_insert_len(interval_to_paired_dists,
  @@ -463,22 +463,22 @@
       filtered_insert_dist = get_insert_dist_array(filtered_interval_to_dist)

       if len(filtered_insert_dist) == 0:
  -        print "Error: Could not find any properly mated pairs to " \
  +        print("Error: Could not find any properly mated pairs to " \
                 "compute insert length with. Are you sure your BAM reads " \
                 "are properly paired and map the chromosome headers in the " \
  -              "constitutive exon file?"
  +              "constitutive exon file?")
           sys.exit(1)

       mu, sdev, dispersion, num_pairs = \
           compute_insert_len_stats(filtered_insert_dist)

  -    print "mean\tsdev\tdispersion"
  -    print "%.1f\t%.1f\t%.1f" \
  -          %(mu, sdev, dispersion)
  +    print("mean\tsdev\tdispersion")
  +    print("%.1f\t%.1f\t%.1f" \
  +          %(mu, sdev, dispersion))
       min_insert = min(filtered_insert_dist)
       max_insert = max(filtered_insert_dist)
  -    print "min insert: %d" %(min_insert)
  -    print "max insert: %d" %(max_insert)
  +    print("min insert: %d" %(min_insert))
  +    print("max insert: %d" %(max_insert))

       # Write headers
       header_line = "#%s=%.1f,%s=%.1f,%s=%.1f,%s=%d\n" \
  @@ -495,10 +495,10 @@


   def greeting():
  -    print "Utility for computing insert length distributions from paired-end " \
  -          "BAM files."
  -    print "Part of MISO (Mixture of Isoforms model)\n"
  -    print "See --help for usage.\n"
  +    print("Utility for computing insert length distributions from paired-end " \
  +          "BAM files.")
  +    print("Part of MISO (Mixture of Isoforms model)\n")
  +    print("See --help for usage.\n")


   def main():
  @@ -531,7 +531,7 @@
       if options.output_dir is None:
           greeting()

  -        print "Error: need --output-dir."
  +        print("Error: need --output-dir.")
           return

       output_dir = os.path.abspath(os.path.expanduser(options.output_dir))
  --- src/MISO/misopy/pickle_utils.py	(original)
  +++ src/MISO/misopy/pickle_utils.py	(refactored)
  @@ -3,7 +3,7 @@
   ##
   import misopy
   import os
  -import cPickle as pickle
  +import pickle as pickle

   def load_pickled_file(pickled_filename):
       if os.access(pickled_filename, os.F_OK):
  RefactoringTool: Refactored src/MISO/misopy/read_simulator.py
  --- src/MISO/misopy/read_simulator.py	(original)
  +++ src/MISO/misopy/read_simulator.py	(refactored)
  @@ -25,13 +25,13 @@
                   if all(array(curr_read) == 1):
                       num_constitutive_reads += 1
           computed_const = True
  -        print "Iso %d (len = %d): %d unambiguous supporting reads" %(n, gene.isoforms[n].len,
  -                                                                     num_iso_reads)
  -    print "No. constitutive reads (consistent with all): %d" %(num_constitutive_reads)
  +        print("Iso %d (len = %d): %d unambiguous supporting reads" %(n, gene.isoforms[n].len,
  +                                                                     num_iso_reads))
  +    print("No. constitutive reads (consistent with all): %d" %(num_constitutive_reads))

   def get_reads_summary(reads):
       if reads.ndim != 2:
  -        raise Exception, "get_reads_summary only defined for two-isoform."
  +        raise Exception("get_reads_summary only defined for two-isoform.")
       ni = 0
       ne = 0
       nb = 0
  @@ -83,7 +83,7 @@
       num_NB = (gene.get_part_by_label('A').len - read_len + 1) + (gene.get_part_by_label('C').len - read_len + 1)
       p_NB = psi_f*((num_NB)/float(len(iso1_seq) - read_len + 1)) + \
              (1-psi_f)*(num_NB/float(len(iso2_seq) - read_len + 1))
  -    print "p_NI: %.5f, p_NE: %.5f, p_NB: %.5f" %(p_NI, p_NE, p_NB)
  +    print("p_NI: %.5f, p_NE: %.5f, p_NB: %.5f" %(p_NI, p_NE, p_NB))
       return [p_NI*num_reads, p_NE*num_reads, p_NB*num_reads, p_oh_violation*num_reads]

   def simulate_two_iso_reads(gene, true_psi, num_reads, read_len, overhang_len,
  @@ -93,9 +93,9 @@
       been generated by that isoform (denoted 1) or not (denoted 0).
       """
       if len(gene.isoforms) != 2:
  -        raise Exception, "simulate_two_iso_reads requires a gene with only two isoforms."
  +        raise Exception("simulate_two_iso_reads requires a gene with only two isoforms.")
       if len(true_psi) < 2:
  -        raise Exception, "Simulate reads requires a probability vector of size > 2."
  +        raise Exception("Simulate reads requires a probability vector of size > 2.")
       reads_summary = [0, 0, 0]
       all_reads = []
       categories = []
  @@ -153,15 +153,15 @@
       if the read could have come from the isoform and 2 otherwise.
       """
       if type(true_psi) != list:
  -        raise Exception, "simulate_reads: expects true_psi to be a probability vector summing to 1."
  +        raise Exception("simulate_reads: expects true_psi to be a probability vector summing to 1.")
       if len(gene.isoforms) == 2:
  -        raise Exception, "simulate_reads: should use simulate_two_iso_reads for genes with only two isoforms."
  +        raise Exception("simulate_reads: should use simulate_two_iso_reads for genes with only two isoforms.")
       if sum(true_psi) != 1:
  -        raise Exception, "simulate_reads: true_psi must sum to 1."
  +        raise Exception("simulate_reads: true_psi must sum to 1.")
       all_reads = []
       read_coords = []
       if len(true_psi) < 2:
  -        raise Exception, "Simulate reads requires a probability vector of size > 2."
  +        raise Exception("Simulate reads requires a probability vector of size > 2.")
       for k in range(0, num_reads):
           reads_sampled = sample_random_read(gene, true_psi, read_len, overhang_len)
           alignment = reads_sampled[0]
  @@ -184,8 +184,8 @@
       pe_reads = reads[:, 0]
       frag_lens = reads[:, 1]
       num_reads = len(pe_reads)
  -    print "Checking read consistency for %d reads..." %(num_reads)
  -    print reads
  +    print("Checking read consistency for %d reads..." %(num_reads))
  +    print(reads)
       is_consistent = False
       is_consistent = all(frag_lens[nonzero(pe_reads == 1)] != -Inf)
       if not is_consistent:
  @@ -212,8 +212,8 @@
       else:
           r = -1 * (power(frag_mean, 2)/float(frag_mean - frag_variance))
           p = frag_mean / float(frag_variance)
  -        print "Sampling frag_mean=",frag_mean, " frag_variance=", frag_variance
  -        print "r: ",r, "  p: ", p
  +        print("Sampling frag_mean=",frag_mean, " frag_variance=", frag_variance)
  +        print("r: ",r, "  p: ", p)
  RefactoringTool: Refactored src/MISO/misopy/reads_utils.py
           return negative_binomial(r, p)

   def compute_rpkc(list_read_counts, const_region_lens, read_len):
  @@ -244,7 +244,7 @@
       and the second is a set of corresponding fragment lengths for each alignment.
       """
       if sum(true_psi) != 1:
  -        raise Exception, "simulate_reads: true_psi must sum to 1."
  +        raise Exception("simulate_reads: true_psi must sum to 1.")
       # sample reads
       reads = []
       read_coords = []
  @@ -260,7 +260,7 @@
                   frag_len = sample_normal_frag_len(frag_mean=mean_frag_len, frag_variance=frag_variance)
               insert_len = frag_len - (2 * read_len)
               if insert_len < 0:
  -                raise Exception, "Sampled fragment length that is shorter than 2 * read_len!"
  +                raise Exception("Sampled fragment length that is shorter than 2 * read_len!")
                   #print "Sampled fragment length that is shorter than 2 * read_len!"
               sampled_frag_lens.append(frag_len)
           reads_sampled = sample_random_read_pair(gene, true_psi, read_len, overhang_len, insert_len, mean_frag_len)
  --- src/MISO/misopy/reads_utils.py	(original)
  +++ src/MISO/misopy/reads_utils.py	(refactored)
  @@ -27,7 +27,7 @@
           counts_dict[hashable_read] += 1

       # Sort results by keys for consistency
  -    keys = counts_dict.keys()
  +    keys = list(counts_dict.keys())
       keys.sort()

       counts = [(k, counts_dict[k]) for k in keys]
  RefactoringTool: Refactored src/MISO/misopy/run_events_analysis.py
  --- src/MISO/misopy/run_events_analysis.py	(original)
  +++ src/MISO/misopy/run_events_analysis.py	(refactored)
  @@ -40,12 +40,12 @@
       genes_gff_fname = os.path.join(gff_index_dir,
                                      "genes.gff")
       if not os.path.isfile(genes_gff_fname):
  -        print "WARNING: Could not find \'genes.gff\' in %s - " \
  +        print("WARNING: Could not find \'genes.gff\' in %s - " \
                 "skipping prefilter stage. Please reindex your " \
                 "GFF file with the latest version to enable " \
  -              "prefiltering." %(gff_index_dir)
  +              "prefiltering." %(gff_index_dir))
           return None
  -    print "Prefiltering reads..."
  +    print("Prefiltering reads...")
       coverage_fname = exon_utils.get_bam_gff_coverage(bam_filename,
                                                        genes_gff_fname,
                                                        output_dir)
  @@ -63,8 +63,8 @@
                   continue
               attribs = gff_utils.parse_gff_attribs(fields[8])
               if "ID" not in attribs:
  -                print "WARNING: No ID= found for line:\n%s\nSkipping..." \
  -                    %(line)
  +                print("WARNING: No ID= found for line:\n%s\nSkipping..." \
  +                    %(line))
                   continue
               event_id = attribs["ID"]
               ids_passing_filter.append(event_id)
  @@ -80,10 +80,10 @@
       annotation and BAM filename.  Warn users if there are
       headers mismatches.
       """
  -    print "Checking your GFF annotation and BAM for mismatches..."
  +    print("Checking your GFF annotation and BAM for mismatches...")
       # Check that BAM exists
       if not os.path.isfile(bam_filename):
  -        print "Error: BAM %s cannot be found." %(bam_filename)
  +        print("Error: BAM %s cannot be found." %(bam_filename))
           return
       # Check that a BAM header is available
       bam_index_fname = "%s.bai" %(bam_filename)
  @@ -91,7 +91,7 @@
           main_logger.warning("Expected BAM index file %s not found." \
                               %(bam_index_fname))
           main_logger.warning("Are you sure your BAM file is indexed?")
  -    print "Checking if BAM has mixed read lengths..."
  +    print("Checking if BAM has mixed read lengths...")
       bam_file = pysam.Samfile(bam_filename, "rb")
       n = 0
       seq_lens = {}
  @@ -101,7 +101,7 @@
               break
           seq_lens[len(bam_read.seq)] = True
           n += 1
  -    all_seq_lens = seq_lens.keys()
  +    all_seq_lens = list(seq_lens.keys())
       if len(all_seq_lens) > 1:
           msg = "Found mixed length reads in your BAM file: %s\n" \
                 "MISO does not support mixed read lengths. Please " \
  @@ -114,7 +114,7 @@
           main_logger.warning(msg)
           time.sleep(5)
       else:
  -        print "Found reads of length %d in BAM." %(all_seq_lens[0])
  +        print("Found reads of length %d in BAM." %(all_seq_lens[0]))
           # Check the BAM read length against the read length that was
           # given
           if given_read_len != None:
  @@ -184,11 +184,11 @@
                               "while your %s does not." %(chr_containing,
                                                           not_chr_containing))
           main_logger.warning("The first few BAM chromosomes were: %s" \
  -                            %(",".join(bam_chroms.keys())))
  -        print "BAM references: "
  -        print bam_file.references
  +                            %(",".join(list(bam_chroms.keys()))))
  +        print("BAM references: ")
  +        print(bam_file.references)
           main_logger.warning("The first few GFF chromosomes were: %s" \
  -                            %(",".join(gff_chroms.keys())))
  +                            %(",".join(list(gff_chroms.keys()))))
           main_logger.warning("Run is likely to fail or produce empty output. Proceeding " \
                               "anyway...")
           time.sleep(15)
  @@ -217,12 +217,12 @@

       misc_utils.make_dir(output_dir)

  -    print "Computing Psi for events of type %s" %(event_type)
  -    print "  - samples used: ", sample_filenames.keys()
  -
  -    for sample_label, sample_filename in sample_filenames.iteritems():
  -        print "Processing sample: label=%s, filename=%s" \
  -            %(sample_label, sample_filename)
  +    print("Computing Psi for events of type %s" %(event_type))
  +    print("  - samples used: ", list(sample_filenames.keys()))
  +
  +    for sample_label, sample_filename in sample_filenames.items():
  +        print("Processing sample: label=%s, filename=%s" \
  +            %(sample_label, sample_filename))
           results_output_dir = os.path.join(output_dir, sample_label)
           misc_utils.make_dir(results_output_dir)

  @@ -234,10 +234,10 @@

           # Filter events
           if filter_events:
  -            print "Filtering events..."
  +            print("Filtering events...")
               events.filter_events(settings=Settings.get())

  -        print "Running on a total of %d events." %(len(events.events))
  +        print("Running on a total of %d events." %(len(events.events)))

           events_filename = events.output_file(results_output_dir,
                                                sample_label)
  @@ -256,24 +256,24 @@
                   miso_cmd += ' --use-cluster --chunk-jobs %d' %(chunk_jobs)
               else:
                   miso_cmd += ' --use-cluster'
  -        print "Executing: %s" %(miso_cmd)
  +        print("Executing: %s" %(miso_cmd))
           if use_cluster:
  -            print " - Using cluster"
  +            print(" - Using cluster")
           os.system(miso_cmd)


   def greeting(parser=None):
  -    print "MISO (Mixture of Isoforms model)"
  -    print "Probabilistic analysis of RNA-Seq data to detect " \
  -          "differential isoforms"
  -    print "Use --help argument to view options.\n"
  +    print("MISO (Mixture of Isoforms model)")
  +    print("Probabilistic analysis of RNA-Seq data to detect " \
  +          "differential isoforms")
  +    print("Use --help argument to view options.\n")
       if parser is not None:
           parser.print_help()


   def main():
  -    print "MISO (Mixture of Isoforms model)"
  -    print "To run MISO, please use \"miso\" instead."
  +    print("MISO (Mixture of Isoforms model)")
  +    print("To run MISO, please use \"miso\" instead.")

   if __name__ == '__main__':
       main()
  RefactoringTool: Refactored src/MISO/misopy/run_miso.py
  --- src/MISO/misopy/run_miso.py	(original)
  +++ src/MISO/misopy/run_miso.py	(refactored)
  @@ -51,19 +51,19 @@
       misc_utils.make_dir(output_dir)

       if not os.path.exists(gff_index_filename):
  -        print "Error: No GFF %s" %(gff_index_filename)
  +        print("Error: No GFF %s" %(gff_index_filename))
           return

       num_genes = len(gene_ids)

  -    print "Computing Psi for %d genes..." %(num_genes)
  -    print "  - " + ", ".join(gene_ids)
  -    print "  - GFF filename: %s" %(gff_index_filename)
  -    print "  - BAM: %s" %(bam_filename)
  -    print "  - Outputting to: %s" %(output_dir)
  +    print("Computing Psi for %d genes..." %(num_genes))
  +    print("  - " + ", ".join(gene_ids))
  +    print("  - GFF filename: %s" %(gff_index_filename))
  +    print("  - BAM: %s" %(bam_filename))
  +    print("  - Outputting to: %s" %(output_dir))

       if paired_end:
  -        print "  - Paired-end mode: ", paired_end
  +        print("  - Paired-end mode: ", paired_end)

       settings = Settings.get()
       settings_params = Settings.get_sampler_params()
  @@ -102,7 +102,7 @@
       # Check if we're in compressed mode
       compressed_mode = misc_utils.is_compressed_index(gff_index_filename)

  -    for gene_id, gene_info in gff_genes.iteritems():
  +    for gene_id, gene_info in gff_genes.items():
           lookup_id = gene_id
           # Skip genes that we were not asked to run on
           if lookup_id not in gene_ids:
  @@ -112,9 +112,9 @@

           # Sanity check: if the isoforms are all shorter than the read,
           # skip the event
  -        if all(map(lambda l: l < read_len, gene_obj.iso_lens)):
  -            print "All isoforms of %s shorter than %d, so skipping" \
  -                  %(gene_id, read_len)
  +        if all([l < read_len for l in gene_obj.iso_lens]):
  +            print("All isoforms of %s shorter than %d, so skipping" \
  +                  %(gene_id, read_len))
               continue

           # Find the most inclusive transcription start and end sites
  @@ -140,12 +140,12 @@
           # Skip gene if none of the reads align to gene boundaries
           if filter_reads:
               if num_raw_reads < min_event_reads:
  -                print "Only %d reads in gene, skipping (needed >= %d reads)" \
  +                print("Only %d reads in gene, skipping (needed >= %d reads)" \
                         %(num_raw_reads,
  -                        min_event_reads)
  +                        min_event_reads))
                   continue
               else:
  -                print "%d raw reads in event" %(num_raw_reads)
  +                print("%d raw reads in event" %(num_raw_reads))

           num_isoforms = len(gene_obj.isoforms)
           hyperparameters = ones(num_isoforms)
  @@ -191,7 +191,7 @@
           # Pick .miso output filename based on the pickle filename
           miso_basename = os.path.basename(gff_index_filename)
           if not miso_basename.endswith(".pickle"):
  -            print "Error: Invalid index file %s" %(gff_index_filename)
  +            print("Error: Invalid index file %s" %(gff_index_filename))
               sys.exit(1)
           miso_basename = miso_basename.replace(".pickle", "")
           output_filename = os.path.join(chrom_dir, "%s" %(miso_basename))
  @@ -212,7 +212,7 @@
       corresponding to the event/gene.
       """
       if options.read_len == None:
  -        print "Error: must provide --read-len."
  +        print("Error: must provide --read-len.")
           sys.exit(1)

       overhang_len = 1
  @@ -227,18 +227,18 @@
           os.path.abspath(os.path.expanduser(options.compute_genes_from_file[1]))
       output_dir = \
           os.path.abspath(os.path.expanduser(options.compute_genes_from_file[2]))
  -    print "Computing Psi for genes from file..."
  -    print "  - Input file: %s" %(genes_filename)
  +    print("Computing Psi for genes from file...")
  +    print("  - Input file: %s" %(genes_filename))
       if options.paired_end != None:
           paired_end = float(options.paired_end[0]), \
                        float(options.paired_end[1])
  -        print "  - Paired-end mode"
  +        print("  - Paired-end mode")
       # Check that the events filename exists
       if not os.path.isfile(genes_filename):
  -        print "Error: %s filename does not exist." %(genes_filename)
  +        print("Error: %s filename does not exist." %(genes_filename))
           sys.exit(1)
       if not os.path.isfile(bam_filename):
  -        print "Error: BAM filename %s does not exist." %(bam_filename)
  +        print("Error: BAM filename %s does not exist." %(bam_filename))
           sys.exit(1)
       # Load the events and their indexed GFF paths
       num_genes = 0
  @@ -246,14 +246,14 @@
           for line in genes_in:
               gene_id, gff_filename = line.strip().split("\t")
               if not os.path.isfile(gff_filename):
  -                print "Error: %s does not exist." %(gff_filename)
  +                print("Error: %s does not exist." %(gff_filename))
                   sys.exit(1)
               compute_gene_psi([gene_id], gff_filename, bam_filename,
                                output_dir, options.read_len, overhang_len,
                                paired_end=paired_end,
                                event_type=options.event_type)
               num_genes += 1
  -    print "Processed %d genes" %(num_genes)
  +    print("Processed %d genes" %(num_genes))


   def run_compute_gene_psi(options):
  @@ -261,7 +261,7 @@
       Parse options and run compute_genes_psi.
       """
       if options.read_len == None:
  -        print "Error: must provide --read-len."
  +        print("Error: must provide --read-len.")
           sys.exit(1)

       overhang_len = 1
  @@ -295,10 +295,10 @@


   def greeting(parser=None):
  -    print "MISO (Mixture of Isoforms model)"
  -    print "Probabilistic analysis of RNA-Seq data to detect " \
  -          "differential isoforms"
  -    print "Use --help argument to view options.\n"
  +    print("MISO (Mixture of Isoforms model)")
  +    print("Probabilistic analysis of RNA-Seq data to detect " \
  +          "differential isoforms")
  +    print("Use --help argument to view options.\n")
       if parser is not None:
           parser.print_help()

  @@ -408,18 +408,18 @@
           use_compressed = \
               os.path.abspath(os.path.expanduser(options.use_compressed))
           if not os.path.exists(use_compressed):
  -            print "Error: mapping filename from event IDs to compressed IDs %s " \
  -                  "is not found." %(use_compressed)
  +            print("Error: mapping filename from event IDs to compressed IDs %s " \
  +                  "is not found." %(use_compressed))
               sys.exit(1)
           else:
  -            print "Compression being used."
  +            print("Compression being used.")

       if options.samples_to_compare is not None:
           sample1_dirname = os.path.abspath(options.samples_to_compare[0])
           sample2_dirname = os.path.abspath(options.samples_to_compare[1])
           output_dirname = os.path.abspath(options.samples_to_compare[2])
           if not os.path.isdir(output_dirname):
  -            print "Making comparisons directory: %s" %(output_dirname)
  +            print("Making comparisons directory: %s" %(output_dirname))
               misc_utils.make_dir(output_dirname)
           ht.output_samples_comparison(sample1_dirname,
                                        sample2_dirname,
  @@ -443,7 +443,7 @@
               os.path.abspath(os.path.expanduser(options.summarize_samples[0]))
           if options.summary_label != None:
               samples_label = options.summary_label
  -            print "Using summary label: %s" %(samples_label)
  +            print("Using summary label: %s" %(samples_label))
           else:
               samples_label = \
                   os.path.basename(os.path.expanduser(samples_dir))
  @@ -462,29 +462,29 @@
       if options.view_gene != None:
           indexed_gene_filename = \
               os.path.abspath(os.path.expanduser(options.view_gene))
  -        print "Viewing genes in %s" %(indexed_gene_filename)
  +        print("Viewing genes in %s" %(indexed_gene_filename))
           gff_genes = gff_utils.load_indexed_gff_file(indexed_gene_filename)

           if gff_genes == None:
  -            print "No genes."
  +            print("No genes.")
               sys.exit(1)

  -        for gene_id, gene_info in gff_genes.iteritems():
  -            print "Gene %s" %(gene_id)
  +        for gene_id, gene_info in gff_genes.items():
  +            print("Gene %s" %(gene_id))
               gene_obj = gene_info['gene_object']
  -            print " - Gene object: ", gene_obj
  -            print "=="
  -            print "Isoforms: "
  +            print(" - Gene object: ", gene_obj)
  +            print("==")
  +            print("Isoforms: ")
               for isoform in gene_obj.isoforms:
  -                print " - ", isoform
  -            print "=="
  -            print "mRNA IDs: "
  +                print(" - ", isoform)
  +            print("==")
  +            print("mRNA IDs: ")
               for mRNA_id in gene_info['hierarchy'][gene_id]['mRNAs']:
  -                print "%s" %(mRNA_id)
  -            print "=="
  -            print "Exons: "
  +                print("%s" %(mRNA_id))
  +            print("==")
  +            print("Exons: ")
               for exon in gene_obj.parts:
  -                print " - ", exon
  +                print(" - ", exon)

   if __name__ == '__main__':
       main()
  RefactoringTool: Refactored src/MISO/misopy/sam_rpkm.py
  --- src/MISO/misopy/sam_rpkm.py	(original)
  +++ src/MISO/misopy/sam_rpkm.py	(refactored)
  @@ -66,38 +66,38 @@
       """
       Compute RPKMs for genes listed in GFF based on BAM reads.
       """
  -    print "Computing RPKMs..."
  -    print "  - GFF filename: %s" %(gff_filename)
  -    print "  - BAM filename: %s" %(bam_filename)
  -    print "  - Output dir: %s" %(output_dir)
  +    print("Computing RPKMs...")
  +    print("  - GFF filename: %s" %(gff_filename))
  +    print("  - BAM filename: %s" %(bam_filename))
  +    print("  - Output dir: %s" %(output_dir))

       if not os.path.isdir(output_dir):
           os.makedirs(output_dir)

       output_filename = os.path.join(output_dir,
                                      "%s.rpkm" %(os.path.basename(bam_filename)))
  -    print "Outputting RPKMs to: %s" %(output_filename)
  +    print("Outputting RPKMs to: %s" %(output_filename))

       rpkm_fieldnames = ['gene_id', 'rpkm', 'const_exon_lens',
                          'num_reads']

       # Parse the GFF into genes
  -    print "Parsing GFF into genes..."
  +    print("Parsing GFF into genes...")
       t1 = time.time()
       gff_genes = load_genes_from_gff(gff_filename)
       t2 = time.time()
  -    print "Parsing took %.2f seconds" %(t2 - t1)
  +    print("Parsing took %.2f seconds" %(t2 - t1))

       # Load the BAM file
       bamfile = sam_utils.load_bam_reads(bam_filename)

  -    print "Counting all reads..."
  +    print("Counting all reads...")
       t1 = time.time()
       num_total_reads = count_total_reads(bam_filename)
       t2 = time.time()
  -    print "Took: %.2f seconds" %(t2 - t1)
  -
  -    print "Number of total reads in BAM file: %d" %(num_total_reads)
  +    print("Took: %.2f seconds" %(t2 - t1))
  +
  +    print("Number of total reads in BAM file: %d" %(num_total_reads))

       num_genes = 0

  @@ -106,7 +106,7 @@
       exons_too_small = {}
       num_no_const = 0

  -    for gene_id, gene_info in gff_genes.iteritems():
  +    for gene_id, gene_info in gff_genes.items():
           # Get the gene object
           gene = gene_info['gene_object']

  @@ -124,12 +124,12 @@
               chrom = gene.chrom

           if "random" in chrom:
  -            print "Skipping random chromosome gene: %s, %s" \
  -                  %(gene_id, chrom)
  +            print("Skipping random chromosome gene: %s, %s" \
  +                  %(gene_id, chrom))
               continue

           if len(const_exons) == 0:
  -            print "Gene %s has no constitutive regions!" %(gene_id)
  +            print("Gene %s has no constitutive regions!" %(gene_id))
               num_no_const += 1
               continue

  @@ -143,9 +143,9 @@
               try:
                   reads = bamfile.fetch(chrom, exon.start, exon.end)
               except ValueError:
  -                print "Error fetching region: %s:%d-%d" %(chrom,
  +                print("Error fetching region: %s:%d-%d" %(chrom,
                                                             exon.start,
  -                                                          exon.end)
  +                                                          exon.end))
                   break

               # Count reads landing in exon
  @@ -194,16 +194,16 @@
           # Compute how many reads land in each constitutive exon
           num_genes += 1

  -    num_too_small = len(exons_too_small.keys())
  -
  -    print "Computed RPKMs for %d genes." %(num_genes)
  -    print "  - Total of %d genes cannot be used because they lack const. regions." \
  -          %(num_no_const)
  -    print "  - Total of %d genes cannot be used since their exons are too small." \
  -          %(num_too_small)
  -    for gene, total_counts in exons_too_small.iteritems():
  -        print "      gene_id\ttotal_counts"
  -        print "    * %s\t%d" %(gene, total_counts)
  +    num_too_small = len(list(exons_too_small.keys()))
  +
  +    print("Computed RPKMs for %d genes." %(num_genes))
  +    print("  - Total of %d genes cannot be used because they lack const. regions." \
  +          %(num_no_const))
  +    print("  - Total of %d genes cannot be used since their exons are too small." \
  +          %(num_too_small))
  +    for gene, total_counts in exons_too_small.items():
  +        print("      gene_id\ttotal_counts")
  +        print("    * %s\t%d" %(gene, total_counts))

       # Output RPKMs to file
       dictlist2file(rpkms_dictlist, output_filename,
  @@ -224,7 +224,7 @@

       if options.compute_rpkm != None:
           if options.read_len == 0:
  -            print "Error: Must give --read-len to compute RPKMs."
  +            print("Error: Must give --read-len to compute RPKMs.")
               return

           gff_filename = os.path.abspath(os.path.expanduser(options.compute_rpkm[0]))
  RefactoringTool: Refactored src/MISO/misopy/sam_to_bam.py
  --- src/MISO/misopy/sam_to_bam.py	(original)
  +++ src/MISO/misopy/sam_to_bam.py	(refactored)
  @@ -8,7 +8,7 @@
   def sam_to_bam(sam_filename, output_dir,
                  header_ref=None):
       # Convert to BAM
  -    print "Converting SAM to BAM..."
  +    print("Converting SAM to BAM...")
       if not os.path.isdir(output_dir):
           os.makedirs(output_dir)

  @@ -19,26 +19,26 @@
       if header_ref != None:
           cmd += " -t %s" %(header_ref)
       cmd += " > %s" %(bam_filename)
  -    print "  - Executing: %s" %(cmd)
  +    print("  - Executing: %s" %(cmd))
       os.system(cmd)

       # Sort
  -    print "Sorting BAM file..."
  +    print("Sorting BAM file...")
       sorted_filename = "%s.sorted" %(bam_filename.split(".bam")[0])
       cmd = "samtools sort %s %s" %(bam_filename,
                                     sorted_filename)
  -    print "  - Executing: %s" %(cmd)
  +    print("  - Executing: %s" %(cmd))
       os.system(cmd)

       # Index
       final_filename = "%s.bam" %(sorted_filename)
  -    print "Indexing BAM..."
  +    print("Indexing BAM...")
       cmd = "samtools index %s" %(final_filename)
  -    print "  - Executing: %s" %(cmd)
  +    print("  - Executing: %s" %(cmd))
       os.system(cmd)

       t2 = time.time()
  -    print "Conversion took %.2f minutes." %((t2 - t1)/60.)
  +    print("Conversion took %.2f minutes." %((t2 - t1)/60.))

   def main():
       from optparse import OptionParser
  @@ -55,7 +55,7 @@

           if options.ref != None:
               ref = os.path.abspath(os.path.expanduser(options.ref))
  -            print "Using ref: %s" %(ref)
  +            print("Using ref: %s" %(ref))

           sam_filename = os.path.abspath(os.path.expanduser(options.convert[0]))
           output_dir = os.path.abspath(os.path.expanduser(options.convert[1]))
  @@ -63,7 +63,7 @@
           sam_to_bam(sam_filename, output_dir, header_ref=ref)

       else:
  -        print "Need --convert to convert SAM to BAM."
  +        print("Need --convert to convert SAM to BAM.")

   if __name__ == "__main__":
       main()
  RefactoringTool: Refactored src/MISO/misopy/sam_utils.py
  --- src/MISO/misopy/sam_utils.py	(original)
  +++ src/MISO/misopy/sam_utils.py	(refactored)
  @@ -144,7 +144,7 @@
       """
       Load a set of indexed BAM reads.
       """
  -    print "Loading BAM filename from: %s" %(bam_filename)
  +    print("Loading BAM filename from: %s" %(bam_filename))
       bam_filename = os.path.abspath(os.path.expanduser(bam_filename))
       bamfile = pysam.Samfile(bam_filename, "rb",
                               template=template)
  @@ -170,14 +170,14 @@
       try:
           gene_reads = bamfile.fetch(chrom, start, end)
       except ValueError:
  -        print "Cannot fetch reads in region: %s:%d-%d" %(chrom,
  +        print("Cannot fetch reads in region: %s:%d-%d" %(chrom,
                                                            start,
  -                                                         end)
  +                                                         end))
       except AssertionError:
  -        print "AssertionError in region: %s:%d-%d" %(chrom,
  +        print("AssertionError in region: %s:%d-%d" %(chrom,
                                                        start,
  -                                                     end)
  -        print "  - Check that your BAM file is indexed!"
  +                                                     end))
  +        print("  - Check that your BAM file is indexed!")
       return gene_reads


  @@ -250,7 +250,7 @@
       num_unpaired = 0
       num_total = 0

  -    for read_name, read in paired_reads.iteritems():
  +    for read_name, read in paired_reads.items():
           if len(read) != 2:
               unpaired_reads[read_name] = read
               num_unpaired += 1
  @@ -269,19 +269,19 @@
               continue

           if left_read.pos > right_read.pos:
  -            print "WARNING: %s left mate starts later than right "\
  -                  "mate" %(left_read.qname)
  +            print("WARNING: %s left mate starts later than right "\
  +                  "mate" %(left_read.qname))
           num_total += 1

       # Delete reads that are on the same strand
       for del_key in to_delete:
           del paired_reads[del_key]

  -    print "Filtered out %d read pairs that were on same strand." \
  -        %(len(to_delete))
  -    print "Filtered out %d reads that had no paired mate." \
  -        %(num_unpaired)
  -    print "  - Total read pairs: %d" %(num_total)
  +    print("Filtered out %d read pairs that were on same strand." \
  +        %(len(to_delete)))
  +    print("Filtered out %d reads that had no paired mate." \
  +        %(num_unpaired))
  +    print("  - Total read pairs: %d" %(num_total))

       if not return_unpaired:
           return paired_reads
  @@ -324,7 +324,7 @@
       if strand_rule == "fr-unstranded":
           return True
       if strand_rule == "fr-secondstrand":
  -        raise Exception, "fr-secondstrand currently unsupported."
  +        raise Exception("fr-secondstrand currently unsupported.")
       matches = False
       if paired_end is not None:
           ## Paired-end reads
  @@ -338,7 +338,7 @@
               elif target_strand == "-":
                   return (flag_to_strand(read2.flag) == "-")
           else:
  -            raise Exception, "Unknown strandedness rule."
  +            raise Exception("Unknown strandedness rule.")
       else:
           ## Single-end reads
           if strand_rule == "fr-firststrand":
  @@ -346,7 +346,7 @@
               # match the target strand
               matches = (flag_to_strand(read.flag) == target_strand)
           else:
  -            raise Exception, "Unknown strandedness rule."
  +            raise Exception("Unknown strandedness rule.")
       return matches


  @@ -398,7 +398,7 @@
           # Process reads into format required by fastmiso
           # MISO C engine requires pairs to follow each other in order.
           # Unpaired reads are not supported.
  -        for read_id, read_info in paired_reads.iteritems():
  +        for read_id, read_info in paired_reads.items():
               if check_strand:
                   # Check strand
                   if not read_matches_strand(read_info,
  @@ -447,8 +447,8 @@
               num_reads += 1

       if check_strand:
  -        print "No. reads discarded due to strand violation: %d" \
  -            %(num_strand_discarded)
  +        print("No. reads discarded due to strand violation: %d" \
  +            %(num_strand_discarded))

       reads = (tuple(read_positions),
                tuple(read_cigars))
  @@ -471,7 +471,7 @@

       k = 0

  -    for read_id, read_pair in paired_reads.iteritems():
  +    for read_id, read_pair in paired_reads.items():
           if len(read_pair) != 2:
               # Skip reads with no pair
               continue
  @@ -487,7 +487,7 @@
   #            print "read %s inconsistent with all isoforms" %(read_id)
               k += 1

  -    print "Filtered out %d reads that were not consistent with any isoform" %(k)
  +    print("Filtered out %d reads that were not consistent with any isoform" %(k))
       return pe_reads, num_read_pairs


  @@ -512,7 +512,7 @@
           else:
               num_skipped += 1

  -    print "Skipped total of %d reads." %(num_skipped)
  +    print("Skipped total of %d reads." %(num_skipped))

       return alignments, num_reads

  @@ -522,7 +522,7 @@
       """
       Align BAM reads to the gene model.
       """
  -    print "Aligning reads to gene..."
  +    print("Aligning reads to gene...")
       t1 = time.time()

       if paired_end != None:
  @@ -535,8 +535,8 @@
                                                       overhang_len)

       t2 = time.time()
  -    print "Alignment to gene took %.2f seconds (%d reads)." %((t2 - t1),
  -                                                              num_reads)
  +    print("Alignment to gene took %.2f seconds (%d reads)." %((t2 - t1),
  +                                                              num_reads))
       return reads


  RefactoringTool: Refactored src/MISO/misopy/samples_utils.py
  --- src/MISO/misopy/samples_utils.py	(original)
  +++ src/MISO/misopy/samples_utils.py	(refactored)
  @@ -31,16 +31,16 @@
           self.compressed_ids_fname = use_compressed
           self.compressed_ids_to_genes = None
           if self.compressed_ids_fname is not None:
  -            print "  - Loading compressed IDs mapping from: %s" \
  -                  %(self.compressed_ids_fname)
  +            print("  - Loading compressed IDs mapping from: %s" \
  +                  %(self.compressed_ids_fname))
               # Load mapping from gene IDs to their hashes
               self.compressed_ids_to_genes = \
                 misc_utils.load_compressed_ids_to_genes(self.compressed_ids_fname)
               if len(self.compressed_ids_to_genes) == 0:
  -                print "Error: Compressed IDs shelve file is empty. Are you sure " \
  +                print("Error: Compressed IDs shelve file is empty. Are you sure " \
                         "the index directory you passed was created with the " \
                         "--compress-id flag, e.g.:\n" \
  -                      "index_gff yourfile.gff --compress-id"
  +                      "index_gff yourfile.gff --compress-id")
                   sys.exit(1)
           # Get all the MISO relevant filenames
           self.all_filenames = get_samples_dir_filenames(samples_dir)
  @@ -116,7 +116,7 @@
               event_data = curr_db.get_event_data_as_stream(event_name)
               samples = load_samples(event_data)
           if samples is None:
  -            print "WARNING: Could not parse event %s samples" %(event_name)
  +            print("WARNING: Could not parse event %s samples" %(event_name))
           return samples


  @@ -202,9 +202,9 @@
           elif f.startswith("assigned_counts="):
               counts['assigned_counts'] = f.split("=")[1]

  -    if len(counts.keys()) != 2:
  -        print "Warning: Could not get counts fields out of " \
  -              "%s header." %(samples_header)
  +    if len(list(counts.keys())) != 2:
  +        print("Warning: Could not get counts fields out of " \
  +              "%s header." %(samples_header))
           counts = {'counts': 'n/a',
                     'assigned_counts': 'n/a'}

  @@ -242,8 +242,8 @@
       event_name = basename.split(".miso")[0]
       if use_compressed_map is not None:
           if event_name not in use_compressed_map:
  -            print "MISO FILENAME IS: %s" %(miso_filename)
  -            print event_name
  +            print("MISO FILENAME IS: %s" %(miso_filename))
  +            print(event_name)
           else:
               event_name = use_compressed_map[event_name]
       return event_name
  @@ -275,8 +275,8 @@
                        "mRNA_ends"]
       summary_header = "%s\n" %("\t".join(header_fields))
       summary_file.write(summary_header)
  -    print "Loading events from: %s" %(samples_dir)
  -    print "Writing summary to: %s" %(summary_filename)
  +    print("Loading events from: %s" %(samples_dir))
  +    print("Writing summary to: %s" %(summary_filename))
       samples_obj = MISOSamples(samples_dir,
                                 use_compressed=use_compressed)
       num_events = 0
  @@ -284,16 +284,16 @@
       for event_name in samples_obj.all_event_names:
           samples_results = samples_obj.get_event_samples(event_name)
           if samples_results is None:
  -            print "WARNING: Skipping %s" %(event_name)
  +            print("WARNING: Skipping %s" %(event_name))
               # Skip files that could not be parsed
               continue
           # If we're not given a mapping to compressed IDs, check
           # that the event IDs do not look compressed
           if misc_utils.is_compressed_name(event_name) and \
              (use_compressed is None):
  -            print "WARNING: %s looks like a compressed id, but no mapping file " \
  +            print("WARNING: %s looks like a compressed id, but no mapping file " \
                     "from compressed IDs to event IDs was given! Try: --use-compressed" \
  -                  %(event_name)
  +                  %(event_name))
           # Load header/parameters information
           samples = samples_results[0]
           header = samples_results[1]
  @@ -303,7 +303,7 @@
           counts_info = samples_results[5]
           shape_len = len(shape(samples))
           if shape_len < 2:
  -            print "WARNING: Skipping %s -- mishaped file" %(event_name)
  +            print("WARNING: Skipping %s -- mishaped file" %(event_name))
               continue
           num_samples, num_isoforms = shape(samples)
           output_fields = format_credible_intervals(event_name, samples)
  @@ -325,7 +325,7 @@
           output_line = "%s\n" %("\t".join(output_fields))
           summary_file.write(output_line)
           num_events += 1
  -    print "  - Summarized a total of %d events." %(num_events)
  +    print("  - Summarized a total of %d events." %(num_events))
       summary_file.close()


  @@ -371,7 +371,7 @@
       Also collect files in samples_dir for backwards compatibility.
       """
       directories = glob.glob(os.path.join(samples_dir, "*"))
  -    directories = filter(is_miso_chrom_dir, directories)
  +    directories = list(filter(is_miso_chrom_dir, directories))

       # Filenames indexed by chromosomes
       filenames = []
  @@ -391,21 +391,18 @@
                    for fname in filenames]

       # Remove directories and files beginning with "."
  -    filenames = filter(lambda f: not os.path.isdir(f),
  -                       filenames)
  -    filenames = filter(lambda f: not os.path.basename(f).startswith("."),
  -                       filenames)
  +    filenames = [f for f in filenames if not os.path.isdir(f)]
  +    filenames = [f for f in filenames if not os.path.basename(f).startswith(".")]

       # Resulting files should be either *.miso files
       # or *.miso_db files, but not both
       miso_filenames = \
  -      filter(lambda f: os.path.basename(f).endswith(".miso"),
  -             filenames)
  +      [f for f in filenames if os.path.basename(f).endswith(".miso")]
       miso_db_filenames = \
  -      filter(miso_db.is_miso_db_fname,
  -             filenames)
  +      list(filter(miso_db.is_miso_db_fname,
  +             filenames))
       if len(miso_filenames) > 0 and len(miso_db_filenames) > 0:
  -        print "WARNING: Directory %s has both *.miso and *.miso_db files" \
  -              %(samples_dir)
  +        print("WARNING: Directory %s has both *.miso and *.miso_db files" \
  +              %(samples_dir))
       relevant_filenames = miso_filenames + miso_db_filenames
       return relevant_filenames
  RefactoringTool: Refactored src/MISO/misopy/settings.py
  --- src/MISO/misopy/settings.py	(original)
  +++ src/MISO/misopy/settings.py	(refactored)
  @@ -6,7 +6,7 @@

   import misopy
   from misopy.parse_csv import *
  -import ConfigParser
  +import configparser

   miso_path = os.path.dirname(os.path.abspath(os.path.expanduser(__file__)))

  @@ -18,7 +18,7 @@
           ignores section headers, so make sure each option is unique in the file
           returns a dictionary with all the options mapped to their values.
           """
  -        config = ConfigParser.ConfigParser()
  +        config = configparser.ConfigParser()

           if path != None:
               cls.settings_path = path
  @@ -28,10 +28,10 @@
                                                "settings",
                                                "miso_settings.txt")

  -        print "Using MISO settings file: %s" %(cls.settings_path)
  +        print("Using MISO settings file: %s" %(cls.settings_path))
           if not os.path.isfile(cls.settings_path):
  -            print "Error: Settings file %s does not exist." \
  -                %(cls.settings_path)
  +            print("Error: Settings file %s does not exist." \
  +                %(cls.settings_path))
               sys.exit(1)
           cls.parsed_settings = config.read(cls.settings_path)

  @@ -71,8 +71,8 @@

           for name in param_names:
               if name not in cls.global_settings:
  -                raise Exception, "Error: need %s parameter to be set in settings file." \
  -                      %(name)
  +                raise Exception("Error: need %s parameter to be set in settings file." \
  +                      %(name))
               sampler_params[name] = cls.global_settings[name]
           # Record optional parameters
           for name in opt_param_names:
  @@ -138,8 +138,8 @@
               if not ((strandedness == "fr-unstranded") or \
                       (strandedness == "fr-firststrand") or \
                       (strandedness == "fr-secondstrand")):
  -                print "Error: Invalid strand parameter %s" \
  -                    %(strandedness)
  +                print("Error: Invalid strand parameter %s" \
  +                    %(strandedness))
                   sys.exit(1)
           return strandedness

  RefactoringTool: Refactored src/MISO/misopy/summarize_miso.py
  --- src/MISO/misopy/summarize_miso.py	(original)
  +++ src/MISO/misopy/summarize_miso.py	(refactored)
  @@ -28,9 +28,9 @@
   miso_path = os.path.dirname(os.path.abspath(__file__))

   def greeting(parser=None):
  -    print "MISO (Mixture of Isoforms model)"
  -    print "Summarize MISO output to get Psi values and confidence intervals."
  -    print "Use --help argument to view options.\n"
  +    print("MISO (Mixture of Isoforms model)")
  +    print("Summarize MISO output to get Psi values and confidence intervals.")
  +    print("Use --help argument to view options.\n")
       if parser is not None:
           parser.print_help()

  @@ -61,11 +61,11 @@
           use_compressed = \
               os.path.abspath(os.path.expanduser(options.use_compressed))
           if not os.path.exists(use_compressed):
  -            print "Error: mapping filename from event IDs to compressed IDs %s " \
  -                  "is not found." %(use_compressed)
  +            print("Error: mapping filename from event IDs to compressed IDs %s " \
  +                  "is not found." %(use_compressed))
               sys.exit(1)
           else:
  -            print "Compression being used."
  +            print("Compression being used.")

       ##
       ## Summarizing samples
  @@ -75,7 +75,7 @@
               os.path.abspath(os.path.expanduser(options.summarize_samples[0]))
           if options.summary_label != None:
               samples_label = options.summary_label
  -            print "Using summary label: %s" %(samples_label)
  +            print("Using summary label: %s" %(samples_label))
           else:
               samples_label = \
                   os.path.basename(os.path.expanduser(samples_dir))
  RefactoringTool: Refactored src/MISO/misopy/test_cluster.py
  --- src/MISO/misopy/test_cluster.py	(original)
  +++ src/MISO/misopy/test_cluster.py	(refactored)
  @@ -27,7 +27,7 @@
           """
           Test MISO on cluster.
           """
  -        print "Testing single-end SE event interface..."
  +        print("Testing single-end SE event interface...")

           ##
           ## Try running MISO on cluster using default settings.
  @@ -51,14 +51,14 @@
                                                          read_len,
                                                          overhang_len,
                                                          event_type)
  -        print "Executing: %s" %(miso_cmd)
  +        print("Executing: %s" %(miso_cmd))
           os.system(miso_cmd)

       def test_cluster_gene_psi(self):
           """
           Test gene-level Psi inferences using SAM/BAM reads.
           """
  -        print "Testing gene-level Psi..."
  +        print("Testing gene-level Psi...")
           sam_dir = os.path.join(self.tests_output_dir, "sam-output")
           bam_filename = os.path.join(sam_dir, "c2c12.Atp2b1.sorted.bam")

  @@ -73,7 +73,7 @@
                                                   gff_filename,
                                                   gff_index_dir)

  -        print "Executing: %s" %(index_cmd)
  +        print("Executing: %s" %(index_cmd))
           os.system(index_cmd)

           output_dir = os.path.join(self.tests_output_dir, "gene-psi-output")
  @@ -87,7 +87,7 @@
                        read_len,
                        insert_mean,
                        insert_sd)
  -        print "Executing: %s" %(miso_cmd)
  +        print("Executing: %s" %(miso_cmd))
           os.system(miso_cmd)


  RefactoringTool: Refactored src/MISO/misopy/test_miso.py
  --- src/MISO/misopy/test_miso.py	(original)
  +++ src/MISO/misopy/test_miso.py	(refactored)
  @@ -4,7 +4,7 @@
   import unittest

   import pysam
  -import sam_utils
  +from . import sam_utils

   class TestMISO(unittest.TestCase):
       """
  @@ -36,14 +36,14 @@
           The 'a' ensures this runs first.
           """

  -        print "Testing conversion of SAM to BAM..."
  +        print("Testing conversion of SAM to BAM...")
           output_dir = \
               os.path.join(self.tests_output_dir, "sam-output")
           sam_to_bam_cmd = \
               "%s --convert %s %s" %(self.sam_to_bam_script,
                                      self.test_sam_filename,
                                      output_dir)
  -        print "Executing: %s" %(sam_to_bam_cmd)
  +        print("Executing: %s" %(sam_to_bam_cmd))
           os.system(sam_to_bam_cmd)

           # Make sure conversion worked; sorted, indexed BAM file is outputted
  @@ -85,10 +85,10 @@
           minus_target_strand = "-"
           # fr-unstranded: both strand reads should match
           # either target strand
  -        print "Testing fr-unstranded..."
  +        print("Testing fr-unstranded...")
           for curr_read in [f_read, r_read]:
               for target in [plus_target_strand, minus_target_strand]:
  -                print "Checking read ", curr_read.qname, " against ", target
  +                print("Checking read ", curr_read.qname, " against ", target)
                   assert(sam_utils.read_matches_strand(curr_read,
                                                        target,
                                                        "fr-unstranded") == True), \
  @@ -96,7 +96,7 @@
           # fr-firststrand: forward read must match target strand,
           # i.e. +read matches +target, and -read matches -target
           # test +read
  -        print "Testing fr-firststrand..."
  +        print("Testing fr-firststrand...")
           assert(sam_utils.read_matches_strand(f_read,
                                                plus_target_strand,
                                                "fr-firststrand") == True), \
  @@ -134,7 +134,7 @@

           The 'z' ensures this runs last.
           """
  -        print "Testing gene-level Psi..."
  +        print("Testing gene-level Psi...")
           sam_dir = os.path.join(self.tests_output_dir, "sam-output")
           bam_filename = os.path.join(sam_dir, "c2c12.Atp2b1.sorted.bam")

  @@ -152,12 +152,12 @@
                                        "genes",
                                        "Atp2b1",
                                        "indexed")
  -        print "Testing GFF indexing of: %s" %(gff_filename)
  +        print("Testing GFF indexing of: %s" %(gff_filename))
           index_cmd = "%s --index %s %s" %(self.index_gff_script,
                                            gff_filename,
                                            gff_index_dir)

  -        print "Executing: %s" %(index_cmd)
  +        print("Executing: %s" %(index_cmd))
           os.system(index_cmd)

           output_dir = os.path.join(self.tests_output_dir,
  @@ -168,7 +168,7 @@
                        bam_filename,
                        output_dir,
                        read_len)
  -        print "Executing: %s" %(miso_cmd)
  +        print("Executing: %s" %(miso_cmd))
           os.system(miso_cmd)

   def main():
  RefactoringTool: Refactored src/MISO/misopy/sashimi_plot/Sashimi.py
  --- src/MISO/misopy/sashimi_plot/Sashimi.py	(original)
  +++ src/MISO/misopy/sashimi_plot/Sashimi.py	(refactored)
  @@ -55,9 +55,9 @@
           else:
               fig_height = self.settings["fig_height"]
               fig_width = self.settings["fig_width"]
  -            print "Reading dimensions from settings..."
  -            print " - Height: %.2f" %(float(fig_height))
  -            print " - Width: %.2f" %(float(fig_width))
  +            print("Reading dimensions from settings...")
  +            print(" - Height: %.2f" %(float(fig_height)))
  +            print(" - Width: %.2f" %(float(fig_width)))
               self.dimensions = [fig_width, fig_height]


  @@ -69,13 +69,13 @@
           self.output_filename = os.path.join(self.output_dir, plot_basename)

       def setup_figure(self):
  -        print "Setting up plot using dimensions: ", self.dimensions
  +        print("Setting up plot using dimensions: ", self.dimensions)
           plt.figure(figsize=self.dimensions)

           # If asked, use sans serif fonts
           font_size = self.settings["font_size"]
           if self.settings["sans_serif"]:
  -            print "Using sans serif fonts."
  +            print("Using sans serif fonts.")
               plotting.make_sans_serif(font_size=font_size)

       def save_plot(self, plot_label=None):
  @@ -84,7 +84,7 @@
           the file type.
           """
           if self.output_filename == None:
  -            raise Exception, "sashimi_plot does not know where to save the plot."
  +            raise Exception("sashimi_plot does not know where to save the plot.")
           output_fname = None
           if plot_label is not None:
               # Use custom plot label if given
  @@ -94,5 +94,5 @@
                   os.path.dirname(dirname, "%s.%s" %(plot_label, ext))
           else:
               output_fname = self.output_filename
  -        print "Saving plot to: %s" %(output_fname)
  +        print("Saving plot to: %s" %(output_fname))
           plt.savefig(output_fname)
  --- src/MISO/misopy/sashimi_plot/plot.py	(original)
  RefactoringTool: Refactored src/MISO/misopy/sashimi_plot/plot.py
  +++ src/MISO/misopy/sashimi_plot/plot.py	(refactored)
  @@ -2,8 +2,8 @@
   ## Old Sashimi plot interface
   ##
   def main():
  -    print "plot.py interface to Sashimi plot is now deprecated. " \
  -          "Please run \'sashimi_plot\' instead."
  +    print("plot.py interface to Sashimi plot is now deprecated. " \
  +          "Please run \'sashimi_plot\' instead.")

   if __name__ == "__main__":
       main()
  RefactoringTool: Refactored src/MISO/misopy/sashimi_plot/sashimi_plot.py
  --- src/MISO/misopy/sashimi_plot/sashimi_plot.py	(original)
  +++ src/MISO/misopy/sashimi_plot/sashimi_plot.py	(refactored)
  @@ -43,8 +43,8 @@
       Plot a Bayes factor distribution from a .miso_bf file.
       """
       if not bf_filename.endswith(".miso_bf"):
  -        print "WARNING: %s does not end in .miso_bf, are you sure it is the " \
  -              "output of a MISO samples comparison?" %(bf_filename)
  +        print("WARNING: %s does not end in .miso_bf, are you sure it is the " \
  +              "output of a MISO samples comparison?" %(bf_filename))

       # Load BF data
       data, h = csv2dictlist_raw(bf_filename)
  @@ -64,8 +64,8 @@
           delta_psi = event['diff']

           if type(bf) == str and "," in bf:
  -            print "WARNING: %s is a multi-isoform event, skipping..." \
  -                %(event)
  +            print("WARNING: %s is a multi-isoform event, skipping..." \
  +                %(event))
               continue
           else:
               # Impose upper limit on Bayes factor
  @@ -77,12 +77,12 @@
       bfs_and_deltas = array(bfs_and_deltas)
       num_events = len(bfs_and_deltas)

  -    print "Loaded %d event comparisons." %(num_events)
  +    print("Loaded %d event comparisons." %(num_events))

       output_filename = sashimi_obj.output_filename

  -    print "Plotting Bayes factors distribution"
  -    print "  - Output filename: %s" %(output_filename)
  +    print("Plotting Bayes factors distribution")
  +    print("  - Output filename: %s" %(output_filename))
       bf_thresholds = settings["bf_thresholds"]
       bar_color = settings["bar_color"]

  @@ -90,11 +90,11 @@
       num_events_used = sum(bfs_and_deltas[:, 0] >= min_bf_thresh)
       for thresh in bf_thresholds:
           if type(thresh) != int:
  -            print "Error: BF thresholds must be integers."
  +            print("Error: BF thresholds must be integers.")
               sys.exit(1)
  -    print "Using BF thresholds: "
  -    print bf_thresholds
  -    print "Using bar color: %s" %(bar_color)
  +    print("Using BF thresholds: ")
  +    print(bf_thresholds)
  +    print("Using bar color: %s" %(bar_color))
       plot_cumulative_bars(bfs_and_deltas[:, 0],
                            bf_thresholds,
                            bar_color=bar_color,
  @@ -124,11 +124,11 @@
       Also plots MISO estimates and Psi values.
       """
       if not os.path.isfile(settings_filename):
  -        print "Error: settings filename %s not found." %(settings_filename)
  +        print("Error: settings filename %s not found." %(settings_filename))
           sys.exit(1)

       if not os.path.isdir(pickle_dir):
  -        print "Error: event pickle directory %s not found." %(pickle_dir)
  +        print("Error: event pickle directory %s not found." %(pickle_dir))
           sys.exit(1)

       # Retrieve the full pickle filename
  @@ -137,20 +137,20 @@

       # Check that file basename exists
       if len(glob.glob("%s*" %(genes_filename))) == 0:
  -        raise Exception, "Cannot find file %s. Are you sure the events " \
  +        raise Exception("Cannot find file %s. Are you sure the events " \
                            "were indexed with the latest version of index_gff.py?" \
  -                         %(genes_filename)
  +                         %(genes_filename))

       event_to_filenames = shelve.open(genes_filename)
       if event_name not in event_to_filenames:
  -        raise Exception, "Event %s not found in pickled directory %s. " \
  +        raise Exception("Event %s not found in pickled directory %s. " \
                 "Are you sure this is the right directory for the event?" \
  -              %(event_name, pickle_dir)
  +              %(event_name, pickle_dir))

       pickle_filename = event_to_filenames[event_name]

       if no_posteriors:
  -        print "Asked to not plot MISO posteriors."
  +        print("Asked to not plot MISO posteriors.")

       plot_density_from_file(settings_filename, pickle_filename, event_name,
                              output_dir,
  @@ -167,7 +167,7 @@
       Plot insert length distribution.
       """
       if not os.path.isfile(settings_filename):
  -        print "Error: settings filename %s not found." %(settings_filename)
  +        print("Error: settings filename %s not found." %(settings_filename))
           sys.exit(1)
       plot_name = os.path.basename(insert_len_filename)
       sashimi_obj = Sashimi(plot_name, output_dir,
  @@ -178,16 +178,16 @@
       sashimi_obj.setup_figure()
       s = plt.subplot(1, 1, 1)

  -    print "Plotting insert length distribution..."
  -    print "  - Distribution file: %s" %(insert_len_filename)
  -    print "  - Output plot: %s" %(output_filename)
  +    print("Plotting insert length distribution...")
  +    print("  - Distribution file: %s" %(insert_len_filename))
  +    print("  - Output plot: %s" %(output_filename))

       insert_dist, params = pe_utils.load_insert_len(insert_len_filename)

       mean, sdev, dispersion, num_pairs \
             = pe_utils.compute_insert_len_stats(insert_dist)
  -    print "min insert: %.1f" %(min(insert_dist))
  -    print "max insert: %.1f" %(max(insert_dist))
  +    print("min insert: %.1f" %(min(insert_dist)))
  +    print("max insert: %.1f" %(max(insert_dist)))
       plt.title("%s (%d read-pairs)" \
                 %(plot_name,
                   num_pairs),
  @@ -211,10 +211,10 @@
       sashimi_obj.save_plot()

   def greeting():
  -    print "Sashimi plot: Visualize spliced RNA-Seq reads along gene models. " \
  -          "Part of the MISO (Mixture of Isoforms model) framework."
  -    print "See --help for usage.\n"
  -    print "Manual available at: http://genes.mit.edu/burgelab/miso/docs/sashimi.html\n"
  +    print("Sashimi plot: Visualize spliced RNA-Seq reads along gene models. " \
  +          "Part of the MISO (Mixture of Isoforms model) framework.")
  +    print("See --help for usage.\n")
  +    print("Manual available at: http://genes.mit.edu/burgelab/miso/docs/sashimi.html\n")


   def main():
  @@ -254,7 +254,7 @@
           sys.exit(1)

       if options.output_dir == None:
  -        print "Error: need --output-dir"
  +        print("Error: need --output-dir")
           sys.exit(1)

       output_dir = os.path.abspath(os.path.expanduser(options.output_dir))
  RefactoringTool: Refactored src/MISO/misopy/sashimi_plot/plot_utils/plot_gene.py
  --- src/MISO/misopy/sashimi_plot/plot_utils/plot_gene.py	(original)
  +++ src/MISO/misopy/sashimi_plot/plot_utils/plot_gene.py	(refactored)
  @@ -57,9 +57,9 @@
           try:
               subset_reads = bamfile.fetch(reference=chrom, start=tx_start,end=tx_end)
           except ValueError as e:
  -            print "Error retrieving files from %s: %s" %(chrom, str(e))
  -            print "Are you sure %s appears in your BAM file?" %(chrom)
  -            print "Aborting plot..."
  +            print("Error retrieving files from %s: %s" %(chrom, str(e)))
  +            print("Are you sure %s appears in your BAM file?" %(chrom))
  +            print("Aborting plot...")
               return axvar
           # wiggle, jxns = readsToWiggle_pysam(subset_reads, tx_start, tx_end)
           # p1 = subprocess.Popen(["samtools", "view", "-F", "0x4", file_name,], stdout=subprocess.PIPE)
  @@ -77,8 +77,8 @@
           p1.stdout.close()
           output,err = p2.communicate()
           if err:
  -            print err
  -            print 'Setting the number of mapped read to 1.'
  +            print(err)
  +            print('Setting the number of mapped read to 1.')
               cover = 1
           else:
               cover = int(output) / 1e6
  @@ -87,7 +87,7 @@
       coverage = np.mean(all_c)
       wiggle = 1e3 * wiggle / coverage / bamfile_num
       # junction_width_scale = settings["junction_width_scale"]
  -    for j_key in jxns.keys():
  +    for j_key in list(jxns.keys()):
           jxns[j_key] = int(round(1.0 * jxns[j_key] / bamfile_num, 0))
       # gene_reads = sam_utils.fetch_bam_reads_in_gene(bamfile, gene_obj.chrom,\
       #     tx_start, tx_end, gene_obj)
  @@ -132,7 +132,7 @@
       show_text_background = settings["text_background"]
       maxy = 0
       for jxn in jxns:
  -        leftss, rightss = map(int, jxn.split(":"))
  +        leftss, rightss = list(map(int, jxn.split(":")))

           ss1, ss2 = [graphcoords[leftss - tx_start - 1],\
               graphcoords[rightss - tx_start]]
  @@ -246,7 +246,7 @@
               prefix = ''
               for item in file_names:
                   if '-' in item:
  -                    start, end = map(int, item.split('-'))
  +                    start, end = list(map(int, item.split('-')))
                       for i in range(start, end+1):
                           files.append(bam_files[i-1])  # here we suppose that the index of files begins from 0
                           prefix = label_prefixs[i-1]
  @@ -270,7 +270,7 @@
               pre_group_name += " IncLevel: {0:.2f}".format(inc/num_file)
               sample_labels.append(pre_group_name)
           except:
  -            print 'read grouping info failed.'
  +            print('read grouping info failed.')
               group_file.close()
               sys.exit(1)
       sample_colors = cm.rainbow(np.linspace(0, 1, group_num)) * 0.85
  @@ -312,8 +312,8 @@
       show_xlabel = settings["show_xlabel"]
       if plot_title is None:
           plot_title = event
  -    print "Using intron scale ", intron_scale
  -    print "Using exon scale ", exon_scale
  +    print("Using intron scale ", intron_scale)
  +    print("Using exon scale ", exon_scale)

       # Always show y-axis for read densities for now
       showYaxis = True
  @@ -333,8 +333,8 @@
           # if the group color is customized by the user
           if len(colors) != len(group_colors):
               print('\033[0;31;m') # change the print color as red
  -            print("The number of custom colors is {0} which doesn't match the group number {1}. The program uses the "
  -                  "rainbow color as default.".format(len(colors), len(group_colors)))
  +            print(("The number of custom colors is {0} which doesn't match the group number {1}. The program uses the "
  +                  "rainbow color as default.".format(len(colors), len(group_colors))))
               print('\033[0m')  # set the color as default value
               colors = settings["colors"] = group_colors

  @@ -376,7 +376,7 @@
           # Read sample label
           sample_label = settings["sample_labels"][i]

  -        print "Reading sample label: %s" %(sample_label)
  +        print("Reading sample label: %s" %(sample_label))
           # print "Processing BAM: %s" %(bam_file)

           plotted_ax, maxy = plot_density_single(settings, sample_label,
  @@ -400,9 +400,9 @@
                       (i, gene_posterior_ratio - 1))

                   if not os.path.isfile(miso_file):
  -                    print "Warning: MISO file %s not found" %(miso_file)
  -
  -                print "Loading MISO file: %s" %(miso_file)
  +                    print("Warning: MISO file %s not found" %(miso_file))
  +
  +                print("Loading MISO file: %s" %(miso_file))
                   plot_posterior_single(miso_file, ax2, posterior_bins,
                                         showXaxis=showXaxis, show_ylabel=False,
                                         font_size=font_size,
  @@ -411,7 +411,7 @@
                   box(on=False)
                   xticks([])
                   yticks([])
  -                print "Posterior plot failed."
  +                print("Posterior plot failed.")

       ##
       ## Figure out correct y-axis values
  @@ -433,7 +433,7 @@
       universal_yticks = linspace(0, max_used_yval,
                                   nyticks + 1)
       # Round up yticks
  -    universal_ticks = map(math.ceil, universal_yticks)
  +    universal_ticks = list(map(math.ceil, universal_yticks))
       for sample_num, curr_ax in enumerate(plotted_axes):
           if showYaxis:
               curr_ax.set_ybound(lower=fake_ymin, upper=max_used_yval)
  @@ -537,7 +537,7 @@
       for read in reads:
           # Skip reads with no CIGAR string
           if read.cigar is None:
  -            print "Skipping read with no CIGAR string: %s" %(read.cigar)
  +            print("Skipping read with no CIGAR string: %s" %(read.cigar))
               continue
           cigar_str = sam_utils.sam_cigar_to_str(read.cigar)

  @@ -552,8 +552,8 @@
           for cigar_part in read.cigar:
               if cigar_part[0] == 1 or \
                  cigar_part[0] == 2:
  -                print "Skipping read with CIGAR %s" \
  -                      %(cigar_str)
  +                print("Skipping read with CIGAR %s" \
  +                      %(cigar_str))
                   skipit = True
           if skipit:
               continue
  @@ -769,7 +769,7 @@
       axis_color = "k"
       for shown_axis in axes_to_show:
           if shown_axis in axvar.spines:
  -            print "Setting color on %s axis" %(shown_axis)
  +            print("Setting color on %s axis" %(shown_axis))
               axvar.spines[shown_axis].set_linewidth(axis_size)
               axvar.xaxis.set_tick_params(size=tick_size,
                                           color=axis_color)
  @@ -822,8 +822,8 @@
                             settings_filename=settings_f,
                             no_posteriors=no_posteriors)

  -    print "Plotting read densities and MISO estimates along event..."
  -    print "  - Event: %s" %(event)
  +    print("Plotting read densities and MISO estimates along event...")
  +    print("  - Event: %s" %(event))

       settings = sashimi_obj.settings
       if no_posteriors:
  RefactoringTool: Refactored src/MISO/misopy/sashimi_plot/plot_utils/plot_settings.py
  --- src/MISO/misopy/sashimi_plot/plot_utils/plot_settings.py	(original)
  +++ src/MISO/misopy/sashimi_plot/plot_utils/plot_settings.py	(refactored)
  @@ -5,7 +5,7 @@
   import os
   import ast

  -import ConfigParser
  +import configparser

   import misopy
   import misopy.miso_utils as miso_utils
  @@ -84,14 +84,14 @@
       """
       settings = get_default_settings()

  -    config = ConfigParser.ConfigParser()
  +    config = configparser.ConfigParser()

  -    print "Reading settings from: %s" %(settings_filename)
  +    print("Reading settings from: %s" %(settings_filename))
       config.read(settings_filename)

       for section in config.sections():
           for option in config.options(section):
  -            print "Parsing %s:%s" %(section, option)
  +            print("Parsing %s:%s" %(section, option))
               if option in FLOAT_PARAMS:
                   settings[option] = config.getfloat(section, option)
               elif option in INT_PARAMS:
  @@ -129,9 +129,9 @@

       if not (num_labels == num_bams == num_colors) and not(settings["group_info"]):
           print('\033[0;31;m')  # change the print color as red
  -        print "Error: Must provide sample label and color for each entry in bam_files!"
  -        print "  - Provided %d labels, %d BAMs, %d colors" \
  -            %(num_labels, num_bams, num_colors)
  +        print("Error: Must provide sample label and color for each entry in bam_files!")
  +        print("  - Provided %d labels, %d BAMs, %d colors" \
  +            %(num_labels, num_bams, num_colors))
           print('\033[0m')  # set the color as default value
           sys.exit(1)

  @@ -149,7 +149,7 @@

       if "coverages" in settings:
           coverages = ast.literal_eval(settings["coverages"])
  -        coverages = map(float, coverages)
  +        coverages = list(map(float, coverages))
           # Normalize coverages per M
           coverages = [x / 1e6  for x in coverages]
       else:
  @@ -158,7 +158,7 @@

       if len(settings["coverages"]) != len(settings["sample_labels"]):
           print('\033[0;31;m')  # change the print color as red
  -        print "Error: Must provide a coverage value for each sample or leave coverages unset."
  +        print("Error: Must provide a coverage value for each sample or leave coverages unset.")
           print('\033[0m')  # set the color as default value
           sys.exit(1)

  RefactoringTool: Refactored src/MISO/misopy/sashimi_plot/plot_utils/plotting.py
  --- src/MISO/misopy/sashimi_plot/plot_utils/plotting.py	(original)
  +++ src/MISO/misopy/sashimi_plot/plot_utils/plotting.py	(refactored)
  @@ -93,7 +93,7 @@


   def show_spines(ax,spines):
  -    for loc, spine in ax.spines.iteritems():
  +    for loc, spine in ax.spines.items():
           if loc not in spines:
               spine.set_color('none') # don't draw spine

  @@ -170,7 +170,7 @@
       plt.rcParams['ps.useafm'] = True
       plt.rcParams['pdf.fonttype'] = 42
       #rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})
  -    print "Setting to FreeSans"
  +    print("Setting to FreeSans")
       rc('font',**{'family':'sans-serif','sans-serif':['FreeSans']})
       plt.rcParams['pdf.fonttype'] = 42
       plt.rcParams['font.size'] = font_size
  RefactoringTool: Refactored src/MISO/misopy/sashimi_plot/plot_utils/samples_plotter.py
  --- src/MISO/misopy/sashimi_plot/plot_utils/samples_plotter.py	(original)
  +++ src/MISO/misopy/sashimi_plot/plot_utils/samples_plotter.py	(refactored)
  @@ -75,7 +75,7 @@
                   plt.ylabel('Frequency (Isoform %d)' %(c + 1))
               plt.subplots_adjust(wspace=0.5)
           else:
  -            raise Exception, "Invalid number of isoforms %d" %(num_isoforms)
  +            raise Exception("Invalid number of isoforms %d" %(num_isoforms))
           return plot_handle

       def plot_two_iso_samples(self, fig=None, isoform_index=0, num_rows=1, num_cols=1, subplot_start=1,
  @@ -121,7 +121,7 @@
           # Normalize samples
           if normed:
               yticks = list(plt.gca().get_yticks())
  -            print "yticks: ", yticks
  +            print("yticks: ", yticks)
               ytick_labels = ["%.2f" %(float(ytick) / float(normed)) for ytick in yticks]
               ax.set_yticklabels(ytick_labels)
   #            samples_to_plot = samples_to_plot / float(len(samples_to_plot))
  RefactoringTool: Refactored src/rmats2sashimiplot/rmats2sashimiplot.py
  --- src/rmats2sashimiplot/rmats2sashimiplot.py	(original)
  +++ src/rmats2sashimiplot/rmats2sashimiplot.py	(refactored)
  @@ -1,4 +1,4 @@
  -from __future__ import print_function
  +

   import os
   import sys
  RefactoringTool: Files that were modified:
  RefactoringTool: src/MISO/__init__.py
  RefactoringTool: src/MISO/test.py
  RefactoringTool: src/MISO/misopy/Gene.py
  RefactoringTool: src/MISO/misopy/__init__.py
  RefactoringTool: src/MISO/misopy/as_events.py
  RefactoringTool: src/MISO/misopy/cluster_utils.py
  RefactoringTool: src/MISO/misopy/compare_miso.py
  RefactoringTool: src/MISO/misopy/credible_intervals.py
  RefactoringTool: src/MISO/misopy/exon_utils.py
  RefactoringTool: src/MISO/misopy/filter_events.py
  RefactoringTool: src/MISO/misopy/gff_utils.py
  RefactoringTool: src/MISO/misopy/hypothesis_test.py
  RefactoringTool: src/MISO/misopy/index_gff.py
  RefactoringTool: src/MISO/misopy/json_utils.py
  RefactoringTool: src/MISO/misopy/kde_subclass.py
  RefactoringTool: src/MISO/misopy/legacy_test_pysplicing.py
  RefactoringTool: src/MISO/misopy/misc_utils.py
  RefactoringTool: src/MISO/misopy/miso.py
  RefactoringTool: src/MISO/misopy/miso_db.py
  RefactoringTool: src/MISO/misopy/miso_pack.py
  RefactoringTool: src/MISO/misopy/miso_sampler.py
  RefactoringTool: src/MISO/misopy/miso_utils.py
  RefactoringTool: src/MISO/misopy/miso_zip.py
  RefactoringTool: src/MISO/misopy/module_availability.py
  RefactoringTool: src/MISO/misopy/parse_csv.py
  RefactoringTool: src/MISO/misopy/parse_gene.py
  RefactoringTool: src/MISO/misopy/pe_utils.py
  RefactoringTool: src/MISO/misopy/pickle_utils.py
  RefactoringTool: src/MISO/misopy/py2c_gene.py
  RefactoringTool: src/MISO/misopy/read_simulator.py
  RefactoringTool: src/MISO/misopy/reads_utils.py
  RefactoringTool: src/MISO/misopy/run_events_analysis.py
  RefactoringTool: src/MISO/misopy/run_miso.py
  RefactoringTool: src/MISO/misopy/sam_rpkm.py
  RefactoringTool: src/MISO/misopy/sam_to_bam.py
  RefactoringTool: src/MISO/misopy/sam_utils.py
  RefactoringTool: src/MISO/misopy/samples_utils.py
  RefactoringTool: src/MISO/misopy/settings.py
  RefactoringTool: src/MISO/misopy/summarize_miso.py
  RefactoringTool: src/MISO/misopy/test_cluster.py
  RefactoringTool: src/MISO/misopy/test_miso.py
  RefactoringTool: src/MISO/misopy/sashimi_plot/Sashimi.py
  RefactoringTool: src/MISO/misopy/sashimi_plot/plot.py
  RefactoringTool: src/MISO/misopy/sashimi_plot/sashimi_plot.py
  RefactoringTool: src/MISO/misopy/sashimi_plot/plot_utils/plot_gene.py
  RefactoringTool: src/MISO/misopy/sashimi_plot/plot_utils/plot_settings.py
  RefactoringTool: src/MISO/misopy/sashimi_plot/plot_utils/plotting.py
  RefactoringTool: src/MISO/misopy/sashimi_plot/plot_utils/samples_plotter.py
  RefactoringTool: src/rmats2sashimiplot/rmats2sashimiplot.py
  Using pip 23.1.2 from $PREFIX/lib/python3.8/site-packages/pip (python 3.8)
  Non-user install because user site-packages disabled
  Ignoring indexes: https://pypi.org/simple
  Created temporary directory: /private/tmp/pip-build-tracker-4z12e36u
  Initialized build tracking at /private/tmp/pip-build-tracker-4z12e36u
  Created build tracker: /private/tmp/pip-build-tracker-4z12e36u
  Entered build tracker: /private/tmp/pip-build-tracker-4z12e36u
  Created temporary directory: /private/tmp/pip-install-8jvsihs7
  Created temporary directory: /private/tmp/pip-ephem-wheel-cache-_kle568w
  Processing $SRC_DIR
    Added file://$SRC_DIR to build tracker '/private/tmp/pip-build-tracker-4z12e36u'
    Created temporary directory: /private/tmp/pip-modern-metadata-fymfjny6
    Preparing metadata (pyproject.toml): started
    Running command Preparing metadata (pyproject.toml)
    /opt/mambaforge/envs/bioconda/conda-bld/rmats2sashimiplot_1685182621597/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placeh/lib/python3.8/site-packages/setuptools/_distutils/dist.py:250: UserWarning: 'licence' distribution option is deprecated; use 'license'
      warnings.warn(msg)
    running dist_info
    creating /private/tmp/pip-modern-metadata-fymfjny6/rmats2sashimiplot.egg-info
    writing /private/tmp/pip-modern-metadata-fymfjny6/rmats2sashimiplot.egg-info/PKG-INFO
    writing dependency_links to /private/tmp/pip-modern-metadata-fymfjny6/rmats2sashimiplot.egg-info/dependency_links.txt
    writing entry points to /private/tmp/pip-modern-metadata-fymfjny6/rmats2sashimiplot.egg-info/entry_points.txt
    writing top-level names to /private/tmp/pip-modern-metadata-fymfjny6/rmats2sashimiplot.egg-info/top_level.txt
    writing manifest file '/private/tmp/pip-modern-metadata-fymfjny6/rmats2sashimiplot.egg-info/SOURCES.txt'
    reading manifest file '/private/tmp/pip-modern-metadata-fymfjny6/rmats2sashimiplot.egg-info/SOURCES.txt'
    reading manifest template 'MANIFEST.in'
    adding license file 'LICENSE'
    writing manifest file '/private/tmp/pip-modern-metadata-fymfjny6/rmats2sashimiplot.egg-info/SOURCES.txt'
    creating '/private/tmp/pip-modern-metadata-fymfjny6/rmats2sashimiplot-2.0.4.dist-info'
    Preparing metadata (pyproject.toml): finished with status 'done'
    Source in $SRC_DIR has version 2.0.4, which satisfies requirement rmats2sashimiplot==2.0.4 from file://$SRC_DIR
    Removed rmats2sashimiplot==2.0.4 from file://$SRC_DIR from build tracker '/private/tmp/pip-build-tracker-4z12e36u'
  Created temporary directory: /private/tmp/pip-unpack-_up66bw5
  Building wheels for collected packages: rmats2sashimiplot
    Created temporary directory: /private/tmp/pip-wheel-zn917w3e
    Destination directory: /private/tmp/pip-wheel-zn917w3e
    Building wheel for rmats2sashimiplot (pyproject.toml): started
    Running command Building wheel for rmats2sashimiplot (pyproject.toml)
    /opt/mambaforge/envs/bioconda/conda-bld/rmats2sashimiplot_1685182621597/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placeh/lib/python3.8/site-packages/setuptools/_distutils/dist.py:250: UserWarning: 'licence' distribution option is deprecated; use 'license'
      warnings.warn(msg)
    running bdist_wheel
    running build
    running build_py
    creating build
    creating build/lib
    creating build/lib/rmats2sashimiplot
    copying src/rmats2sashimiplot/__init__.py -> build/lib/rmats2sashimiplot
    copying src/rmats2sashimiplot/rmats2sashimiplot.py -> build/lib/rmats2sashimiplot
    creating build/lib/MISO
    copying src/MISO/__init__.py -> build/lib/MISO
    copying src/MISO/test.py -> build/lib/MISO
    creating build/lib/MISO/misopy
    copying src/MISO/misopy/credible_intervals.py -> build/lib/MISO/misopy
    copying src/MISO/misopy/miso_utils.py -> build/lib/MISO/misopy
    copying src/MISO/misopy/run_events_analysis.py -> build/lib/MISO/misopy
    copying src/MISO/misopy/miso_sampler.py -> build/lib/MISO/misopy
    copying src/MISO/misopy/sam_utils.py -> build/lib/MISO/misopy
    copying src/MISO/misopy/reads_utils.py -> build/lib/MISO/misopy
    copying src/MISO/misopy/legacy_test_pysplicing.py -> build/lib/MISO/misopy
    copying src/MISO/misopy/gff_utils.py -> build/lib/MISO/misopy
    copying src/MISO/misopy/as_events.py -> build/lib/MISO/misopy
    copying src/MISO/misopy/miso_zip.py -> build/lib/MISO/misopy
    copying src/MISO/misopy/exon_utils.py -> build/lib/MISO/misopy
    copying src/MISO/misopy/run_miso.py -> build/lib/MISO/misopy
    copying src/MISO/misopy/__init__.py -> build/lib/MISO/misopy
    copying src/MISO/misopy/hypothesis_test.py -> build/lib/MISO/misopy
    copying src/MISO/misopy/sam_to_bam.py -> build/lib/MISO/misopy
    copying src/MISO/misopy/misc_utils.py -> build/lib/MISO/misopy
    copying src/MISO/misopy/sam_rpkm.py -> build/lib/MISO/misopy
    copying src/MISO/misopy/index_gff.py -> build/lib/MISO/misopy
    copying src/MISO/misopy/filter_events.py -> build/lib/MISO/misopy
    copying src/MISO/misopy/miso_db.py -> build/lib/MISO/misopy
    copying src/MISO/misopy/py2c_gene.py -> build/lib/MISO/misopy
    copying src/MISO/misopy/miso.py -> build/lib/MISO/misopy
    copying src/MISO/misopy/cluster_utils.py -> build/lib/MISO/misopy
    copying src/MISO/misopy/miso_pack.py -> build/lib/MISO/misopy
    copying src/MISO/misopy/test_miso.py -> build/lib/MISO/misopy
    copying src/MISO/misopy/settings.py -> build/lib/MISO/misopy
    copying src/MISO/misopy/test_cluster.py -> build/lib/MISO/misopy
    copying src/MISO/misopy/parse_csv.py -> build/lib/MISO/misopy
    copying src/MISO/misopy/summarize_miso.py -> build/lib/MISO/misopy
    copying src/MISO/misopy/Gene.py -> build/lib/MISO/misopy
    copying src/MISO/misopy/compare_miso.py -> build/lib/MISO/misopy
    copying src/MISO/misopy/samples_utils.py -> build/lib/MISO/misopy
    copying src/MISO/misopy/pickle_utils.py -> build/lib/MISO/misopy
    copying src/MISO/misopy/kde_subclass.py -> build/lib/MISO/misopy
    copying src/MISO/misopy/parse_gene.py -> build/lib/MISO/misopy
    copying src/MISO/misopy/json_utils.py -> build/lib/MISO/misopy
    copying src/MISO/misopy/module_availability.py -> build/lib/MISO/misopy
    copying src/MISO/misopy/read_simulator.py -> build/lib/MISO/misopy
    copying src/MISO/misopy/pe_utils.py -> build/lib/MISO/misopy
    creating build/lib/MISO/misopy/sashimi_plot
    copying src/MISO/misopy/sashimi_plot/plot.py -> build/lib/MISO/misopy/sashimi_plot
    copying src/MISO/misopy/sashimi_plot/Sashimi.py -> build/lib/MISO/misopy/sashimi_plot
    copying src/MISO/misopy/sashimi_plot/__init__.py -> build/lib/MISO/misopy/sashimi_plot
    copying src/MISO/misopy/sashimi_plot/sashimi_plot.py -> build/lib/MISO/misopy/sashimi_plot
    creating build/lib/MISO/misopy/sashimi_plot/plot_utils
    copying src/MISO/misopy/sashimi_plot/plot_utils/plot_settings.py -> build/lib/MISO/misopy/sashimi_plot/plot_utils
    copying src/MISO/misopy/sashimi_plot/plot_utils/samples_plotter.py -> build/lib/MISO/misopy/sashimi_plot/plot_utils
    copying src/MISO/misopy/sashimi_plot/plot_utils/plotting.py -> build/lib/MISO/misopy/sashimi_plot/plot_utils
    copying src/MISO/misopy/sashimi_plot/plot_utils/plot_gene.py -> build/lib/MISO/misopy/sashimi_plot/plot_utils
    copying src/MISO/misopy/sashimi_plot/plot_utils/__init__.py -> build/lib/MISO/misopy/sashimi_plot/plot_utils
    installing to build/bdist.macosx-10.9-x86_64/wheel
    running install
    running install_lib
    creating build/bdist.macosx-10.9-x86_64
    creating build/bdist.macosx-10.9-x86_64/wheel
    creating build/bdist.macosx-10.9-x86_64/wheel/rmats2sashimiplot
    copying build/lib/rmats2sashimiplot/__init__.py -> build/bdist.macosx-10.9-x86_64/wheel/rmats2sashimiplot
    copying build/lib/rmats2sashimiplot/rmats2sashimiplot.py -> build/bdist.macosx-10.9-x86_64/wheel/rmats2sashimiplot
    creating build/bdist.macosx-10.9-x86_64/wheel/MISO
    copying build/lib/MISO/__init__.py -> build/bdist.macosx-10.9-x86_64/wheel/MISO
    copying build/lib/MISO/test.py -> build/bdist.macosx-10.9-x86_64/wheel/MISO
    creating build/bdist.macosx-10.9-x86_64/wheel/MISO/misopy
    copying build/lib/MISO/misopy/credible_intervals.py -> build/bdist.macosx-10.9-x86_64/wheel/MISO/misopy
    copying build/lib/MISO/misopy/miso_utils.py -> build/bdist.macosx-10.9-x86_64/wheel/MISO/misopy
    copying build/lib/MISO/misopy/run_events_analysis.py -> build/bdist.macosx-10.9-x86_64/wheel/MISO/misopy
    copying build/lib/MISO/misopy/miso_sampler.py -> build/bdist.macosx-10.9-x86_64/wheel/MISO/misopy
    copying build/lib/MISO/misopy/sam_utils.py -> build/bdist.macosx-10.9-x86_64/wheel/MISO/misopy
    copying build/lib/MISO/misopy/reads_utils.py -> build/bdist.macosx-10.9-x86_64/wheel/MISO/misopy
    copying build/lib/MISO/misopy/legacy_test_pysplicing.py -> build/bdist.macosx-10.9-x86_64/wheel/MISO/misopy
    copying build/lib/MISO/misopy/gff_utils.py -> build/bdist.macosx-10.9-x86_64/wheel/MISO/misopy
    copying build/lib/MISO/misopy/as_events.py -> build/bdist.macosx-10.9-x86_64/wheel/MISO/misopy
    copying build/lib/MISO/misopy/miso_zip.py -> build/bdist.macosx-10.9-x86_64/wheel/MISO/misopy
    copying build/lib/MISO/misopy/exon_utils.py -> build/bdist.macosx-10.9-x86_64/wheel/MISO/misopy
    copying build/lib/MISO/misopy/run_miso.py -> build/bdist.macosx-10.9-x86_64/wheel/MISO/misopy
    copying build/lib/MISO/misopy/__init__.py -> build/bdist.macosx-10.9-x86_64/wheel/MISO/misopy
    copying build/lib/MISO/misopy/hypothesis_test.py -> build/bdist.macosx-10.9-x86_64/wheel/MISO/misopy
    copying build/lib/MISO/misopy/sam_to_bam.py -> build/bdist.macosx-10.9-x86_64/wheel/MISO/misopy
    copying build/lib/MISO/misopy/misc_utils.py -> build/bdist.macosx-10.9-x86_64/wheel/MISO/misopy
    copying build/lib/MISO/misopy/sam_rpkm.py -> build/bdist.macosx-10.9-x86_64/wheel/MISO/misopy
    copying build/lib/MISO/misopy/index_gff.py -> build/bdist.macosx-10.9-x86_64/wheel/MISO/misopy
    copying build/lib/MISO/misopy/filter_events.py -> build/bdist.macosx-10.9-x86_64/wheel/MISO/misopy
    copying build/lib/MISO/misopy/miso_db.py -> build/bdist.macosx-10.9-x86_64/wheel/MISO/misopy
    copying build/lib/MISO/misopy/py2c_gene.py -> build/bdist.macosx-10.9-x86_64/wheel/MISO/misopy
    copying build/lib/MISO/misopy/miso.py -> build/bdist.macosx-10.9-x86_64/wheel/MISO/misopy
    copying build/lib/MISO/misopy/cluster_utils.py -> build/bdist.macosx-10.9-x86_64/wheel/MISO/misopy
    copying build/lib/MISO/misopy/miso_pack.py -> build/bdist.macosx-10.9-x86_64/wheel/MISO/misopy
    copying build/lib/MISO/misopy/test_miso.py -> build/bdist.macosx-10.9-x86_64/wheel/MISO/misopy
    creating build/bdist.macosx-10.9-x86_64/wheel/MISO/misopy/sashimi_plot
    copying build/lib/MISO/misopy/sashimi_plot/plot.py -> build/bdist.macosx-10.9-x86_64/wheel/MISO/misopy/sashimi_plot
    copying build/lib/MISO/misopy/sashimi_plot/Sashimi.py -> build/bdist.macosx-10.9-x86_64/wheel/MISO/misopy/sashimi_plot
    copying build/lib/MISO/misopy/sashimi_plot/__init__.py -> build/bdist.macosx-10.9-x86_64/wheel/MISO/misopy/sashimi_plot
    copying build/lib/MISO/misopy/sashimi_plot/sashimi_plot.py -> build/bdist.macosx-10.9-x86_64/wheel/MISO/misopy/sashimi_plot
    creating build/bdist.macosx-10.9-x86_64/wheel/MISO/misopy/sashimi_plot/plot_utils
    copying build/lib/MISO/misopy/sashimi_plot/plot_utils/plot_settings.py -> build/bdist.macosx-10.9-x86_64/wheel/MISO/misopy/sashimi_plot/plot_utils
    copying build/lib/MISO/misopy/sashimi_plot/plot_utils/samples_plotter.py -> build/bdist.macosx-10.9-x86_64/wheel/MISO/misopy/sashimi_plot/plot_utils
    copying build/lib/MISO/misopy/sashimi_plot/plot_utils/plotting.py -> build/bdist.macosx-10.9-x86_64/wheel/MISO/misopy/sashimi_plot/plot_utils
    copying build/lib/MISO/misopy/sashimi_plot/plot_utils/plot_gene.py -> build/bdist.macosx-10.9-x86_64/wheel/MISO/misopy/sashimi_plot/plot_utils
    copying build/lib/MISO/misopy/sashimi_plot/plot_utils/__init__.py -> build/bdist.macosx-10.9-x86_64/wheel/MISO/misopy/sashimi_plot/plot_utils
    copying build/lib/MISO/misopy/settings.py -> build/bdist.macosx-10.9-x86_64/wheel/MISO/misopy
    copying build/lib/MISO/misopy/test_cluster.py -> build/bdist.macosx-10.9-x86_64/wheel/MISO/misopy
    copying build/lib/MISO/misopy/parse_csv.py -> build/bdist.macosx-10.9-x86_64/wheel/MISO/misopy
    copying build/lib/MISO/misopy/summarize_miso.py -> build/bdist.macosx-10.9-x86_64/wheel/MISO/misopy
    copying build/lib/MISO/misopy/Gene.py -> build/bdist.macosx-10.9-x86_64/wheel/MISO/misopy
    copying build/lib/MISO/misopy/compare_miso.py -> build/bdist.macosx-10.9-x86_64/wheel/MISO/misopy
    copying build/lib/MISO/misopy/samples_utils.py -> build/bdist.macosx-10.9-x86_64/wheel/MISO/misopy
    copying build/lib/MISO/misopy/pickle_utils.py -> build/bdist.macosx-10.9-x86_64/wheel/MISO/misopy
    copying build/lib/MISO/misopy/kde_subclass.py -> build/bdist.macosx-10.9-x86_64/wheel/MISO/misopy
    copying build/lib/MISO/misopy/parse_gene.py -> build/bdist.macosx-10.9-x86_64/wheel/MISO/misopy
    copying build/lib/MISO/misopy/json_utils.py -> build/bdist.macosx-10.9-x86_64/wheel/MISO/misopy
    copying build/lib/MISO/misopy/module_availability.py -> build/bdist.macosx-10.9-x86_64/wheel/MISO/misopy
    copying build/lib/MISO/misopy/read_simulator.py -> build/bdist.macosx-10.9-x86_64/wheel/MISO/misopy
    copying build/lib/MISO/misopy/pe_utils.py -> build/bdist.macosx-10.9-x86_64/wheel/MISO/misopy
    running install_egg_info
    running egg_info
    writing src/rmats2sashimiplot.egg-info/PKG-INFO
    writing dependency_links to src/rmats2sashimiplot.egg-info/dependency_links.txt
    writing entry points to src/rmats2sashimiplot.egg-info/entry_points.txt
    writing top-level names to src/rmats2sashimiplot.egg-info/top_level.txt
    reading manifest file 'src/rmats2sashimiplot.egg-info/SOURCES.txt'
    reading manifest template 'MANIFEST.in'
    adding license file 'LICENSE'
    writing manifest file 'src/rmats2sashimiplot.egg-info/SOURCES.txt'
    Copying src/rmats2sashimiplot.egg-info to build/bdist.macosx-10.9-x86_64/wheel/rmats2sashimiplot-2.0.4-py3.8.egg-info
    running install_scripts
    creating build/bdist.macosx-10.9-x86_64/wheel/rmats2sashimiplot-2.0.4.dist-info/WHEEL
    creating '/private/tmp/pip-wheel-zn917w3e/.tmp-so2ktkur/rmats2sashimiplot-2.0.4-py3-none-any.whl' and adding 'build/bdist.macosx-10.9-x86_64/wheel' to it
    adding 'MISO/__init__.py'
    adding 'MISO/test.py'
    adding 'MISO/misopy/Gene.py'
    adding 'MISO/misopy/__init__.py'
    adding 'MISO/misopy/as_events.py'
    adding 'MISO/misopy/cluster_utils.py'
    adding 'MISO/misopy/compare_miso.py'
    adding 'MISO/misopy/credible_intervals.py'
    adding 'MISO/misopy/exon_utils.py'
    adding 'MISO/misopy/filter_events.py'
    adding 'MISO/misopy/gff_utils.py'
    adding 'MISO/misopy/hypothesis_test.py'
    adding 'MISO/misopy/index_gff.py'
    adding 'MISO/misopy/json_utils.py'
    adding 'MISO/misopy/kde_subclass.py'
    adding 'MISO/misopy/legacy_test_pysplicing.py'
    adding 'MISO/misopy/misc_utils.py'
    adding 'MISO/misopy/miso.py'
    adding 'MISO/misopy/miso_db.py'
    adding 'MISO/misopy/miso_pack.py'
    adding 'MISO/misopy/miso_sampler.py'
    adding 'MISO/misopy/miso_utils.py'
    adding 'MISO/misopy/miso_zip.py'
    adding 'MISO/misopy/module_availability.py'
    adding 'MISO/misopy/parse_csv.py'
    adding 'MISO/misopy/parse_gene.py'
    adding 'MISO/misopy/pe_utils.py'
    adding 'MISO/misopy/pickle_utils.py'
    adding 'MISO/misopy/py2c_gene.py'
    adding 'MISO/misopy/read_simulator.py'
    adding 'MISO/misopy/reads_utils.py'
    adding 'MISO/misopy/run_events_analysis.py'
    adding 'MISO/misopy/run_miso.py'
    adding 'MISO/misopy/sam_rpkm.py'
    adding 'MISO/misopy/sam_to_bam.py'
    adding 'MISO/misopy/sam_utils.py'
    adding 'MISO/misopy/samples_utils.py'
    adding 'MISO/misopy/settings.py'
    adding 'MISO/misopy/summarize_miso.py'
    adding 'MISO/misopy/test_cluster.py'
    adding 'MISO/misopy/test_miso.py'
    adding 'MISO/misopy/sashimi_plot/Sashimi.py'
    adding 'MISO/misopy/sashimi_plot/__init__.py'
    adding 'MISO/misopy/sashimi_plot/plot.py'
    adding 'MISO/misopy/sashimi_plot/sashimi_plot.py'
    adding 'MISO/misopy/sashimi_plot/plot_utils/__init__.py'
    adding 'MISO/misopy/sashimi_plot/plot_utils/plot_gene.py'
    adding 'MISO/misopy/sashimi_plot/plot_utils/plot_settings.py'
    adding 'MISO/misopy/sashimi_plot/plot_utils/plotting.py'
    adding 'MISO/misopy/sashimi_plot/plot_utils/samples_plotter.py'
    adding 'rmats2sashimiplot/__init__.py'
    adding 'rmats2sashimiplot/rmats2sashimiplot.py'
    adding 'rmats2sashimiplot-2.0.4.dist-info/LICENSE'
    adding 'rmats2sashimiplot-2.0.4.dist-info/METADATA'
    adding 'rmats2sashimiplot-2.0.4.dist-info/WHEEL'
    adding 'rmats2sashimiplot-2.0.4.dist-info/entry_points.txt'
    adding 'rmats2sashimiplot-2.0.4.dist-info/top_level.txt'
    adding 'rmats2sashimiplot-2.0.4.dist-info/RECORD'
    removing build/bdist.macosx-10.9-x86_64/wheel
    Building wheel for rmats2sashimiplot (pyproject.toml): finished with status 'done'
    Created wheel for rmats2sashimiplot: filename=rmats2sashimiplot-2.0.4-py3-none-any.whl size=151756 sha256=5360d702f6a419416e869e63d7f37add6916ff60b252805298b4d13929180460
    Stored in directory: /private/tmp/pip-ephem-wheel-cache-_kle568w/wheels/b1/b2/e3/f8de03dd1a6707a0ddb8159e11fc3d1fee9bf20bd3843131a9
  Successfully built rmats2sashimiplot
  Installing collected packages: rmats2sashimiplot

    changing mode of $PREFIX/bin/index_gff to 755
    changing mode of $PREFIX/bin/rmats2sashimiplot to 755
    changing mode of $PREFIX/bin/sashimi_plot to 755
  Successfully installed rmats2sashimiplot-2.0.4
  Removed build tracker: '/private/tmp/pip-build-tracker-4z12e36u'

  Resource usage statistics from building rmats2sashimiplot:
     Process count: 4
     CPU time: Sys=0:00:00.4, User=0:00:03.2
     Memory: 69.0M
     Disk usage: 2.6K
     Time elapsed: 0:00:10.6


  Packaging rmats2sashimiplot
  INFO:conda_build.build:Packaging rmats2sashimiplot
  Packaging rmats2sashimiplot-2.0.4-py38ha5e64a6_3
  INFO:conda_build.build:Packaging rmats2sashimiplot-2.0.4-py38ha5e64a6_3
  compiling .pyc files...
  number of files: 116
  Fixing permissions
  Packaged license file/s.
  INFO :: Time taken to mark (prefix)
          0 replacements in 0 files was 0.13 seconds
  Files containing CONDA_PREFIX
  -----------------------------
  bin/index_gff (text): Patching
  bin/rmats2sashimiplot (text): Patching
  bin/sashimi_plot (text): Patching
  TEST START: /opt/mambaforge/envs/bioconda/conda-bld/osx-64/rmats2sashimiplot-2.0.4-py38ha5e64a6_3.tar.bz2
  Renaming work directory '/opt/mambaforge/envs/bioconda/conda-bld/rmats2sashimiplot_1685182621597/work' to '/opt/mambaforge/envs/bioconda/conda-bld/rmats2sashimiplot_1685182621597/work_moved_rmats2sashimiplot-2.0.4-py38ha5e64a6_3_osx-64'
  shutil.move(work)=/opt/mambaforge/envs/bioconda/conda-bld/rmats2sashimiplot_1685182621597/work, dest=/opt/mambaforge/envs/bioconda/conda-bld/rmats2sashimiplot_1685182621597/work_moved_rmats2sashimiplot-2.0.4-py38ha5e64a6_3_osx-64)
  INFO:conda_build.utils:Renaming work directory '/opt/mambaforge/envs/bioconda/conda-bld/rmats2sashimiplot_1685182621597/work' to '/opt/mambaforge/envs/bioconda/conda-bld/rmats2sashimiplot_1685182621597/work_moved_rmats2sashimiplot-2.0.4-py38ha5e64a6_3_osx-64'
  INFO:conda_build.utils:shutil.move(work)=/opt/mambaforge/envs/bioconda/conda-bld/rmats2sashimiplot_1685182621597/work, dest=/opt/mambaforge/envs/bioconda/conda-bld/rmats2sashimiplot_1685182621597/work_moved_rmats2sashimiplot-2.0.4-py38ha5e64a6_3_osx-64)
  Reloading output folder: /opt/mambaforge/envs/bioconda/conda-bld

  ## Package Plan ##

    environment location: /opt/mambaforge/envs/bioconda/conda-bld/rmats2sashimiplot_1685182621597/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_p


  The following NEW packages will be INSTALLED:

      bedtools:            2.31.0-h6372da2_2         bioconda
      brotli:              1.0.9-hb7f2c08_8          conda-forge
      brotli-bin:          1.0.9-hb7f2c08_8          conda-forge
      bzip2:               1.0.8-h0d85af4_4          conda-forge
      c-ares:              1.19.1-h0dc2134_0         conda-forge
      ca-certificates:     2023.5.7-h8857fd0_0       conda-forge
      certifi:             2023.5.7-pyhd8ed1ab_0     conda-forge
      charset-normalizer:  3.1.0-pyhd8ed1ab_0        conda-forge
      contourpy:           1.0.7-py38h98b9b1b_0      conda-forge
      cycler:              0.11.0-pyhd8ed1ab_0       conda-forge
      fonttools:           4.39.4-py38hcafd530_0     conda-forge
      freetype:            2.12.1-h3f81eb7_1         conda-forge
      htslib:              1.17-h567f53e_1           bioconda
      idna:                3.4-pyhd8ed1ab_0          conda-forge
      importlib-resources: 5.12.0-pyhd8ed1ab_0       conda-forge
      importlib_resources: 5.12.0-pyhd8ed1ab_0       conda-forge
      jpeg:                9e-hb7f2c08_3             conda-forge
      kiwisolver:          1.4.4-py38h98b9b1b_1      conda-forge
      krb5:                1.20.1-h049b76e_0         conda-forge
      lcms2:               2.14-h90f4b2a_0           conda-forge
      lerc:                4.0.0-hb486fe8_0          conda-forge
      libblas:             3.9.0-16_osx64_openblas   conda-forge
      libbrotlicommon:     1.0.9-hb7f2c08_8          conda-forge
      libbrotlidec:        1.0.9-hb7f2c08_8          conda-forge
      libbrotlienc:        1.0.9-hb7f2c08_8          conda-forge
      libcblas:            3.9.0-16_osx64_openblas   conda-forge
      libcurl:             7.88.1-h6df9250_1         conda-forge
      libcxx:              16.0.4-hd57cbcb_0         conda-forge
      libdeflate:          1.13-h775f41a_0           conda-forge
      libedit:             3.1.20191231-h0678c8f_2   conda-forge
      libev:               4.33-haf1e3a3_1           conda-forge
      libffi:              3.4.2-h0d85af4_5          conda-forge
      libgfortran:         5.0.0-11_3_0_h97931a8_31  conda-forge
      libgfortran5:        12.2.0-he409387_31        conda-forge
      liblapack:           3.9.0-16_osx64_openblas   conda-forge
      libnghttp2:          1.52.0-he2ab024_0         conda-forge
      libopenblas:         0.3.21-openmp_h429af6e_3  conda-forge
      libpng:              1.6.39-ha978bb4_0         conda-forge
      libsqlite:           3.42.0-h58db7d2_0         conda-forge
      libssh2:             1.10.0-h47af595_3         conda-forge
      libtiff:             4.4.0-h5e0c7b4_3          conda-forge
      libwebp-base:        1.3.0-hb7f2c08_0          conda-forge
      libxcb:              1.13-h0d85af4_1004        conda-forge
      libzlib:             1.2.13-hfd90126_4         conda-forge
      llvm-openmp:         16.0.4-hff08bdf_0         conda-forge
      matplotlib-base:     3.7.1-py38hcb346ec_0      conda-forge
      munkres:             1.1.4-pyh9f0ad1d_0        conda-forge
      ncurses:             6.3-h96cf925_1            conda-forge
      numpy:               1.24.3-py38h9a4a08f_0     conda-forge
      openjpeg:            2.5.0-h5d0d7b0_1          conda-forge
      openssl:             3.1.0-h8a1eda9_3          conda-forge
      packaging:           23.1-pyhd8ed1ab_0         conda-forge
      pillow:              9.2.0-py38h85595ef_3      conda-forge
      platformdirs:        3.5.1-pyhd8ed1ab_0        conda-forge
      pooch:               1.7.0-pyha770c72_3        conda-forge
      pthread-stubs:       0.4-hc929b4f_1001         conda-forge
      pyparsing:           3.0.9-pyhd8ed1ab_0        conda-forge
      pysam:               0.21.0-py38h85ed9dd_0     bioconda
      pysocks:             1.7.1-pyha2e5f31_6        conda-forge
      python:              3.8.16-hf9b03c3_1_cpython conda-forge
      python-dateutil:     2.8.2-pyhd8ed1ab_0        conda-forge
      python_abi:          3.8-3_cp38                conda-forge
      readline:            8.2-h9e318b2_1            conda-forge
      requests:            2.31.0-pyhd8ed1ab_0       conda-forge
      rmats2sashimiplot:   2.0.4-py38ha5e64a6_3      local
      samtools:            1.17-hf4d6830_0           bioconda
      scipy:               1.10.1-py38h9cf86d3_3     conda-forge
      six:                 1.16.0-pyh6c4a22f_0       conda-forge
      tk:                  8.6.12-h5dbffcc_0         conda-forge
      typing-extensions:   4.6.2-hd8ed1ab_0          conda-forge
      typing_extensions:   4.6.2-pyha770c72_0        conda-forge
      unicodedata2:        15.0.0-py38hef030d1_0     conda-forge
      urllib3:             2.0.2-pyhd8ed1ab_0        conda-forge
      xorg-libxau:         1.0.11-h0dc2134_0         conda-forge
      xorg-libxdmcp:       1.1.3-h35c211d_0          conda-forge
      xz:                  5.2.6-h775f41a_0          conda-forge
      zipp:                3.15.0-pyhd8ed1ab_0       conda-forge
      zlib:                1.2.13-hfd90126_4         conda-forge
      zstd:                1.5.2-hbc0c0cd_6          conda-forge

  Preparing transaction: ...working... done
  Verifying transaction: ...working... done
  Executing transaction: ...working... done
  export PREFIX=/opt/mambaforge/envs/bioconda/conda-bld/rmats2sashimiplot_1685182621597/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_p
  export SRC_DIR=/opt/mambaforge/envs/bioconda/conda-bld/rmats2sashimiplot_1685182621597/test_tmp
  import: 'MISO'
  import: 'MISO.misopy'
  import: 'MISO.misopy.sashimi_plot'
  import: 'MISO.misopy.sashimi_plot.plot_utils'
  import: 'rmats2sashimiplot'
  import: 'MISO'
  import: 'MISO.misopy'
  import: 'MISO.misopy.sashimi_plot'
  import: 'MISO.misopy.sashimi_plot.plot_utils'
  import: 'rmats2sashimiplot'
  + rmats2sashimiplot --help
  usage: rmats2sashimiplot [-h] --l1 L1 --l2 L2 -o OUT_DIR
                           [-t {SE,A5SS,A3SS,MXE,RI}] [-e EVENTS_FILE]
                           [-c COORDINATE] [--s1 S1] [--s2 S2] [--b1 B1]
                           [--b2 B2] [--exon_s EXON_S] [--intron_s INTRON_S]
                           [--group-info GROUP_INFO] [--min-counts MIN_COUNTS]
                           [--color COLOR] [--font-size FONT_SIZE]
                           [--hide-number] [--no-text-background]

  optional arguments:
    -h, --help            show this help message and exit

  Required:
    --l1 L1               The label for first sample.
    --l2 L2               The label for second sample.
    -o OUT_DIR            The output directory.

  rMATS event input:
    Use either (rMATS event input) or (Coordinate and annotation input)

    -t {SE,A5SS,A3SS,MXE,RI}
                          Type of event from rMATS result used in the analysis.
                          'SE': skipped exon, 'A5SS': alternative 5' splice
                          site, 'A3SS' alternative 3' splice site, 'MXE':
                          mutually exclusive exons, 'RI': retained intron. (Only
                          if using rMATS event input)
    -e EVENTS_FILE        The rMATS output event file (Only if using rMATS event
                          input)

  Coordinate and annotation input:
    Use either (Coordinate and annotation input) or (rMATS event input)

    -c COORDINATE         The genome region coordinates and a GFF3 (not GTF)
                          annotation file of genes and transcripts. The format
                          is -c
                          {chromosome}:{strand}:{start}:{end}:{/path/to/gff3}
                          (Only if using Coordinate and annotation input)

  SAM Files:
    Mapping results for sample_1 & sample_2 in SAM format. Replicates must be
    in a comma separated list. (Only if using SAM)

    --s1 S1               sample_1 sam files: s1_rep1.sam[,s1_rep2.sam]
    --s2 S2               sample_2 sam files: s2_rep1.sam[,s2_rep2.sam]

  BAM Files:
    Mapping results for sample_1 & sample_2 in BAM format. Replicates must be
    in a comma separated list. (Only if using BAM)

    --b1 B1               sample_1 bam files: s1_rep1.bam[,s1_rep2.bam]
    --b2 B2               sample_2 bam files: s2_rep1.bam[,s2_rep2.bam]

  Optional:
    --exon_s EXON_S       How much to scale down exons. Default: 1
    --intron_s INTRON_S   How much to scale down introns. For example,
                          --intron_s 5 results in an intron with real length of
                          100 being plotted as 100/5 = 20. Default: 1
    --group-info GROUP_INFO
                          The path to a *.gf file which groups the replicates.
                          One sashimi plot will be generated for each group
                          instead of the default behavior of one plot per
                          replicate
    --min-counts MIN_COUNTS
                          Individual junctions with read count below --min-
                          counts will be omitted from the plot. Default: 0
    --color COLOR         Specify a list of colors with one color per plot.
                          Without grouping there is one plot per replicate. With
                          grouping there is one plot per group: --color
                          '#CC0011[,#FF8800]'
    --font-size FONT_SIZE
                          Set the font size. Default: 8
    --hide-number         Do not display the read count on the junctions
    --no-text-background  Do not put a white box behind the junction read count
  + index_gff --help
  <module 'misopy' from '$PREFIX/lib/python3.8/site-packages/MISO/misopy/__init__.py'>
  Usage: index_gff [options]

  Options:
    -h, --help         show this help message and exit
    --index=INDEX_GFF  Index the given GFF. Takes as arguments as GFF filename
                       and an output directory.
    --compress-id      Use the compressed version of the GFF 'ID=' field rather
                       than the ID itself when creating .miso output filenames.
  + sashimi_plot --help
  Traceback (most recent call last):
    File "/opt/mambaforge/envs/bioconda/conda-bld/rmats2sashimiplot_1685182621597/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_p/bin/sashimi_plot", line 7, in <module>
      from MISO.misopy.sashimi_plot.sashimi_plot import main
    File "/opt/mambaforge/envs/bioconda/conda-bld/rmats2sashimiplot_1685182621597/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_p/lib/python3.8/site-packages/MISO/misopy/sashimi_plot/sashimi_plot.py", line 32, in <module>
      from misopy.sashimi_plot.Sashimi import Sashimi
    File "/opt/mambaforge/envs/bioconda/conda-bld/rmats2sashimiplot_1685182621597/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_p/lib/python3.8/site-packages/MISO/misopy/sashimi_plot/Sashimi.py", line 11, in <module>
      import misopy.sashimi_plot.plot_utils.plotting as plotting
    File "/opt/mambaforge/envs/bioconda/conda-bld/rmats2sashimiplot_1685182621597/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_p/lib/python3.8/site-packages/MISO/misopy/sashimi_plot/plot_utils/plotting.py", line 5, in <module>
      from mpl_toolkits.axes_grid.axislines import SubplotZero
  ModuleNotFoundError: No module named 'mpl_toolkits.axes_grid'
  Tests failed for rmats2sashimiplot-2.0.4-py38ha5e64a6_3.tar.bz2 - moving package to /opt/mambaforge/envs/bioconda/conda-bld/broken
  WARNING:conda_build.build:Tests failed for rmats2sashimiplot-2.0.4-py38ha5e64a6_3.tar.bz2 - moving package to /opt/mambaforge/envs/bioconda/conda-bld/broken
  TESTS FAILED: rmats2sashimiplot-2.0.4-py38ha5e64a6_3.tar.bz2
