{% set version = "1.6.0" %}
{% set name = "GenProSeq" %}
{% set bioc = "3.18" %}

package:
  name: 'bioconductor-{{ name|lower }}'
  version: '{{ version }}'
source:
  url:
    - 'https://bioconductor.org/packages/{{ bioc }}/bioc/src/contrib/{{ name }}_{{ version }}.tar.gz'
    - 'https://bioconductor.org/packages/{{ bioc }}/bioc/src/contrib/Archive/{{ name }}/{{ name }}_{{ version }}.tar.gz'
    - 'https://bioarchive.galaxyproject.org/{{ name }}_{{ version }}.tar.gz'
    - 'https://depot.galaxyproject.org/software/bioconductor-{{ name|lower }}/bioconductor-{{ name|lower }}_{{ version }}_src_all.tar.gz'
  md5: 15e772912f2019256df52d192edd5402
build:
  number: 0
  rpaths:
    - lib/R/lib/
    - lib/
  run_exports: '{{ pin_subpackage("bioconductor-genproseq", max_pin="x.x") }}'
  noarch: generic
# Suggests: ggseqlogo, VAExprs, stringdist, knitr, testthat, rmarkdown
requirements:
  host:
    - 'bioconductor-deeppincs >=1.10.0,<1.11.0'
    - 'bioconductor-ttgsea >=1.10.0,<1.11.0'
    - r-base
    - r-catencoders
    - r-keras
    - r-mclust
    - r-reticulate
    - r-tensorflow
    - r-word2vec
  run:
    - 'bioconductor-deeppincs >=1.10.0,<1.11.0'
    - 'bioconductor-ttgsea >=1.10.0,<1.11.0'
    - r-base
    - r-catencoders
    - r-keras
    - r-mclust
    - r-reticulate
    - r-tensorflow
    - r-word2vec
test:
  commands:
    - '$R -e "library(''{{ name }}'')"'
about:
  home: 'https://bioconductor.org/packages/{{ bioc }}/bioc/html/{{ name }}.html'
  license: Artistic-2.0
  summary: 'Generating Protein Sequences with Deep Generative Models'
  description: 'Generative modeling for protein engineering is key to solving fundamental problems in synthetic biology, medicine, and material science. Machine learning has enabled us to generate useful protein sequences on a variety of scales. Generative models are machine learning methods which seek to model the distribution underlying the data, allowing for the generation of novel samples with similar properties to those on which the model was trained. Generative models of proteins can learn biologically meaningful representations helpful for a variety of downstream tasks. Furthermore, they can learn to generate protein sequences that have not been observed before and to assign higher probability to protein sequences that satisfy desired criteria. In this package, common deep generative models for protein sequences, such as variational autoencoder (VAE), generative adversarial networks (GAN), and autoregressive models are available. In the VAE and GAN, the Word2vec is used for embedding. The transformer encoder is applied to protein sequences for the autoregressive model.'

