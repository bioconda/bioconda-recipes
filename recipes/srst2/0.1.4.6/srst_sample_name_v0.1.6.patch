diff --git a/scripts/srst2.py b/scripts/srst2.py
index 67e48ae..916792e 100755
--- a/scripts/srst2.py
+++ b/scripts/srst2.py
@@ -233,7 +233,7 @@ def parse_fai(fai_file,db_type,delimiter):
 	return size, gene_clusters, unique_gene_symbols, unique_allele_symbols, gene_cluster_symbols
 
 
-def read_pileup_data(pileup_file, size, prob_err, consensus_file = ""):
+def read_pileup_data(pileup_file, size, prob_err, sample_name, consensus_file = ""):
 	with open(pileup_file) as pileup:
 		prob_success = 1 - prob_err	# Set by user, default is prob_err = 0.01
 		hash_alignment = {}
@@ -372,7 +372,7 @@ def read_pileup_data(pileup_file, size, prob_err, consensus_file = ""):
 				elif consensus_file.split(".")[-2] == "all_consensus_alleles":
 					consensus_type = "consensus"
 				with open(consensus_file, "a") as consensus_outfile:
-					consensus_outfile.write(">{0}.{1} {2}\n".format(allele, consensus_type, pileup_file.split(".")[1].split("__")[1]))
+					consensus_outfile.write(">{0}.{1} {2}\n".format(allele, consensus_type, sample_name))
 					outstring = consensus_seq + "\n"
 					consensus_outfile.write(outstring)
 
@@ -782,7 +782,7 @@ def create_allele_pileup(allele_name, all_pileup_file):
 def parse_scores(run_type,args,scores, hash_edge_depth, 
 					avg_depth_allele, coverage_allele, mismatch_allele, indel_allele,  
 					missing_allele, size_allele, next_to_del_depth_allele,
-					unique_cluster_symbols,unique_allele_symbols, pileup_file):
+					unique_cluster_symbols,unique_allele_symbols, pileup_file, sample_name):
 					
 	# sort into hash for each gene locus
 	scores_by_gene = collections.defaultdict(dict) # key1 = gene, key2 = allele, value = score
@@ -868,11 +868,11 @@ def parse_scores(run_type,args,scores, hash_edge_depth,
 			if args.report_new_consensus or args.report_all_consensus:
 				new_alleles_filename = args.output + ".new_consensus_alleles.fasta" 
 				allele_pileup_file = create_allele_pileup(results[gene][0], pileup_file)
-				read_pileup_data(allele_pileup_file, size_allele, args.prob_err, consensus_file = new_alleles_filename)
+				read_pileup_data(allele_pileup_file, size_allele, args.prob_err, sample_name, consensus_file = new_alleles_filename)
 		if args.report_all_consensus:
 			new_alleles_filename = args.output + ".all_consensus_alleles.fasta"
 			allele_pileup_file = create_allele_pileup(results[gene][0], pileup_file)
-			read_pileup_data(allele_pileup_file, size_allele, args.prob_err, consensus_file = new_alleles_filename)
+			read_pileup_data(allele_pileup_file, size_allele, args.prob_err, sample_name, consensus_file = new_alleles_filename)
 
 	return results # (allele, diffs, depth_problem, divergence)
 					
@@ -1265,7 +1265,7 @@ def map_fileSet_to_db(args,sample_name,fastq_inputs,db_name,fasta,size,gene_name
 		logging.info(' Processing SAMtools pileup...')
 		hash_alignment, hash_max_depth, hash_edge_depth, avg_depth_allele, coverage_allele, \
 				mismatch_allele, indel_allele, missing_allele, size_allele, next_to_del_depth_allele= \
-				read_pileup_data(pileup_file, size, args.prob_err)
+				read_pileup_data(pileup_file, size, args.prob_err, sample_name)
 
 		# Generate scores for all alleles (prints these and associated info if verbose)
 		#   result = dict, with key=allele, value=score
@@ -1283,7 +1283,7 @@ def map_fileSet_to_db(args,sample_name,fastq_inputs,db_name,fasta,size,gene_name
 	allele_scores = parse_scores(run_type, args, scores, \
 			hash_edge_depth, avg_depth_allele, coverage_allele, mismatch_allele,  \
 			indel_allele, missing_allele, size_allele, next_to_del_depth_allele,
-			unique_gene_symbols, unique_allele_symbols, pileup_file)
+			unique_gene_symbols, unique_allele_symbols, pileup_file, sample_name)
 			
 	# REPORT/RECORD RESULTS
 	
